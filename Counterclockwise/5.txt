CHAPTER 5





Reengineering Medical Rules


The only man I know who behaves sensibly is my tailor; he takes my measurements anew each time he sees me. The rest go on with their old measurements and expect me to fit them.

—George Bernard Shaw





Imagine a situation in which an elderly woman is able to live independently. She typically shops for her groceries every few days. When she arrives at her apartment door, she puts down the grocery bag, searches for her key, opens the door, and then bends down to pick up the bag and carries it inside. Today, however, is different. She puts the bag down but can’t bend over far enough to pick it up. Luckily, a neighbor happens by to help her, but the problem persists. If she can’t get her groceries home, she is no longer able to take care of herself. Her adult children, fearing for her diminished state, help her move to a nursing home.

Now consider this scenario. An elderly woman living independently comes back to her apartment with her groceries. She places the bag on a small shelf outside her door, searches for her key, opens the door, and carries in her grocery bag. In the first case, the woman is considered too frail to care for herself, but not in the latter. The only difference is a small piece of wood serving as a shelf.

The external world is socially constructed, but we rarely see it that way. Most things were initially designed to meet the needs of the designer and that person’s conception of the “typical” person. The width of a seat in a theater, the height of a kitchen table, and the size of a sugar cube were all decisions that might not best meet our individual needs. The problem is that we often don’t see much of our external world. It’s in the background, unchanging and unchallenged, blinding us to the fact that choices were made in its construction. If our socially constructed environment ceases to work for us, we see it as a fault of ours. It rarely occurs to us to attribute the problem to the environment or to change the construction to meet our needs. When I reach for a dish on the top shelf in the kitchen and accidentally drop it, I may attribute the broken plate to my clumsiness. It would be better for me to forget the personal insult and attribute it to being distracted as I reached for the plate. It would be even better, however, to recognize that the shelf was built for someone taller than I am. Perhaps with this realization, I might even decide to have the shelves redesigned to better fit my needs.

The shape of the medical world affects our views of ourselves and our health and it too is socially constructed. Doctors and nurses wear uniforms, hospital rooms are all similar, bandages are white, IV poles are ominous-looking, doctors’ offices are barren except for framed degrees, patients doors are left open—most everything about the medical world as it is constructed is a double-edged sword, although we rarely recognize the negative effects or challenge their reason for being.

Let’s take these up in turn. Medical uniforms serve certain important functions: they denote group affiliation, and they are white so that dirt and other contaminants can be easily spotted. Medical uniforms also confer status on the wearer. Each of these functions comes at a cost, which varies depending on the context. If we visit a doctor in her office, do we need to see her in a white coat to know that she is our doctor? The uniform creates distance and implicitly keeps us in our place. It tells us who the expert is here, and so we are less likely to question her, even if questioning would be to our advantage. If the doctor needed to perform some messy procedure, at that time a lab coat could be donned. In a nursing home setting, elderly adults are not likely to be confused with staff; the latter probably don’t need to wear uniforms. When they do, they emphasize “nursing” over “home.” Whatever the advantages of uniforms, their disadvantages bear thinking about.

What is the effect of the uniform on the wearer? Deciding what to wear every day presents the opportunity to examine how we are feeling psychologically (and physically)—if only we were to ask why we make the choices we do. This information could be useful. By choosing our clothes, we become more individualized, and that could lead us to take more responsibility for our actions. While our uniforms convey status, it is easy for us to hide behind status. Years ago, when consulting to a nursing home, I vividly remember how dramatically my experience changed when I first thought about uniforms. I didn’t have a uniform proper, but I walked around with a pen and pad on which I rarely wrote anything down. They were my uniform, and I found that I hid behind them. My “uniform” announced that I was a person of status. It determined how the staff would view and interact with me and how I in turn would interact with them. I didn’t need to fully engage. After all, I was in charge. On my third visit to one of these homes, I decided to put the pad and pen away. Going without my “uniform” forced me be in the present as a person, not as someone with a particular status earned in the past. I found it exhilarating and I began to look forward to my time at that facility, which I used to dread.

I soon suggested that the nurses put their uniforms away as well. They at first strenuously objected but in the end followed suit. I was consulting to the nursing home and not doing research, so I didn’t collect data, but once the uniforms were put away, the difference in the nursing home was almost palpable. Individuals interacted with other individuals. While there were still differences among residents, nurses, doctors, and consultant, especially age-related ones, these differences—and the status associated with the roles—became less a factor in dealing with everyday problems. Residents seemed to be less demanding of the nurses, and nurses seemed to be more respectful of the residents.

Why should the everyday external world have such negative effects on the very people that the medical establishment is trying to help? Perhaps the answer can be found in the growing body of social psychological research on how past experience influences our current behavior in ways that we are often unaware of. It often takes very little to make such experiences salient.

Psychologists Anthony Greenwald and Mahzarin Banaji refer to the cues that activate particular associations and influence our behavior as “primes.”1 Our physical environment primes our feelings and behavior, although we are typically oblivious to its influence. Primes often tell us what is expected of us, and too often we mindlessly comply. Many aspects of the medical world do just this in ways that are not helpful, presenting us with subtle cues that lead us to behave in ways we otherwise would not behave. In a sense they control our behavior. Psychologists John Bargh, Mark Chen, and Lara Burrows conducted a wonderful study to understand more deeply the effects of priming and to consider its potential negative effects.2 Subjects were randomly put into one of two groups. In the experimental group, they were asked to solve anagrams, unaware that they had been formed from words that were stereotypes about old age (for example, felorguft from forgetful). The control group solved anagrams of neutral, non-age-related words. After solving the anagrams, people were purportedly finished with their participation and dismissed. The researchers then timed their short walk to the elevator in order to leave the building. Those research participants whose anagrams contained primes for “old age” walked to the elevator more slowly.

In more recent work, my students Maja Djikic and Sarah Stapleton and I were interested in seeing if we could reverse the effects of mindless primes.3 Before we started the study proper we had people sort a hundred photographs of old and young individuals. We found that if young people sort mixed photos of old and young people, the photos prime old age. In our experiment, those in the control group were instructed to put the photos into two groups, “old” or “young,” twenty at a time, thus priming them for old age. This group replicated the slowed walking speed of the previous study’s subjects. An experimental group sorted the photos into several groups where, for each twenty photos, they were given a new, non-age-related category (such as “gender”) on which to base the sorting. A second experimental group generated their own non-age-related sorting categories. We were looking to see whether the mindful action of recatego-rizing would lead people to be immune to the “old age” prime. We expected them to come to see the person in the photo was many things and not just old. The experimental groups that did the mindful sorting did not walk slowly. Being mindful allowed them to overcome the effects of the “old age” prime.





The Socially Constructed World


White coats in hospitals may work the same way. They prime the concept “doctor” and so they bring to mind our stereotypes about doctors. If we see doctors as authority figures instead of as people first, we tend to behave as though they are just that, even if a particular doctor may be very approachable. Doctor and nurse uniforms are also likely to prime “patient” as well, and when we see ourselves as patients, we tend to behave like them.

Most doctors’ offices are rather sterile and uninviting, conveying to patients the seriousness of their visit, even when it may not be very serious. Almost every aspect of a hospital room suggests serious illness. Not only does this affect the patient directly by inducing stress, but it affects him indirectly through his family and friends. Imagine you come to see me in the hospital and you see that I’m on an IV. Where would you stand and how do you interact with me? Now imagine that the pole from which the IV hangs is playfully candy-striped, like a child’s image of the North Pole. Where might you stand and how do you interact with me? (Of course, if the pole has always been striped, we might associate candy striping with ominous needles. The larger point is that often we are oblivious to the effect of the environment on our behavior.)

Imagine that you are recovering from knee surgery after an early winter ski accident. When you’re ready to get up and around on your crutches, you might realize that whoever made them didn’t think that winter ambulation was a good idea. If crutches were made so that you could press a button to release metal cleats, you would not necessarily be so house-bound.

In nursing homes, life is made as easy as possible for the residents. On the face of it, this seems to be a good thing. Without any difficulties, however, there is little room for any feeling of mastery. If we truly wanted life to be easy, we would make very different choices than most of us currently do. We would only ski on beginners’ slopes; we’d be content to play just scales on our musical instruments; we’d rarely if ever try anything new. Clearly, most of us want to be challenged intellectually, physically, or both. To master something new feels good and fosters mindfulness, which is good for us and our health. And there is more benefit to the process of actively mastering (because it is mindful) than having already mastered. The elderly are often deprived of these advantages. Not only do we make life too easy for them, but we overassist them with whatever difficulties we can’t completely eliminate. Helping feels good to the helper, but over time it may make the helped feel incompetent. Dr. Jerry Avorn of Harvard Medical School and I conducted research in which we either guided elderly adults in a task, directly helped them, or let them fend for themselves.4 The results were clear: those who were helped performed the most poorly at the task. I’m not suggesting that we stop being helpful. I am suggesting that we think twice in each instance and ask if, given a bit more time, the person could help herself. If she does, she helps herself to be healthier.

Another group we overhelp is the “disabled.” Handicapped signs label us as such and suggest that our abilities are steady-state. There are days any of us can walk a good distance and days that it is harder, but how often do I ask myself what I feel I can do today if I have a handicapped parking sticker and always make use of the allotted spaces? The way to deal with infirmity is not to ignore it or hide it; rather, the world we construct could and should do a better job of conveying to us that our abilities vary from day to day and that the disorders we have are not fixed. (Some parking lots have a minibus that drives around, picking up anyone who wants a ride, eliminating the need to sequester those with a need for help to a specific area of the lot.) Some of the changes that could be made don’t require much work, just new thinking. Consider one of my pet peeves: open-door policies in nursing homes and hospitals. The open door not only deprives us of privacy but also implicitly tells us we are weak and in need of constant supervision. While an open door may be useful on a critical care ward, the human costs may be unnecessarily high for others. Anything that subtly tells us we need total care fosters dependency, passivity, and mindlessness. When we are encouraged to depend so completely on others, we don’t need to pay attention to how we may be able to care for ourselves today. If we were brought into the process of caring for ourselves, we probably would think to pay attention to subtle changes in our health, to take charge of at least some of the things we can do ourselves, and in so doing improve our psychological and physical state.

Medical equipment shouts that we are sick. Does the grab bar in the shower have to look so categorically out of place? It could be designed to fit more discreetly into the overall design. Can’t crutches be more aesthetically appealing? When I was a graduate student, I saw someone wearing a cast that was colorfully painted. It invited the observer to look, indeed to stare at the person’s misfortune. It occurred to me that at least part of the reason we avoid people with handicaps is because they create a conflict for us. We’re curious and want to look, but we’re not supposed to stare.

Colleagues Shelley Taylor, Susan Fiske, Benzion Chanowitz, and I decided to test this psychological conflict between wanting to stare and the desire to follow our social norms against staring, what we called the novel-stimulus hypothesis.5 We wanted to see if when people were given the chance to satisfy their curiosity, they would be less likely to avoid disabled people when they encountered them.

We conducted experiments in which student participants were allowed to observe a person with a large leg brace through a one-way mirror, and then measured how close the student sat to the person when later in the same room. Not surprisingly, we found that those students who were allowed to stare sat closer than those who were suddenly introduced to the person and asked to sit with him or her.

The FAA has a checklist for airline pilots to use as a safety check. The checklist is now so familiar that many pilots run through it mindlessly, which has resulted in an increase in accidents. Likewise, one of the most damaging artifacts of our socially constructed medical world is the medical chart. First, these charts don’t change much, and in this regard, the medical staff, just like the pilots, may learn to treat them mindlessly. The categorical information that is the focus of these charts—information such as past medical history, psychological history, medications, allergies—is based on what is necessary for the typical patient. Idiosyncratic information that might be important can get lost. Research reveals new findings every day, but charts are upgraded infrequently. Consider if instead we redesigned these charts so that they required the doctor to look intently at the patient (perhaps to gauge pallor or alertness or temperament) in order to complete part of them; the information gathered and tallied would by necessity be different each time the doctor or nurse used the chart. Now the doctor would have to actively engage the patient, and the patient would feel individualized and engage the doctor. The interaction would go from mindless to mindful, and the health and well-being of both patient and doctor would improve.6

The technology already exists to make the environment (both the general environment and the medical environment) more accommodating to an older population. For example, older people often find cell phones, PDAs, and the like hard to read because the screen fonts were created by and for young people. As long as our culture teaches us that vision must get worse as we age, there is a ready market awaiting the person who redesigns these devices for those of us with less acute vision and a lack of desire to find out how to program the larger font. In the same way, medication typically used to be tested on young adults. As a result, older adults were often overmedicated. If the reverse had been the case, younger adults would seem beyond treatment—the drugs just would not have been as effective. Some of us who are young resemble the old, and just as certainly some of us who are old resemble the young; thus some of us are not getting enough medication and some are getting too much.

What if, instead of writing a prescription for a single medication, the doctor gave us a choice of at least two medications that she believed would be beneficial? That would not only bring us into the process and increase our mindfulness but also remind the physician of the uncertainty inherent in the choice in the first place. It might even be enough to lead us to stay tuned in over time while we take the chosen medication, revealing the variability in our symptoms to us.

In changing our houses and offices—all aspects of the environment—so that there is a better fit for us, we might be surprised by improvements in health that could follow. But why end there? Perhaps there is a way to prevent some of the diminished capacities that accompany aging. What if we created virtual aging and virtual disease to enable people when younger and healthy to learn how better to cope with and overcome many of the symptoms they may eventually experience? Let’s go back to the assumption that as we age, our field of vision narrows and we become more sensitive to cold. A thirty-degree day feels different in February than it does in October, regardless of the sweaters we may wear. While we adapt to seasonal changes, we typically don’t adjust to age-related changes. If younger people, say in their forties or fifties, were exposed to a narrowing field of vision and increased sensitivity to cold, we could learn how to deal with these and other age-related changes while still feeling strong. Because the situation would be novel for us as younger adults, increased attention to variability in our reactions (a mindful response) could very well follow. With attention to variability comes an increase in perceived control, which in turn will make us pay more attention to the situation; an increase in mindfulness will increase health and increase our control over the symptoms. Having learned how to “deal with” age-related changes, we would be better fit to face our own aging. If we assume problems are a necessary consequence of aging about which we can do nothing, on the other hand, we do not expend the time or energy looking for ways to decrease or reverse them.

Sometimes the solution is right at hand, like the shelf described above, and we do not need to create virtual worlds. My grandmother would turn the thermostat up. My mother would turn it down. Each thought the other abnormally cold or hot, respectively, but since they both accepted that old people are generally the ones with the “problems,” my grandmother most often lost the battle of the thermostat. If they had not looked at differences in this way, they might have easily solved the problem by respectively putting on or taking off a sweater before having an argument about it.

Another reason why we need to attend to the fit between ourselves and our environments is because of the way we still mindlessly process environments when we are young adults. Often when we furnish our houses, we buy a table, a couch, some chairs, and a bed, for example. After we’ve lived with them for a short while, we cease to notice them, if we ever really did. We’re often too busy to devote much time to the subtleties of the items around us. If when we are older we are confined more or less to our houses, it won’t now occur to us to see these things in new ways. That is, initially we mindlessly learn to ignore our physical world because we are too busy. Then later, when we are unnecessarily left with too little to think about, it doesn’t occur to us to think about anything we’ve mindlessly previously understood. That doesn’t mean we have to mindfully engage everything even if we could. The alternative is simply not to learn about it mindlessly at the beginning, so in the future it could occur to us to think about it anew. For example, rarely do older adults think to change their rooms around to meet their current needs. The furniture stays put for life, and discarding the table they no longer use, for instance, never comes up for consideration.

Many of us have accepted that we have problems when in fact what may be going on is a poor fit between our lifestyle or occupation and the “problem.” For example, if a job required shifting among many things, ADHD might not be a problem. On the other hand, if we were very energetic, it would be hard to collect tolls all day. Before we conclude that we don’t fit into the world, it would behoove us to consider where we might fit better.





The Importance of Roles


I once slipped on a sheet of ice and found myself in the hospital for the next two weeks, recuperating from a smashed ankle. There I was a patient, a participant, an observer, and, when the pain passed, a psychologist. It was a very revealing two weeks.

It was six-thirty in the morning. I had already been in the hospital for several days, but this was the first one where the drugs I had been given didn’t affect my memory. A nurse came in the room and announced that she was going to take my vital signs. I said only one word to her: “Hi.” She immediately changed her demeanor, exclaiming that I was a breath of fresh air and had made her day. At first I was startled that such a small gesture of recognition on my part had such a big effect. Then I talked to her about it. She told me, not surprisingly, that people don’t like to be awakened and that most of the time they are very unpleasant when she had to do so. In these instances, patients treat nurses as the enemy. Nurses expect this and often preemptively act their part in the drama. In these situations, there are no people present, just patients and nurses, each enacting their role. Add a person and the drama changes for the better for both parties.

Another time, I rang the bell for help and a nurse entered and asked what I needed. As I began to tell her why I had rung, I realized that she was weighing my need against her availability, and this is most often the case. If a nurse is busy, she will find my request burdensome and she will resent the request. Patients, however, cannot know how busy the nurses are at any particular time. We ring the bell and wait, and eventually someone comes. If it takes awhile, the patient feels ignored and nurses feel put upon. Imagine instead that people took the place of nurses and patients.

Patient rings bell. Nurse enters.

PATIENT: “Hi, is it busy right now?”

NURSE: “Yes. Several nurses had to go to the second floor for some emergency. What do you need?”

PATIENT: “Can someone come help me get to the chair when they have a moment?”

NURSE: “Sure. It may be a few minutes, though.”



It’s going to take as long as it takes in any case. Now, however, the wait is met with understanding rather than mounting hostility. Or take the more difficult request for a bedpan to be removed. No one wants to do it, nor should they, but it must be done. If it is done in role, there is often resentment on the part of the aide and perhaps guilt or feelings of helplessness on the patient’s part. I said to a nurse in this circumstance, “I’m sorry, I wish I had another option.” She felt bad and said, “Don’t think twice about it; it’s part of my job.” She no longer resented my request, and I felt grateful rather than guilty.

One morning, the occupational therapist arrived and announced, “I am the OT. My name is Jane.” I replied, “Hello, I’m Ellen. What did you say your name was?” “I’m Jane.” By separating her name from her rank and serial number, she seemed more a person to me. The ensuing session was person to person. This is important because much of the advice medical people are trained to give is really one size fits all, and so to adjust it to our individual needs we need to feel free to ask questions, to refuse some of what we are offered in the way of help, or to ask for more if we need it. I wanted to do upper-body exercises while I waited for my ankle to heal. It wasn’t part of the program, and it would have been hard to ask the OT or PT to help me. It was much easier asking Jane.

Psychologist Adam Grant and I decided to put this idea to the test.7 Subjects were presented with a scenario and asked what they would do in that situation. Half of the people were presented with the following situation: You’re in the hospital, on a bedpan, and very uncomfortable. Your usual nurse is unavailable. There is another nurse outside your room. How likely are you to ask her for help? The other half of the participants were given this scenario: You’re in the hospital, on a bedpan, and very uncomfortable. Your usual nurse, Betty Johnson, is unavailable. There is another nurse outside your room. How likely are you to ask her for help? The only difference between the two groups is whether or not their usual nurse is named. Naming one nurse seems to have suggested that perhaps all nurses are people as well as nurses and that they could be approached more easily than nameless nurses. We found that when roles were replaced with a name, more people replied that they would ask for help.

There is an even more important reason to “pass the role” whenever we can, and that is that mistakes arise from mindlessness. If our interactions with others are not individual in nature, they risk unfolding in a mindless manner. Role-to-role behavior is rule-bound and normative; that is, a typical pattern of behavior is likely to be repeated. There are times when the rules should not be followed, but to notice these instances requires that we pay attention to the way this situation is different. This can be hard for medical staff, because they always see so many patients and tend not to distinguish among them, although it would be to their advantage. But it should not be hard for patients, because we typically are not always patients and we have fewer people to keep track of. And as with the staff, it is clearly in our best interest to do so. It is easier for us to stay mindful if we are who we are and not what our patient role may “demand.”

Once a nurse wanted to take blood to test my sugar level. I am not a diabetic person, and I politely questioned the need for the test. As a patient, I might not have. The nurse then realized that she had the wrong person/patient, and I assume she moved along to find the right one.





