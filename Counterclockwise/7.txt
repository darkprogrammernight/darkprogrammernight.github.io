CHAPTER 7





What’s in a Word?


Where is the wisdom we lost in knowledge?

—T. S. Eliot, The Rock





In 1979, at the age of fifty-six, my mother died of breast cancer. At least, that’s what the medical world reported. I’m still not sure. Before she died, her cancer had gone into “complete remission.” Had another cancer developed in her body quickly, or was it the same cancer back to haunt her? To this day, I don’t know what remission really means. Psychologically, however, remission suggests something very different from cure. Language has the interesting property of being able to increase and decrease our perceptions of control. Different word choices can direct our thoughts about a single situation in many different ways. If somebody has cancer and the cancer goes away, we say it is in remission. The implication is that the same cancer may recur. If that same cancer does not return, was it in “remission,” or has it actually been “cured”?

Now, contrast the language of cancer with that of a cold. We tend to speak of each cold we catch as a new cold. Each time we beat a cold, we become more persuaded that we can beat the next one. While there are surely similarities among the various colds we have had over the course of our lifetimes, there are also many differences from one cold to the next. “This time it started with a sore throat; last time it started with a stuffy nose.” Most of us are quite good at analyzing the progress of colds, but who decided we should pay attention to the differences—as most of us do—and not the similarities? Most of us are oblivious to the idea that there is any choice involved. We were simply led early on in life to believe that each new cold is different from the last but we can master them all. The psychological evidence for this is that our last cold left us at some point. We were successful at beating it.

With respect to cancer, however, being in “remission” means that we are waiting for “it” to return. If “it” does return, the recurrence is seen as part of the same cancer. Psychologically, this may lead us to feel defeated. For each new cold we beat, we implicitly think, “I beat it before, so I can beat it again.” If the cancer comes back, however, we think, “‘It’ is winning. I am just not as strong as ‘it’ is.” Surely the cancer will in some ways bear a similarity to the last cancer, but in other ways, it is just as surely different. Our language leads us to see the similarities in recurring episodes of cancer, while with the common cold we see the dissimilarities. Of course, the stakes are so much higher with cancer that there is even more reason to consider our language choices.

Ever since my mother’s death, I’ve been somewhat ambivalent about the medical world. I have turned to medical doctors when seriously ill, yet I think many underestimate the power of psychology to influence health. As we have seen, the psychological literature is replete with examples of the physical consequences of giving up. Even if one were not as persuaded by the experimental data as I am, it is clear that giving up affects health choices and keeps people from wanting to survive. Why exercise or take medication if one is likely to die soon anyway? Did cancer kill my mother, or did the language that we use to describe cancer lead her to give up?

A friend of mine was diagnosed with breast cancer, which is now in “remission.” She has every reason to believe that she is now fine, but even so, she is scared. When we talk about her cancer, all of the events surrounding my mother’s death vividly return to me. Would things have turned out differently if my mother had thought that her second episode of cancer was not identical to the first? Would my friend be more at ease now if we used the word cure rather than remission to describe her state?

My colleagues Aline Flodr, Shelley Carson, and I recently looked into the effects of language on the well-being of cancer survivors.1 We recruited sixty-four women from around New England who were participating in events such as the Race for a Cure and Making Strides walking events, women who had been treated for breast cancer but were now in a stable condition. We gave them several health questionnaires and a mindfulness scale to complete. One question asked them in which of two categories they would place themselves: in remission or cured. After we analyzed the results, we found that the “cured” group reported significantly higher general health, better physical functioning, fewer role limitations due to health, and less pain. There was also a tendency for them to experience more energy and less fatigue. Regarding their emotional health, they reported greater well-being and social functioning and were significantly less depressed.

When we looked at scores on the mindfulness scale, irrespective of whether they saw themselves as cured, we found that the more mindful a woman was, the better her physical functioning was, the more energy she had, the greater her overall well-being was, and the fewer limitations she had due to her emotional health. All in all, the results were impressive.

The same kinds of issues about language arise in the simple difference between characterizing an alcoholic as “recovering” instead of “recovered.” If an alcoholic has not had a drink in ten years, it seems odd to characterize that person as still recovering. The word recovering suggests that we are victims and helpless against our conditions.

We are told that alcoholics should view themselves as recovering instead of recovered, to remind them that they should not drink. It may be easier, however, to refrain from drinking when one feels strong. Recovering suggests that you’ve never quite beaten the problem. Recovered suggests conviction and strength. It seems to me that the stronger one feels, the less likely one is to revert to harmful behaviors.

What if we called alcoholism an allergy instead of a disease? If one had a severe allergy to alcohol, he or she might think twice about drinking. People who are allergic to shellfish typically don’t eat shrimp or mollusks. The word allergy suggests that the person who is allergic is in charge of treating it; the word disease offers much less control.

A new look at the language of medicine could have farranging implications. If I take Prozac or Paxil, for example, my depressive symptoms may go away, but I still describe myself as a depressed person. I am likely to attribute most of the relief I experience to the medication, but the misery always remains mine. If I take an aspirin to treat a headache, however, I believe my headache has “gone away,” even if I am regularly prone to headaches and likely to suffer another.

If antidepressants are effective in removing depression just as aspirin works to remove headaches, it seems to me that people on antidepressants should not see themselves as being depressed any longer. If there are no symptoms of depression, then it follows that there should be no depression, despite the fact that antidepressants are still being taken.

The labels we choose to apply may have positive as well as negative effects. Consider vitamins. Even though they come in pill form and may be taken to alleviate problems such as arthritis and fatigue, they are nonetheless thought of as “vitamins.” While we take “vitamins” to stay healthy, we take “pills” when we are sick. To my mind, “to be healthy” is not the same thing as “not to be sick.” Each time someone says they’re taking a vitamin, their perception of being healthy gets a boost. To take a “pill,” in contrast, may reinforce my perception of being ill.

We ought to consider using language to repackage our experience of our health and illness. The word painkiller implicitly reinforces the idea that we have no choice in how we interpret certain sensations. Pain, it seems is something to kill. To kill it suggests that it is a very big problem indeed and we are helpless without pills; instead we could take pain pills to erase the pain, rather than kill it. Be that as it may, “pain” consists of many different sensations. Instead of one big problem to be killed with pills, we could interpret pain simply as sensations. There may be an advantage to not naming our sensations but merely to experience them. If we did, we would see that they don’t stand still. They change. A headache may throb at one point while the sensations are barely noticeable the next. To notice the changes gives us a chance to control the sensations. Noticing the changes may also lead us to not need to exert any control. After all, the pain may subside on its own.

The way we use language encourages people with cancer, alcoholism, or depression to consider their disorders as an intractable part of who they are. Colds and headaches, by contrast, describe how we are at a particular time, not who we are. We might be able to improve “how we are” if we make decisions about what to call our ailments based on the differences from one episode to the next. If I enter the physician’s office with stomach pains, for example, I leave feeling somewhat better knowing I have “gastroenteritis.” Having a name for our disorders gives us some comfort. We have much more control, however, once we realize that a particular name and its implications are just one of several that could have been chosen. If it was not serious, it could have been indigestion, among other things; if serious, it could have been a result of an ulcer. Most of us remain oblivious to that choice.

The choices available to us become clear when we find ourselves in situations in which words are used differently than we are accustomed to, or when someone describes the same situation in which we find ourselves in a different way. Years ago, I tried a new dictation program for my computer. I had injured the middle finger of my right hand and, to get on with my writing, I decided to dictate it to the computer. When I spoke about my “gastroenteritis,” the phrase “Castro decided to invite us” appeared on the screen. When I spoke about a “belief,” it took me on a trip to “Belize.” The voice recognition software was programmed to suggest words without awareness of their context. We, however, can be aware of context and ought to choose language very carefully, especially when our health is involved.

We have a choice whether to see ourselves as in remission or cured, to call alcoholism an allergy or a disease—to open up the labels that describe our conditions to see what actually lies beneath the name.





Mindless or Mindful Labels


To be fair, labels help us organize our thoughts. The problems begin, however, when they determine our thoughts. Although we can learn labels deliberately or blindly, all too often it is the latter, which often results in what I’ve termed “premature cognitive commitments.” More simply, we mindlessly accept labels as fixed truths.

I’ve been studying the negative effects of premature cognitive commitments, or mindsets, for over thirty years. When colleague Benzion Chanowitz and I studied premature cognitive commitments we found that when we take in information without questioning it, we implicitly make a commitment to a single understanding of the information we have accepted.2 We treat it as true and it never occurs to us to question it, even if it would be to our advantage to do so. We often take in information we deem irrelevant in just this way. After all, why bother thinking about it if it isn’t important? The problem is that what may be irrelevant at one time may later become quite relevant. We take in information about diseases such as cancer or dementia when we are young and imagine that we will live a very long, healthy life. Later, when forced to confront them, the labels we applied can catch up with us and lead us to places we wouldn’t want to go if we stayed in charge.

In this research, Chanowitz and I invented a disorder that we called “chromosythosis,” which we explained could lead to diminished hearing. We told the participants we were going to test them for the disorder and gave them a booklet describing its symptoms. We did not, however, give everyone identical materials. Three of the four groups we worked with were given booklets that stated that 80 percent of the population had the disorder, which was meant to make the possibility of having the disorder more relevant. We also asked them to imagine how they might help themselves if they were diagnosed as having chromosythosis. The fourth group was given booklets that told them the disorder was rare, only 10 percent of the population had it, making the disease less relevant to them. We didn’t ask them to consider how they might deal with a diagnosis, all of which we hypothesized would lead them to process the information mindlessly.

They did, indeed. We gave all of them a “hearing test” for chromosythosis, which confirmed they indeed had the disorder, and then a series of follow-up tests for specific disabilities described in the booklets. Those for whom the disorder was less relevant, the mindless readers, performed less than half as well as the other groups on the specific follow-up tests than those who thought the material and our instructions to think about how to deal with it were more relevant to them. The way they first processed the information determined how they later used it.

Cognitive commitments can come in the form of a word to describe a single symptom or disease and can be deadly. Even as science is learning that cancer can be a chronic condition or even fully treatable, most of us mindlessly process the label that cancer is a “killer.” If later diagnosed with cancer, we may be more prone to give up, having accepted that our cancer is a killer, when the course of any particular cancer could be otherwise.

How many people trying and failing to have a baby are labeled “infertile”? The label makes the condition stable when for some it may not be. Once labeled infertile, the extreme disappointment may lead to depression and stress—neither of which is good for a relationship (and some doctors think that stress itself is a contributing factor to infertility). If the relationship suffers, sex may diminish, and with that the likelihood of conception decreases, making the diagnosis, in this example, a self-fulfilling prophecy.

Traditional medicine is characterized by a stepwise process involving a patient’s symptoms, the doctor’s diagnosis, and a subsequent treatment. Even before the diagnosis, the labeling begins. The patient is “one who receives medical attention, care, or treatment.” The patient is also defined as “one who suffers.” Soon the patient will acquire more labels; she will be identified as having “illness X,” the symptoms of which will be described further as “acute” or “mild.” The doctor may tell you that the treatment may be “risky.” These labels can be detrimental to both the patient and the future of medicine.

Doctors have been trained in the art of clinical diagnosis using language as a tool to classify particular sets of symptoms. Through the act of classification, the agent assumes control over what he is labeling. For example, in the diagnostic process, doctors may feel reassured professionally for having matched a certain set of symptoms to a specific illness. In naming the disease, the diagnostician has placed the uncertain, unpredictable symptoms of the disease beneath a comforting, familiar name tag. He feels secure, as though he had regained control over the menacing microbes. Diagnosticians tend to generate one or a few hypotheses very early on and thereafter the search for clues is likely to be guided by those hypotheses. With a hypothesis in hand, further information gathering may be constrained, thereby decreasing the likelihood that an alternative hypothesis will be considered and increasing the likelihood of an incorrect diagnosis.

Additionally, once a diagnosis has been made, it is inevitable that the nature of the illness will transform into its idealized form as described by medicine, which catches and tames the disease through language. A disease’s mere label has the ability to foster an illusion of control wherein immediately the expert begins to consider the disease as fixed and inert. In today’s high-pressure, fast-paced, modern health care environment, where doctors must work efficiently under pressure, it is easy to imagine that doctors often work mindlessly, using familiar diagnostic constructs and their corresponding courses of treatment. Atul Gawande writes in his book Complications, it is instead “an imperfect science, an enterprise of constantly changing knowledge, uncertain information, [and] fallible individuals.” Every individual is different, every pathogen is different, and therefore it should necessarily follow that every treatment strategy should be different. Yet, in modern medicine, this is rarely the case; Western medicine is embedded within institutionalized and standardized health care.

When I was an intern in the psychology department at Yale, people walked into the clinic and essentially by doing so labeled themselves as “patients.” At the time, I saw them this way as well. When we discussed certain behaviors they considered problems—say, anxiety, difficulty making a decision, guilt—I tended to label what they reported as “abnormal,” consistent with my use of the “patient” label. Later, when I encountered exactly the same behavior in my acquaintances—the difficulty making a decision or commitment, feelings of guilt, or fear of failure—it seemed odd to me to see the former as problematic and the latter as normal. I became interested in the way labels act as a lens and lead us to see and evaluate that which is seen, while at the same time leading us to ignore what might very well lead to a different evaluation. During that time at Yale, psychologist Robert Abelson and I conducted a study to test this effect.3 We made a videotape of a rather ordinary-looking man being interviewed about work. For half of the clinicians to whom we showed the tape, we labeled the man being interviewed a “patient.” For the other half we labeled him a “job applicant,” thus priming a different view of him. We showed the tape to Freudian therapists and behavior therapists. (Behavior therapists are trained to look past labels.) When the man was labeled a “job applicant,” both groups saw him as well adjusted. But the Freudians who thought they watched a “patient” saw him as poorly adjusted and in need of therapy. The behavior therapists saw “the patient” as well adjusted.

Labels lead us to go on hypothesis-confirming data searches. That is, we look for evidence to support the label. Since most information is ambiguous, the result is “seek and ye shall find.” The label “patient” leads us to examine behavior and life circumstances through a problem-finding lens. The label “patient” also leads us and doctors to search for illness-related symptoms. In both cases, behavior and sensations that could have been seen as typical fluctuations from the norm are interpreted as unhealthy. Moreover, independent cues of health may be totally ignored. The remedy here is actually rather simple. If we entertain the competing hypotheses “We are healthy” and “We are sick” and then go on hypothesis-confirming data searches, we will confirm them both with the result of a more accurate picture of how we are. We will have evidence that we are okay and perhaps also find evidence that we are not. We might see ourselves as generally healthy with a few nagging discomforts, or see ourselves as achy and uncomfortable chronically. Moreover, we might label what we find differently. A sensation that is taken to be an indication of a grave illness is likely to feel worse than one viewed on its own.

Psychologist Dave Rosenhan once conducted a startling study where he and his graduate students attempted to gain admission at a mental health hospital.4 Using pseudonyms, they arrived at the hospital complaining of hearing voices, auditory hallucinations being a hallmark of schizophrenia. In all other respects, they gave an accurate account of their lives, their relationships, and their experiences. After they had been admitted, they stopped complaining of hearing voices and tried to convince the staff that they ought to be released. It took from seven to fifty-four days, on average nineteen, for them to gain release. The staff discharged them with the diagnosis of schizophrenia in remission, although visitors to the ward reported that they had observed no psychological problems in the students’ behavior and other patients suspected that many were not patients at all.

Diagnosis and prognosis are words that carry special meaning for us. Patients ask, “What is the diagnosis?” or “What is the prognosis?” almost as if there were no people involved in formulating the answer. Of course, there are, and neglecting that fact greatly alters the effect of the answers. Compare the effect on a patient who hears “your prognosis is bad” with “According to this doctor, based on what he learned in medical school, your prognosis is bad.”

If our language were more attuned to the situation, I believe we would take more control over our health. We would be aware that medical facts are not handed down from the heavens, but in fact are determined by people under changing, different conditions. I don’t think I can say often enough that medical decisions rest on uncertainty—if there were no uncertainty, there would be no decision to be made. To reveal at least some of this uncertainty would mean that while our doctors may be knowing and caring, they cannot be all-knowing. They are subject to the same biases and value-based judgments as the rest of us. But doctors often feel they have to hide their uncertainty. In extreme cases, they still tend to “hang crepe” (referring to the black crepe hung at funerals): give the worst-case scenario, because if you say the patient will die and the patient lives, everyone is happy, but if you say the patient will be okay and the patient dies, lawsuits may follow.

In some sense, to label a person “terminal” may be the medical world’s most egregious error. Hank Williams sang, “No matter how I struggle and strive, I’m never gonna leave this world alive.” But the label “terminal” is used to predict premature demise. As we know, doctors can’t know when we will die and to tell us we’re “terminal” may be a self-fulfilling prophecy. There are no records of how often doctors have been correct or not after making this prediction.





Numbers


The medical profession has a habit of describing people through numbers. We have a blood pressure reading and quantifiable pulse; we can undergo an EKG or an EEG and get more numbers to describe our relative health. Blood work gives us more numbers still. This is efficient in many respects, but the point to be made here is that, like labels, numbers hide ambiguity. Numbers lead us to become people with high or low levels of cholesterol rather than people who are sad or happy, tired or energetic. We become our numbers and behave accordingly, not infrequently making them self-fulfilling prophecies. When I ask the audience in my lectures if they know their cholesterol levels, as I described earlier, those who answer have let their last reading create a very strong illusion of stability; they hold it still, although if asked they would say it is subject to ongoing, natural fluctuations. Their last level has such a strong hold on them that, despite the fact that I have just spoken at length about mindlessly confusing the stability of our mindsets with the stability of the underlying phenomenon, the demonstration never fails. Numbers can not only hide ambiguity but also objectify us, lead to self-fulfilling prophecies. Surely we are more than our health-related numbers.

Numbers also create the illusion of precision. Consider someone who is forty-two years old and someone who is fifty-four years old. What do we know about these two, other than the fact that the first person is younger? Do we know for sure if she’s healthier, more energetic, or more creative? Of course not. We know very little no matter what our reason for inquiring about their age in the first place.

Numbers exist along a single continuum and don’t convey as much information as we are led to believe. If a person has twice the number of cancer cells as another, what can we predict from just that information? Who will be sicker or die sooner? If the first person was very healthy to start and the latter very sickly, what would you predict?

Body mass index has become a very popular way to measure whether we are overweight. To calculate it, we divide our weight by the square of our height and then multiply by 703. It seems so precise. The only problem is that BMI was never meant to measure an individual’s obesity; it was really meant as a general measure of classifying individuals’ levels of physical activity. It doesn’t differentiate between muscle and fat, so for people with high muscle mass it isn’t particularly valid.

Numbers allow for social comparisons. If I have twenty apples and you have thirty apples, you have more. But what does this mean? Each of my twenty apples may be larger than any of yours, and so I have more apple. Yours may be riper, which could make them tastier or over the hill. The numbers don’t tell us important information we need to have to more accurately compare.

Researchers have developed a mathematical formula to predict a woman’s risk of osteoporotic fracture. The equation has proved 75 percent accurate and will allow physicians to tailor their treatment strategies to help women prevent fractures of fragile bones. While this may seem a great advance, the problem is that we don’t know if we are part of the 75 percent or the remaining 25 percent that the formula misses.

Numbers and the tests they represent are not useless. They are tools, and tools can be helpful if used mindfully to guide us and to give us ideas—not to govern what we do or do not do. But they only imperfectly predict our future health and thus should not determine who or how we are.





That Which Is Unspoken


Imagine that you just got your hair cut and a friend remarks, “Oh, you got a haircut.” Pause. “I like it.” Her pause makes you feel uncertain or even bad, but you find it hard to comment. After all, she did say she liked it.

The meaning of her remark was in the silence, not the words. And the silence was deafening. Likewise, the effects of silence exist in the realm of our health. Imagine that you’re eighty years old, visiting the hospital with your adult child. You speak to the physician and she responds to your child instead of to you. The message is clear: you’re incapable. You’re next visited by two physicians who examine you and then discuss your case with each other, leaving you out of the conversation. You’re objectified, and the absence of communication with you reinforces the idea that you are your disease.

Patients often cite the manner in which doctors speak to them as central to their decision to initiate malpractice suits. Researchers Nalini Ambady, Debi LaPlante, Thai Nguyen, Robert Rosenthal, Nigel Chaumeton, and Wendy Levinson looked at the effects of tone of voice in a medical context.5 The decision to sue a physician is no doubt a difficult one. Research suggests that part of the basis of lawsuits is complaints about interpersonal aspects of care. These researchers investigated whether the surgeons’ tone of voice was related to their malpractice claims history. They took brief clips from doctor/patient interactions during office visits, removed the content so that all that was left was tone of voice, and had them coded for attributes such as warmth, hostility, dominance, and anxiety by people who were unaware of the study’s hypotheses for warmth, hostility, dominance, and anxiety. They then examined whether there was a relationship between these factors and the physician’s malpractice history. When the surgeons’ tone of voice was judged to be not friendly and signaled dominance, they were likely to have more claims filed against them. We react to silence, tone of voice, and nonverbal cues even if we are not aware of it.

In research I conducted with my students we were interested in seeing what would happen if an “expert” nonverbally conveys confidence in the face of verbal uncertainty.6 To look at this, we directed instructors to be confident or unconfident, which was defined here as erect posture (or not), frequent eye contact (or not), and smooth speech (or not). They were then asked to give a sealed envelope to a friend or family member in which a relaxation technique was described in either conditional or unconditional language. The envelopes were sealed so that the instructor couldn’t bias the results since he wouldn’t know whether the person was in the mindful (conditional) group or the mindless (absolute) group. The friends and family members were told to open and read the contents of their envelopes. When the experiment appeared to be over, the instructor announced that he had a pain in his neck and asked the friend or family member what he should do about it. The major measure we were interested in was whether the person considered the information included in the relaxation technique in their response even though the technique had not mentioned the neck. More than twice as many people in the confident but uncertain group thought to use the information creatively.

What can we do in the face of a culture that quantifies virtually everything? We can remind ourselves what these words and numbers really do and do not tell us. And we can reassert the uncertainty that they hide. More than twenty-five years ago I collected data that I never got around to publishing that are relevant here. I asked elderly adults to participate in a study on language, pronouns in particular. One group was asked to increase the number of times they said “I” over a given week. Control groups increased the number of times they said “me,” “he,” or “she.” At the end of the week we then gave a brief questionnaire asking them how active they were and how much control they felt they had over their lives. The findings revealed that increasing the use of “I” led to an increase in perceived control and activity in this group. While language can subtly lead us to behave, think, and feel in ways not to our advantage, we also can intentionally choose our language to help us go in the direction in which we want to go.





