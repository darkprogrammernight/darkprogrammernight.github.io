CHAPTER 4





The Social Construction of Health


We don’t see things as they are, we see them as we are.

—Anaïs Nin





Suitcases in hand, all eight elderly men eventually made it to their respective rooms. While the rooms were not fancy, each man had his own room, and each room was decorated in a timeless fashion with an occasional object, like a piece of china or a vase, that was identifiable as from the 1950s. These details came as a surprise to our participants, as many thought they would basically be spending the week in a nursing home.

Until you spend time in a nursing home, it’s hard to imagine what living in one is like. The doors to individual rooms remain open at all times, everything is done for you and on a schedule that you didn’t choose—meals, when to shower, and where you can and cannot go are all out of your control.1 When I first began working with elderly patients in nursing homes, I was saddened by what I saw: people sitting around with little to do and no choice regarding virtually any aspect of their lives. When I asked why the doors to their rooms were open, I was told that it was a fire hazard to close them. I asked when the last time was that they had a fire and was told, “Never.”

The rooms at the retreat we chose afforded our participants all the privacy and personal responsibility they’d had twenty years earlier. They not only had choices at meals but were asked to participate in the preparation and clean-up. This week was going to be something different for them. Although we ensured their safety and watched carefully, they were essentially on their own.

Remember, when we designed the counterclockwise study, we tried to find the best measures to include to see if we could reverse or retard aging, but we came up short. We called several of the leading geriatricians around the country and asked, “If we had a seventy-year-old in one room and a fifty-year-old in another and could take any measure of those people, which criteria would you trust to know who was who with confidence?” Again, the answer was that only chronological age would confidently reveal the difference. Age begs for reinterpretation. Why do we conflate sickness and debility with old age? Why do we presume diminishment to our senses, sexual appetite, balance, and endurance past fifty? Who said so, and how do they know it to be true? Currently, many believe a sixty-five-year-old is too old to run for public office, too old to adopt a child, and too old to play singles in tennis. At age eighty, many are thought to be too weak to be on their own, too feeble to cook for fear of leaving the stove on, too unbalanced to ride a bicycle, and too delusional to be trusted if they think whatever ails them will get better rather than worse.

Overhearing the research participants talk amongst themselves at the beginning of the retreat made it clear that to a man they accepted these ideas and were all too aware of their “limits.” They ate only the food they “knew” they could easily digest, and because they thought that their taste buds had diminished, they resisted being adventurous in their food choices. Although free to do as they pleased, they didn’t even consider engaging in physical activities except those that were acceptable based on their medical histories. When John slept a little longer than he was used to and Paul was asked to do his own dishes despite his arthritis, they were initially anxious. Fred was a bit different and goaded some of the others into doing more than they were used to doing. To their surprise, everything fell into place. Instead of presuming they “couldn’t” do something, they “got with the program.” Where did their ideas about possibility, or more correctly impossibility, come from?





None of Us Is “Us”


Every day we learn that something we accepted as true the day before is now false. It used to be that butter was better. Then margarine was the only way to go. Now butter is back, but olive oil trumps them all. Any attempt to keep up with all the new medical findings is stressful enough that it’s likely bad for our health. It’s like a scene from Woody Allen’s Sleeper, where upon awakening from a very long sleep, the protagonist discovers that everything bad is good again.

“Take that weight off or you’ll be sorry.” This bit of health advice is partly responsible for the diet craze omnipresent in our culture and provides some with an excuse to take dangerous drugs to help the process along. For years being overweight was seen as a psychological failure, the result of a lack of willpower. Over time, researchers began to look at the genetics of weight and found that something more might be at work—the more than fifty genes that regulate how much we eat, how active we are, and how well our bodies use calories. Then fat got even more complicated. A study showed that even twins fed quite similar diets could have very different weights. For them, at least, weight gain didn’t appear to be tied to how much they ate nor the genes they inherited.

If it’s not lack of will and not our genes that cause us to gain weight, maybe there’s something else at work? A study of the influences of viruses on weight gain by Richard Atkinson and Nikhil Dhurandhar found that 30 percent of their obese subjects had the antibodies for a common type of adenovirus (which can cause minor illness that most of us hardly notice), while only 11 percent of the leaner subjects had them.2 Overall, those who tested positive for the antibodies weighed significantly more than those who hadn’t been infected. Further studies showed that it wasn’t that fat people were more easily infected or that genetic factors were at work. Perhaps being fat in and of itself is a disease? Not so fast, say other researchers; there’s no proof yet.

So, what are the facts about being overweight? Is it that we can’t push back from the table soon enough, or is our desire for food programmed into us? Did we catch it, or is there something else at work? Why we gain weight, it turns out, isn’t nearly as simple as most people imagine, and scientists aren’t at all sure what answer to give us. It might well be that weight is due to a number of factors that differ for each one of us.

We’ve already touched on this kind of mindless consumption of health information in the first chapter. While it is tempting to blindly follow medical advice, it’s difficult to do so when the facts keep changing. It’s not science’s fault; the data on which much medical advice is based are incomplete in many respects. Our bodies are complex, interconnected systems of biological processes that interact differently under the influence of the unique genetic coding and environmental factors that we each possess and experience. There is no practical way to introduce just one of these factors into a medical experiment, and no researcher would want to try. They would only face an impossible task of trying to make sense of the inordinately complicated results in looking for the causes and effects.

If we are to become good stewards of our health, we need to be certain that we have the necessary facts about it. Medical science has much to offer us. But it’s not perfect, and until we appreciate the nature of how science constructs facts, we can’t learn to take control of our health. We can’t know everything about our health, but we can develop a mindful understanding of health through an appreciation of how medical knowledge is developed and applied. While it is tempting to mindlessly follow medical advice, it may become less so after a careful consideration of the incompleteness of the data on which the advice is based.

The instruments used to assess our health have all been created by people and thus are not perfect. The science used to assess them is probabilistic. Perhaps these diagnostic tools do predict successfully for the group, but none of us is “us.”





Necessary Facts


From 1996 to 2006, the number of people seeking psychotherapy increased 150 percent, and that has put pressure on therapists and clinicians to categorize and make sense of the increased number and variety of problems in the people who seek their help. In his book Healing Psychiatry, Harvard psychiatrist David Brendel addresses some of the problems of applying science to mental diseases and the myth of “psychiatric scientism.”3 He notes that patients often just don’t fit the diagnostic categories that clinicians use. People are too complex to fit neatly into them. The problem, as his colleague Steven Hyman describes it, is that “we have no equivalent of blood pressure cuff or blood test or brain scan that is diagnostic.”4 Indeed, scientific investigations yield probabilities that are translated by researchers, textbook writers, the media, teachers, and so on into absolute statements that are easier to talk about and teach. This leads us to think we know more than we do. Virtually all science is treated this way, with increasing simplicity.

Much of the diagnostic information on which we so readily rely when treating disease also struggles with the same simplicity-over-complexity issue: the “objective” medical measures that are used are equally suspect. Hypertension, for example, affects about fifty million Americans and is implicated in problems such as strokes, aneurysms, heart failure, heart attack, and kidney damage but can easily go unnoticed. Moreover, as physicians Sidney Port, Linda Demer, Robert Jennrich, Donald Walter, and Alan Garfinkel note in an interesting study, there is still serious debate over the exact relationship between blood pressure and mortality or even the efficacy of lowering one’s blood pressure.5 As a result, 30 percent of patients treated for hypertension may be treated inappropriately. We overlook these problems because our instruments and blood pressure charts seem so objective: a systolic reading of 140—159 indicates mild hypertension; 160—179, moderate; above 180, severe. The early stages of some of these diseases are characterized almost entirely by our measured blood pressure.

A profile of a disease may be able to tell you how to identify it, what symptoms are commonly experienced by those with it, how the disease typically progresses, and what treatment has been shown most effective for the majority of those whose experiences with the disease have been recorded, but a profile based on averages cannot tell you about our moment-to-moment experience of a condition.

Biologist Jeffrey Gordon has a fun illustration that shows how each of us can respond uniquely, in this case using a morning bowl of cereal by way of example.6 A box of Cheerios tells us that a one-cup serving contains 110 calories. But it may be that not everyone will extract 110 calories from a cup of Cheerios. Some may extract more, some less, depending on the particular combination of microbes in their guts. “A diet has a certain amount of absolute energy,” he explains. “But the amount that can be extracted from that diet may vary between individuals—not in a huge way, but if the energy balance is affected by just a few calories a day, over time that can make a big difference in body weight.”

Our belief in science not with standing, human psychology and physiology are too complex for us to trust that the medical world is infallible. What we have to work with are correlations between observations and diseases. But the correlation is far from perfect. Scientific investigations, again, yield probabilities, not absolutes. These probabilities are translated by researchers, their textbooks, the media, teachers, parents, friends, and business managers into absolute statements that are persuasive and easy to convey. As learners, we accept what may be true under some circumstances and apply it as though it were truth across all circumstances. If instead we had been taught that something was likely in a certain context rather than definite in all, we might be less inclined to treat facts mindlessly. We would find it easier to question and rethink facts when it is in our best interest to do so.

A doctor’s diagnostic tools can predict successfully across a large group of patients, but again, none of us is “us.” Because findings are not absolute, subtle changes in any number of the variables that were in the original investigation could result in very big differences in the results. If we want to test a medication to see its effect on muscle strength, for example, someone has to choose the subjects, frame the information given to each participant in the study, decide what doses to test, and determine what time and under what circumstances to administer the drug. Then someone has to decide what constitutes acceptable levels of muscle strength. There are countless decisions such as these that go into every scientific study conducted. They are the “hidden decisions” that shape medical knowledge.

Again, a doctor may be able to identify a disease and describe its symptoms, how the disease typically progresses, and what treatment has been shown most effective for the majority of those whose experiences with the disease have been recorded. But she cannot predict the particular quality, location, intensity, and duration of the sensations that individuals experience, in specific parts of their body, at any given time and over time. She cannot tell you how particular individuals perceive these sensations and how closely they pay attention to them. She cannot describe what individuals are thinking or how they are coping, including their attitudes toward their condition, body, and prognosis. She cannot tell you where the individuals are or about their individual choices and behaviors at that time. In short, averages, at most, can only tell you what people tend to report experiencing and what tests tend to identify, but they do not tell you about the person.

Diagnoses, prognoses, research methods, and statistics are all necessary for efficient, ethical, and meaningful medical care, but in light of the inherent uncertainty due to variability, medicine, like all domains of study, should be regarded not as a collection of answers but rather as a way of asking questions.

Finding the questions to ask is not easy, because the facts keep changing. While exercise is surely good for us, a very recent study by Fiona Chionh, a medical oncologist, found that women who exercised a great deal were more likely to develop ovarian cancer.7

Exercise is good and yet exercise may be bad. Facts change. Information doesn’t stand still, and this is not the fault of medical science but a reality for science in general. Let’s consider the complexity of the issues involved in understanding the body. Any part of the body may affect any other part due to multiple genetic and environmental issues. An unusual allergy to pistachio nuts, insects, cleaning supplies, certain flowers, et cetera could have an effect on us. A slight imbalance in our shoes, the backpack we carry, or a reach behind a couch for the pen we dropped could do the same. Every day there are mundane experiences that put us in contact with things that could cause us problems, problems that for some of us—due to genetic vulnerability, for instance—could throw us over the proverbial edge. There is no way to factor all of this into any experiment.





A Limited Relationship: Correlation


While statistical concepts are not everyone’s cup of tea, we need to take a moment to understand and appreciate the effects of two important concepts—correlation and regression—with regard to our health. Every statistics book ever written contains the phrase “correlation is not causation.” It’s actually a simple concept: A correlation between two pieces of information means that they are related. If the correlation in the measurement of two phenomena is positive, when the measure of one goes up, so too does the other. If the correlation is negative, their measures move in opposite directions. This does not mean that one is causing the other, however. A frequent need to urinate is correlated with diabetes, but needing to use the bathroom many times a day does not cause diabetes (nor does it mean you already have it). Correlations are rarely if ever perfect. If the correlation is statistically significant, most of the time the two factors are predictably related. What that also means is that sometimes they are not related and one factor cannot predict the other.

Not appreciating the difference between correlation and cause can have real effects. If we have a tumor, and if tumors are correlated with premature death, it cannot be said that our tumor will bring about our death. To be able to draw that conclusion, we’d have to conduct a scientific experiment that proved causation. Because of the number of variables at play, it would be very difficult if not impossible to conduct a study in a way that isolates causation clearly. It is also the case that our expectations are very important to our health. If we expect that the tumor will necessarily lead to our death, we may give up hope, and it may be giving up hope that results in our death, not the tumor.

Recent findings show that girls who are overweight before they become teenagers are more likely to be obese and have a higher risk of heart disease as women.8 This finding may lead some girls to eat more healthfully and exercise more. So far so good. There may also be girls who learn this but fail to lose weight, even if they try. When they cannot lose weight they may, in essence, give up in the face of the information and consign themselves to their fate. They may even eat more out of fear and frustration. Thus the indirect effect of the information can be to lead some to unhealthy behavior. The medical world is only slowly acknowledging the importance of these effects.

Psychologists have conducted insightful studies of the effects of placing animals in situations where they are helpless. Important work by Martin Seligman and others on learned helplessness, for instance, found that many animals that give up actually die prematurely.9 Seligman and his colleagues put three groups of dogs in harnesses. The control group was simply put in the harnesses for a period of time and then released. The other two groups consisted of “yoked pairs.” The first group of dogs would be intentionally subjected to an electric shock, which each dog could stop by pressing a lever. For a second group of dogs, each would receive the same amount of shock as the dogs in the first group but their levers were useless; the dogs had no control over their pain. The first group of these dogs, the ones who could turn off the shock, quickly recovered from the experience, but the other dogs learned to be helpless, exhibiting symptoms similar to chronic clinical depression.

Next, the three groups of dogs were tested in a shuttle-box apparatus, in which the dogs could escape shocks by jumping over a low partition. For the most part, this last group of dogs, who had previously “learned” that they had no control over their fate, just lay down passively and whined. They didn’t even try to escape the shocks.

Similar helplessness experiments have been conducted with rats.10 The rats were restrained until they gave up trying to free themselves and became limp, and then they were placed in ice water. Rather than swim for hours, as those in the control group did (those that had not been restrained), they died soon after entering the water. Autopsies revealed that their deaths were parasympathetic. That is, they died peacefully, simply turning themselves over to their fate.

Humans demonstrate similar effects arising from positive or negative attitudes. Seligman, Christopher Peterson, and George Vaillant reanalyzed the responses to a questionnaire given to a group of Harvard men in 1946, when they were age twenty-five.11 From the men’s statements the researchers characterized each as having either a positive or pessimistic style of explaining the events of their lives. The study tracked the health and medical histories of the men for thirty-five years, and Seligman and his colleagues found that while both groups enjoyed about the same degree of health until age forty-five, those with a pessimistic explanatory style experienced poorer health between ages forty-five and sixty.

Another interesting study looked at the Chinese cultural belief in fate.12 In examining the death records of adult Chinese Americans, the researchers found that Chinese Americans who had a combination of disease and birth year that Chinese astrology and medicine consider ill-fated were more likely to die. For example, 1937 was a fire year, and the heart is the body’s organ associated with that year. A Chinese American born in 1937 was more likely to die of heart disease than another born in a non-fire year. Was the relationship causal? We don’t know. All we have is an interesting and suggestive correlation.

As important, our attitudes can bring about positive effects. Psychologist Sheldon Cohen and his colleagues did some very interesting work in this area.13 They gave subjects questionnaires to assess emotional style and then, with their permission, quarantined them and exposed them to viruses that cause colds or flu. They found that happy people get fewer colds and flu. Regarding attitudes, here may be one area where the elderly may be superior to their younger equals. Psychologist Laura Carstensen has found that older adults are less likely to see things negatively.14 That should make them happier and have a positive effect on their health.

Psychologists Michael Scheier and Charles Carver found a correlation between optimism and recovery from coronary artery bypass surgery.15 Others have studied how attitudes affect recovery and found that this improvement is not a function of a patient’s tendency to deny that he was ill. Those who hold optimistic beliefs actually pay greater attention to their recovery, and in so doing they aid the recovery process and help anticipate complications. This optimism is highly correlated with mindfulness (and also may be causally related). It is well-known that people who are very ill often somehow hold on until important events take place and then give up afterward. Similarly, when one member of an elderly couple dies, the surviving spouse is more likely to die soon afterward.

The consequences of giving up are quite real. When we learn a correlational finding—say, that cancer kills—and mindlessly accept it as necessarily true, then a diagnosis of cancer may unwittingly lead us to see ourselves as victims of self-fulfilling prophecies. Perniciously, any psychologically induced death that occurs only confirms the prediction—“Cancer is indeed a killer”—as if the original correlation were true for more of us than may indeed need to be the case.





Extreme Changes: Regression


Regression is the next statistical concept that we need to understand if we’re going to become mindful health learners. Regression refers to the fact that behavior, feelings, and events vary around their own mean. If I hit a wonderful serve in tennis—a noticeable event for me, because it is so unusual—my next serve will probably be less good, closer to my average serve. The same phenomenon is in play if I hit a serve that is unusually bad: the next one will probably be better. Statisticians refer to this effect as “regression to the mean.”

Regression to the mean is the reason why we are inclined to think that punishment is a more effective response than reinforcement. We notice the extreme. If you compliment my excellent serve, the next one will likely regress to the mean and be worse, and I may presume it is because compliments always throw me off. If you make fun of my bad serve, the next one is likely to be better and I may think I’m reacting to your negative comments and that my improvement is caused by a response to the negative comments—“I’ll show you,” in other words. Of course, one complication in all this is that sometimes we actually learn. Now the question becomes, Was my next serve better because I learned something about how to serve or was it because of regression to the mean? We don’t know.

Ironically, the natural process of regression to the mean often makes whatever medical remedy we try seem to work. Because he had success with it, Francis Bacon believed that warts could be healed by rubbing them with pork rinds. George Washington believed that various bodily ills could be cured by passing a pair of three-inch metal rods over his body, and virtually the entire medical profession in Colonial times believed in using leeches for bloodletting to restore health. (George Washington, unfortunately, died after nine pints of blood were drained from his body in one day to treat a throat infection.) It’s easy to think of Bacon, Washington, and their doctors as unscientific, but we ourselves use the same form of reasoning all the time. Again, we only notice the extreme. I felt kind of achy a couple of days ago, but now I really feel worse than usual, so I’d better take some medicine to help me get through it. The next day I feel better, so those medicines must be wonder drugs.

Because we didn’t pay much attention to our minor symptoms a few days ago, when we note the more severe symptoms and take action, we probably will feel better in the near future. Is it because our symptoms have regressed to the mean or is it the medicine we took? Sometimes the medication does the job; sometimes it gets credit erroneously. In either case, it’s not easy to know which is correct.





Symptoms as Cues to Disease


While a mindful learner ought to be attentive to what her body is telling her, distinguishing between that which demands attention and that which ought to be ignored can mark the fine line between being mindful and being a hypochondriac. At what point does a sensation become a symptom? Certainly, the longer it takes to recognize a symptom, the bigger a problem it may become. And yet if every unusual feeling sent us to seek advice, we’d have no time for life. What sensations do we want to consider symptoms and who makes the final decision? After how long or at what level do I call a pain a problem? We need to look at symptoms more carefully, with regard to both how we ourselves perceive them and how the medical world treats them. It turns out that symptoms are imperfect cues to disease; the correlations between the two are not perfect.

There are two very different kinds of symptoms that we treat as one, although it might serve us better if they were decoupled. There are direct symptoms that are self-evident, such as aches, pains, and fever that we observe for ourselves, and there are indirect symptoms, including blood pressure, heart rate, cholesterol, and blood sugar, that are measured by medical tests. The former are salient, demand our attention, and may be seen as their own disorder rather than as indicative of other problems. The latter are the symptoms given to us by the medical world to monitor our condition and warn us about impending problems. We’ll start with them.

Many indirect symptoms present imperfect cues to disease. Let’s look at cholesterol level and its correlation to heart disease, for example. Research reveals that symptoms such as high cholesterol are related to heart disease, but not everyone with high cholesterol will have a heart attack. While the correlation between high cholesterol and heart disease is a meaningful one for many people under circumstances similar to those in the research, it may or may not be so for any of us individually.

Assume that my cholesterol is very high, which suggests that I may be heading for a heart attack or stroke if I don’t lower it. That information alone is stressful—which itself is not good for my health—but I proceed on the quest to lower my cholesterol level, to the exclusion of all else. (Of course, ignoring everything else makes me more vulnerable to every other disorder that is not immediately related to my level of cholesterol.) Let’s assume I take medication and lower my cholesterol. My stress about my cholesterol goes away and now I don’t worry so much about heart attacks.

It’s like putting in a fire alarm system. I install the system so I don’t have to worry about fires. With it, I can ignore the issue; the alarm system will do the work for me. Mindless to subtle cues, I may be caught unaware when the system fails. This reliance on external “devices” can lead me to be less in tune with my environment—internal and external—such that I don’t notice a whiff of smoke that I might have noticed before the system went in. When I begin to take cholesterol medication, I don’t want to become less in tune with my body such that I neglect or dismiss the first signs of a heart attack.

The problem with correlational research on cholesterol level and heart disease also shows itself when we consider those of us with low levels of cholesterol. Since low cholesterol is not associated with heart problems, people with low cholesterol may believe they don’t have to be concerned about heart attacks. Since the correlation between cholesterol levels and heart attacks is not perfect, some people with low cholesterol levels will have heart attacks, but this group will be caught totally by surprise. This doesn’t mean we shouldn’t take measures such as cholesterol and blood pressure. What it does mean is that we shouldn’t mindlessly rely on them. It would be more to our advantage if they guided rather than governed our thinking. I want to be clear that I am not arguing against medical tests. I am arguing against mindless reliance on them and the mindless state that they can lead to.

We also need to be aware that the way doctors frame the information they give us can have a powerful effect on our choices.

In a wonderful discussion of breast cancer screening in his book Calculated Risks, Gerd Gigerenzer describes four ways the data on mammography could be sensibly presented.16 The physician could describe the relative risk, in which case having a mammogram would reduce the risk of dying from breast cancer by 25 percent. This does not mean that 25 out of 100 lives would be saved. As he explains, if we compare 1,000 women who had a mammogram with 1,000 who didn’t, and 3 in the first group died compared to 4 in the second, the decrease from 4 to 3 is 25 percent and the difference in lives saved is much smaller.

Second, the physician could present the absolute risk reduction, which in this example is 1 out of 1,000. A third way to give the information would be to state the number of women who need to be treated to save one life. Here, that would be 1,000 women. Finally, Gigerenzer suggests that we could convey the increase in life expectancy that results for women ages fifty to sixty-nine who have mammograms. Surprisingly, we increase our life expectancy on average by only twelve days. Given the first but misunderstood presentation of the information, we’d be likely to get a mammogram, but given the last one, perhaps not. Framing matters, but physicians themselves are often blind to the different ways of framing medical findings. One could argue that it can’t hurt to have a mammogram, so perhaps all the doctors need to do is present the first alternative. However, among other costs is the possibility of false positives—where the mammogram erroneously suggests there is a tumor. This is not a psychologically inconsequential result for the recipient of such news.





Hidden Decisions


The medical world must make decisions every day that are based on incomplete data and subject to the hidden decisions that shape the knowledge they use and deliver to us. A doctor’s job is anything but simple, and it isn’t as uncomplicated as it can appear.

Let’s say that we need to have a tissue biopsy that might reveal that we have a cancer. Most of us expect that the procedure is definitive and without ambiguity. We arrive at the hospital, the biopsy is performed, and the tissue is sent to the lab. We expect that it will be easily determined that we either do or do not have cancer. But cancer cells do not come with labels. Someone has to examine each cell and decide whether it is a cancer cell or not. How easy is it to call one cell cancerous and another one healthy? The pathologist and the attending physician must consider any number of important questions.

How large a sample do I need to reach an accurate diagnosis?

What percentage of cells needs to be seen as cancerous for the patient to be diagnosed with cancer?

When was the sample taken and under what conditions and by whom?

If I detect cancer, what treatment do I suggest, based on what norms, and developed by whom?

Who decides what the best treatment is, and how would it be different if someone else were to do so?

How much do I tell the patient?

How negative or positive should I be?

How confident am I of my assessment?



These are just a few of the hidden decisions that are made every day and we haven’t even gotten past one step in the medical process. The difficulty continues until the last set of questions has been addressed.

No two cancers are alike, so it’s important to consider what a diagnosis of cancer means. A frequent method of diagnosis of cancer is a microscopic analysis of cells, also known as cytological confirmation. Included in the analysis is a blood or bone marrow smear, or aspiration or scraping of cells. People then have to make a decision: how many abnormal cells do there have to be to indicate “cancer”? A cytology technician can examine tens of millions of cells a day in the search for malignancies. Whatever cutoff point is used to decide that someone does or does not have cancer, some people will fall just below this number.

It doesn’t matter what the cutoff point is. There will always be some who fall just below that point and others just above it. A group of people with their own understanding of what is correct made the decision in the face of uncertainty—and the result for those who fall just above it can be devastating, just as those who fall just below it may become overly optimistic. Despite the fact that people in the first group may be very close to those of the second, they may face a course of treatment that is difficult and unsettling. In all cases, someone makes a decision that could affect their entire lives. It’s not just our health at stake, these decisions can upturn our emotional, social, and professional lives. IQ test scores, for example, have been used as the basis for classifying people’s abilities far beyond their accuracy. A score of 80 is not statistically different from a score of 79, although the label that attaches to the lower score would certainly have lasting, negative effects if it’s mindlessly imposed on us.

Doctors make these decisions based on the best science possible, and it is often very good science indeed, but there are any number of hidden decisions that go into medical research. There are only so many people who can participate in a study. Those people who never find their way into the study are excluded from consideration, as are those who recover on their own.

When researchers say that the research participants were drawn at random from the general population, what does this really mean and what difference might the differences make? Harry is a multimillionaire, while Jane is struggling to find the money to feed her four young children; Arnie hasn’t left the house for days for fear of having to socialize; Linda won’t even answer her telephone because she’s always pressed against an important deadline. The very wealthy, the very poor, the very shy, and the very busy are not as likely to be included in experiments, and that limits our knowledge about the “general” population. When our health is compared to norms, we need to ask on whom these norms were based. Norms are always more ambiguous than they seem. We have a norm for how much sleep we need, for example. Over $2.5 billion was spent on sleeping pills in 2006. It leads me to question whether the norms about how much sleep we need may be inaccurate and whether we need to ask, “Needed for what?” rather than accept that so many of us are sleep-deprived.

When a study is not based on a robust, truly random sample of the population, the data are less trustworthy. One recent study of more than seventy thousand women—a very robust sampling—shows that older women who take hormone pills that combine estrogen and testosterone more than double their risk of breast cancer.17 All the seventy thousand women in the study also happened to be nurses, which qualifies the robustness of the sample—an increased risk of breast cancer may be specific to nurses rather than the general population. Are those women who choose to become nurses more similar to one another than to the general population of women? And if so, is this similarity an important risk factor? We simply don’t know, which is why scientific research is an almost constant search for better truths and not “the truth.” We can ask whether a sample is ever really truly random, such that pygmies and professors are equally likely to be represented.

Subject selection is just the beginning of the set of decisions that go into the social construction of our health. At each stage of the medical process, from diagnosis to treatment, something must be left out, leaving much room for error. Disease aside, the same questions of who is deciding, based on what criteria, and how things would be different if someone else made the decision come into play in regard to notions of all aspects of health and well-being. Mix together cultural norms and patient attitudes, and suddenly the limitations of medical research and our health, in the broad sense of how we as individuals actually experience our lives, are as much a matter of “says who?” as of expert science.

Becca Levy and I conducted a study to explore whether cultural attitudes and stereotypes about old age might contribute to physical decline that is associated with growing older, in this case memory loss. We wanted to compare the stereotypes many of us hold with the attitudes of people who generally don’t have negative stereotypes about old age. In order to look at people who weren’t burdened by such stereotypes, in addition to a random sampling of young people and adults with normal hearing, we recruited young and elderly members of two communities—the mainland Chinese (where elders are held in high esteem) and deaf Americans (who don’t generally share the hearing world’s negative views of old age). We gave each group a questionnaire that asked, “What are the first five words or descriptions that come to mind when you think of someone old?” As expected, the Chinese and the deaf were less likely to mention memory loss than the other groups. The research question for us was whether this absence of a negative stereotype for memory loss would lead to better memory for the elders in these groups than for mainstream U.S. culture. Or, to put this another way, we hypothesized that negative stereotypes about memory adversely affect memory.

Because these two populations have so little in common other than their regard for the elderly, we reasoned that similar responses on memory tests would give weight to our view. Our hypothesis was that if negative views contribute to memory loss in old age, and the Chinese people and deaf Americans hold more positive views of aging than Americans who have their hearing, mainland Chinese and deaf Americans should show less memory loss with aging. We compared the performance of mainland Chinese and deaf Americans in memory tests and found that while younger people from the groups all performed equally well, the older mainland Chinese and older deaf Americans tested better than older hearing Americans. If memory loss in old age was determined primarily by biology, older subjects would be expected to demonstrate the same memory skills.

The results seem to indicate that age-related changes in our health do not inevitably mean decline. Research on memory loss in general bears out this conclusion. Though some researchers have argued that such a decline is inevitable and have documented consistent trends to that effect, others believe that some aspects of the deterioration of memory may be environmentally determined, shaped by expectations and social contexts. Admittedly, as with all research, we made decisions as to the parameters of the study: for example, of all possible subcultures in the world, we chose two based on our understanding of their lack of bias in this area.





Mindless Labels and Mindful Decisions


Whatever our condition, the cues in our environment that prime our symptoms and the symptoms themselves change from day to day and even hour to hour. The question we face is to decide which symptoms are the “real” ones and which are socially constructed. Should we simply let others decide no matter what the consequences?

Consider the direct symptom of “chronic pain.” How often does something have to hurt before the pain is considered chronic? Once a day for ten minutes? An hour? Every other day?

How intense does the pain have to be? Who decided? How did they make this decision? The decision is not trivial. Once our pain is labeled “chronic” we expect it to occur and we overlook instances of its nonoccurrence. It is in these nonoccurrences that our control lies.

We experience symptoms directly or indirectly, and if the symptoms are intense enough, the medical world then tries to find a label for them. It is easy to see the advantages of symptom labeling; after all, it helps us create a common experience. If I have stomach pains, go to the doctor, and am diagnosed with gastroenteritis, several things result. First, I feel validated that the pain is real and not psychosomatic. I can also more easily talk to people about my disorder, and with a name comes the belief that I am not alone in this experience. With the belief that others have this condition comes the belief that relief, if not immediately available, may soon be found. Finally, there is a benefit for the medical world—different groups of researchers can more easily all study the same problem, possibly finding a treatment more quickly.

The disadvantages of symptom labeling are more subtle. Most important among these subtleties is the way labels lead us to give up control. This happens in several ways: Labeling promotes excessive dependence on experts and technology. It also leads us to compartmentalize ourselves, such that health cues from other parts of our bodies are more likely now to be neglected. A label leads us to accept as stable something that in fact is ever variable. Once we as individuals or a culture believe we know what something is, we are less likely to look at it anew.

Labels lead us to draw distinctions between what fits and what doesn’t. For instance, the medical world has given us two labels for our symptoms: “real” and “psychosomatic.” The distinction itself promotes reliance on the expertise of others once we accept it, even though to us, we feel the same in both cases. The distinction, while perhaps useful in some ways to some people, is still potentially harmful. In one sense, all disorders are psychosomatic; all pain is psychological.

The diagnosis that a condition is “psychosomatic” means that medical science believes it cannot help us. It does not mean the pain is not real. But because persistent pain often engages us in a battle to show “them” (doctor after doctor) that it is real, we give up our control. In fact, if we notice when the pain diminishes, we might figure out how to control it when it is present or just let it continue diminishing.

Many disorders that now have “respectable” names were at one time deemed to be psychosomatic—and the person with the disorder often considered a hypochondriac. Before we had an understanding of arthritis, someone who complained about pain in her fingers, pain in her neck, and pain in her knees might have qualified as a hypochondriac. The first thing, then, to note about hypochondriacs is that the future may give a name to their symptoms and thus free them from that pejorative label. Second, there may be clues in their symptoms that, if taken seriously, could reveal something systemic. If, for example, we kept track of the things people complained of and found that certain symptoms appear together, we might discover a new disorder or a new way of looking at an existing one. Thus, several of the disorders that are seen as psychosomatic today may be labeled as “true” diseases tomorrow.

Few, if any, would dispute the fact that our psychology plays a part in our reaction to and the course of our diseases. The only question is how large a part. The answer is that we cannot really know. If we assume it is a large part, the perceived possibility of controlling our bodies increases exponentially.

How would things be different if we viewed all disease as psychosomatic? If this were the case, it might seem unreasonable and perhaps irresponsible not to try to heal ourselves. We have mistakenly been convinced that our bodies are separate from our minds. Many of us admit that we don’t know much about our biology. Few of us, however, believe that we have no control over our minds.

Whether or not it is important that we label disease, we need to ask who does the labeling. Consider erectile dysfunction and those responsible for deciding whether this is a disorder for which medication should be prescribed, and thus whether insurance companies must pay the bill. If the decision makers at the insurance companies were all women, we might get a very different result than if the deciders were a group of lusty men of the same age. The women might also be more likely to suggest that insurance companies cover birth control pills. Whenever there is a decision to be made, there are decision makers who have values and motivations that may or may not coincide with our own. When disease is considered in this light, we may have more motivation to enter into our own care.

When there is a decision to be made, that means there is uncertainty. When there is uncertainty, there are choices about how much information to consider, what information is relevant, and what is not. There are decisions to be made about what to consider a cost and what to consider a benefit. At each decision point, values enter the equation. Even if that were not the case, although it necessarily is, the scientific data that are being considered are probabilistic, not absolute, suggesting still more uncertainty. If we don’t embrace that uncertainty, the decisions are made for us, the uncertainty is hidden from view, and the rest unfolds according to traditional practice, leaving us with few or no alternatives.





Healthy or Ill?


When the results of our biopsy bring us a diagnosis of cancer, a profound change often happens. Many of us lose our earlier identities and become a “cancer patient,” a label that opens us up to all the negative effects of labels. But that needn’t be the case. Recent work by psychologist Sarit Golub has shown that we have a choice about how we accept and apply those labels.18 Her work found that some people add cancer to their identity, so to speak, while others let the diagnosis take over their identity. The former group fares better on most measures of recovery and psychological well-being.

An interesting aspect of her work is how patients’ ratings of their quality of life don’t always agree with their physicians’ assessment of their physical health. Her research suggests that the largest factor in determining quality of life is the way that people think about the relationship between their identity and their illness. People who felt damaged by their illness tended to rate their quality of life as low, while others who saw the limitations imposed by the disease as an opportunity for growth tended to rate their quality of life as higher. Golub cites Lance Armstrong’s declaration that “cancer is literally the best thing that ever happened to me” as a high-profile example.

If we compared people who fall just short of a diagnosis with those who are just at or above the cutoff, and followed both groups over time, what would we find? I think they would become less and less alike. One group may become healthy while the other remains cancer patients—even though the original difference between them and another diagnosis was not meaningfully different statistically.19 What differs is our reaction to the diagnosis.

A disease presents itself as a set of symptoms. Those who have these symptoms, do nothing, and are fine are not part of the analysis—they never present themselves to the medical world. Thus it is impossible to know how strong the relationship is between these symptoms and subsequent health effects. Moreover, the self-fulfilling aspects of calling these symptoms a disease is unknown. Yet lives would be meaningfully different based on test results that are not meaningfully different.

We look at ourselves and declare that we are either healthy or sick. Despite the tendency to sort people into just two categories, probably no one would argue against the idea that health exists on a continuum. Not only do people vary from person to person in “how much” of an illness they have, they also vary in how intense the illness is for them at any particular time. When my arms and legs are strong and I can breathe like an Olympic swimmer and I have an infection in my ear, am I healthy or sick? When my vision and hearing are excellent and my lungs are strong and I have MS, am I healthy or sick? If our beliefs were inconsequential to our health, it would make no difference, but here the argument is that our beliefs are crucial to our well-being.

Andre Dubus, the wonderful short-story writer, was in a horrible accident that left his legs paralyzed. In his book Meditations from a Movable Chair, he offers a vivid illustration of the choice we have available to us.

“You were hit by a silver—” She named a car I know nothing about, but not the right one.

I said: “It was a Honda Prelude.”

“And it paralyzed you?”

“No. Only my legs are useless. I’m very lucky. I had three broken vertebrae in my back. But my spine was okay. My brain.”



Consider what life would be like if we gave up the idea of healthy or sick—zero versus one—and replaced it with the idea of multiple continua. One minute, for example, we might score 60 percent on one health dimension, 30 percent on another, and perhaps 85 percent on yet a third. How would that change our lived experience? First, we could still feel empowered because we would recognize that much of our body is still working just fine. Second, it is easier to try to “fix” a smaller problem (60 percent healthy) than a big one (100 percent sick). Third, we would have many more people to whom we might compare ourselves and thereby potentially find many more solutions to our health. If you have only 30 percent of the problem and have found a solution, maybe it could work for me at 60 percent. That’s a lot easier to imagine than in the all-or-none world in which we currently find ourselves.

Of course, no doctor, no matter how close to us, no matter how earnest and caring he or she might be, is going to do all those calculations. Once we start to do it for ourselves, we’re sure to run into the problem of how and when we figure it all out. Just how bad is my particular disease, given how good these other parts of me are? As we collect the data on ourselves, we should notice that we keep changing on each continuum. All of this should be a very mindful activity, leading to even more attention to variability. At some point as we become very sophisticated with the process, we should notice similarities and differences over time and that what affects one issue may also affect another. For example, the exercises I’ve been doing to improve my back have also affected my balance and the pain in my foot. If I come to see that using my nondominant hand for some tasks helps my posture, which helps my back pain, I even may find that my hearing has improved, although the link right now is not straightforward. Eventually—only eventually—we may get to a place where we don’t need the continua; we may one day be in a place where we spontaneously notice subtle signals our bodies give and make the necessary corrections as part of our ongoing lived experience.

My friend Elaine tells the story of friends of hers, a female couple, one of whom was a doctor. The nondoctor experienced chest pains while driving and immediately called her doctor partner. Knowing her very well and having little reason based on the science she had learned in medical school to believe her significant other was a likely candidate for a heart attack, the doctor said she was probably having indigestion. Doctor or no doctor, the woman in pain was scared and accordingly drove herself to the hospital anyway. It turned out to be a heart attack.





