Preface
During the 2016 US presidential election, fact-checking revealed that only
one out of every six of the winning candidate’s statements was rated as honest or mostly honest. Yet fact-checking apparently held little sway with millions of voters who saw the candidate whose statements were more factually
aligned as the less trustworthy of the two. How could this be? Despite the postelection soul searching of political pundits, this pattern is far from unique.
Across a host of issues such as the advent of fake news, climate-science denial,
and Bernie Madoff’s appeal to investors, people can be astonishingly gullible.
There are people who come off as authentic and sincere even when the facts
discredit them. People fall victim to conspiracy theories and economic scams
that should be dismissed as obviously ludicrous.
Many people, especially academics, see widespread gullibility as stemming
from an unengaged and ill-informed public: If only people were better educated, surely they would be better at correctly distinguishing fact from fiction.
Yet simple fact-checking coupled with public-education campaigns is unlikely
to provide adequate solutions. Why? Because day in and day out, we spend
our lives within a mind-set that can be characterized as a “truth-default.” We
uncritically accept virtually all of the communication messages we receive as
“honest.” Think about it: how many tweets, posts, articles, texts, e-mails, phone
calls, and spoken declarative sentences do you receive each day? Now ask yourself: How many of those do you question in terms of honesty? Chances are, the
answer is near zero. This is a near-universal human tendency. We all are perceptually blind to deception. We are hardwired to be duped. The question is,
can anything be done to militate against our vulnerability to deception without
further eroding the trust in people and social institutions that we so desperately need in civil society?
But there is a second critical point. Even though we have a strong tendency
toward unquestioning belief, sometimes we do suspect deception. There are
situations in which we abandon our truth-default. But, even when people are
on guard for deception, folk wisdom about deception leads to predictable er-

x

PREFACE

rors in judgment. In the most recent presidential campaign, blurting out po
litically incorrect statements was understood by many Americans as evidence
of authenticity. Appearing confident was interpreted as a sign of honesty. Alternatively, speaking like a politician with carefully chosen words signaled that
the candidate was not to be trusted. Rather than questioning whether the candidate’s statements actually aligned with known facts, assessments of honesty and sincerity were based on the candidate’s demeanor. The problem is,
demeanor is highly misleading. Appearing honest and being honest are usually unrelated.
My objectives here are ambitious and radical. I want to start a revolution. I
seek to overthrow existing deception theory and provide a new, coherent, and
data-consistent approach to understanding deception and deception detection.
For more than twenty-five years, I have seen a need for a new theory of deception and deception detection. Ekman’s idea of leakage was hugely influential, but the deficiencies were apparent almost immediately. His focus shifted
over time from the leakage hierarchy to a focus on the face and microexpressions. But my read of the ensuing literature reveals more excuses for why the
data do not seem to support his theory than solid, replicated, affirmative scientific support. Interpersonal deception theory is even less viable. It is logically incoherent, and I knew it to be empirically false four years before it was
eventually published. The new cognitive load approach in criminal and legal
psychology does not seem to be the path forward either, for the theoretical reasons identified by Steve McCornack, as well as weak, inconsistent, and just
plain odd empirical findings. The need is clear. Existing theory does not cut
it. A new perspective is needed.
Duped: Truth-Default Theory and the Social Science of Lying and Deception tells
the story of my program of research culminating in my new theory of deception: truth-default theory (TDT). Approximately sixty original studies and experiments are summarized and woven together within the TDT framework.
I detail where the ideas came from, how ideas were tested, and how the findings combine to produce a coherent new understanding of human deception
and deception detection.
The story begins in 1989, when I coauthored my first deception detection
experiment as a graduate student. The experiment brought college-student dating couples into the lab, and my professor and I looked at how the closeness
of the communicators’ relationship and how prompting suspicion affected
our research subjects’ ability to tell whether their partners were lying. The big
finding was that even when we tried to make them highly suspicious, our subjects still tended to believe their partners regardless of their partners’ actual

PREFACE

xi

honesty. This finding was called truth-bias, and it has turned out to be a very
robust finding. Since then I have collected data in countries around the world
and recruited a wide variety of research subjects, including college students,
university professors, police detectives, customs agents, and professional spy
catchers. Truth-bias has been a constant finding. I have never found people
to be otherwise. Over time I have pieced together coherent understandings of
truth-bias, how best to catch lies, and the interplay between the two.
TDT proposes that the content of incoming communication is usually un
critically accepted as true, and most of the time this is a good thing for us. One
of the most surprising new insights is that truth-bias and truth-default work
well for us. I argue that the tendency to believe others is an adaptive product
of human evolution that enables efficient communication and social coordination. The truth-default allows humans to function socially. Further, because
most deception is enacted by a few prolific liars, the so-called truth-bias is not
really a bias after all. Passive belief makes us right most of the time. The catch
is that it also makes us vulnerable to occasional deceit.
Importantly, TDT also challenges current social-scientific and folk views of
deception that prioritize nonverbal and linguistic behavior as the keys to lie
detection. According to TDT, the path to improved human lie detection involves listening to what is said, rather than to how it is said. As previously
mentioned, the recent US election provides an excellent example of a situation where confidence and belligerence were decoded as authenticity and were
often mistaken for honesty. More broadly, research shows that using evidence
and skilled question asking produces much better outcomes than passive observation of deception cues like gaze aversion, facial expressions, body language, pronoun usage, or decontextualized counts of details.
My research on lie detection and truth-bias has produced many provocative new findings over the years. For example, we have uncovered what makes
some people more believable than others (a believability quotient) and have
discovered several ways to improve lie-detection accuracy. I directed a team of
researchers (funded by the FBI and involving agents from the NSA) that produced the highest lie-detection accuracy ever published. Truth-default theory
weaves together all these findings under a common framework. The evidence
is organized and presented all in one place.
This book’s perspective is best described as quantitative, experimental, multi
disciplinary social science. My academic home discipline is communication.
Consequently, deception and deception detection are first and foremost understood as communicative processes. The focus is more social and interpersonal than intrapsychic. Theoretically, TDT integrates ideas from a variety of

xii

PREFACE

academic disciplines such as evolutionary biology (Robert Trivers), social psychology (Dan Gilbert), and the philosophy of language (Paul Grice). Structurally, the book is modeled on classics in experimental social psychology such
as Latane and Darley’s (1970) The Unresponsive Bystander, presenting a logical
series of original experiments.
The research subjects in TDT experiments range from college-student dating couples to nationally representative samples of US adults to elite NSA
agents. Data collections span five continents. Every major TDT claim is scientifically tested and replicated. Small chunks of TDT ideas and results have
been appearing in peer-reviewed academic journal articles for more than two
decades. The book shows how all those findings and ideas fit together into a
coherent package. The book also showcases for students, young professors,
and social science aficionados what can be achieved with long, sustained, ambitious, programmatic, multimethod research. The applications are diverse,
ranging from deception in romantic relationships to catching terrorists to
criminal interrogation.
My approach might be described as abductive science. I don’t see what I do
as either dust bowl empiricism or as exclusively hypothetico-deductive theory
testing. The theory building presented in this book is not of the abstract, armchair, speculative sort. The propositions are all data based, and the explanations were articulated so as to offer a coherent account of the existing scientific data. I did not seek to publish my theory until I had original research to
support and replicate every major claim. I have that evidence now, and it is
presented in the pages that follow.
But my intent is not just post hoc explanation. Good theory must also be
generative. It needs to lead to new predictions that no one would think to make
absent the theory. In line with Imre Lakatos, I want to propose a theory that is
out in front of the data, not always chasing from behind to try and catch up.
A final feature of my theory is that it is modular. Truth-default theory is a
collection of quasi-independent minitheories, models, or effects that are joined
by an overarching logic. The parts can stand on their own, but they also fit together to provide a bigger picture.
Stylistically, the text shifts between first-person storytelling, objective scientific narration, and editorializing. The book provides an engaging read targeted
to a diverse audience. I strove to be accessible to the novice while also providing valuable insights for even the most sophisticated and informed reader.
I aim to provide an engaging, fun, interesting read without sacrificing scholarly rigor. The result is a book that can be read and appreciated at different
levels by different audiences.

Acknowledgments
There are several individuals without whom this book would not have
happened, and many of the ideas presented here are not all my own. First, there
is my good friend Steve McCornack, who, to my knowledge, first coined the
term “truth-bias.” Perhaps no other idea has played a more prominent role in
my thinking. Without Steve, it is unlikely I would have ever done a deception
experiment. As I explain in chapter 1, I got my start in deception research as
Steve’s lab assistant. My first several published articles on deception were all
collaborations with Steve. His ideas regarding truth-bias, suspicion, probing,
information manipulation, and the problems with cognitive load all influenced
my thinking in important ways. I am grateful for Steve’s friendship as well as
his intellectual contributions.
Another absolutely critical influence was Hee Sun Park. Besides being my
spouse, she came up with the ideas for the veracity effect, the Park–Levine
probability model of base-rate effects, and the “How People Really Detect Lies”
study. Each of these ideas is a key part of truth-default theory (TDT). Without
these critical pieces of the puzzle, I would not have a coherent theory of deception.
A third key contributor was J. Pete Blair. Prior to earning his PhD, Pete
was a professional investigator and interviewer-interrogator. He has brought a
more applied flavor to my research, and many of the ideas regarding improving accuracy (e.g., content in context, expertise, question effects) are, at least
in part, Pete’s. Pete has become a highly valued collaborator and a good friend.
Three of my former graduate students deserve special mention. Ms. Rachel
Kim was my chief lab assistant and collaborator on the creation of the NSF
tapes, as well as experiments on base-rates, suspicion, deception motives, and
projected motives. I owe Rachel much, and it was a pleasure having her on
the team. When Rachel left MSU, I was exceptionally fortunate to have David
Clare step into the role as my chief lab assistant. David was there for many of
the more recent data collections (e.g., demeanor, experts, interactive base-rates,

xiv

ACKNOWLEDGMENTS

and the FBI expert experiment), and he was a fabulously reliable research assistant and a great student. David’s preliminary PhD paper provides key evidence for the central premise of the theory. Kim Serota played an important
role in the “few prolific liars” program of research, the demeanor studies,
some of the base-rate studies, and the Lie to Me experiment. Amongst many
assets, Kim has a real gift for the visual depiction of data. Kim created or formatted several of the figures presented in the book. He continues to be a valued friend and coauthor and has taken the lead in the lie prevalence research.
His restaurant recommendations are spot-on too.
A number of other students, from high school students to PhD candidates,
have contributed in various ways to the research reported here. These include
(but are not limited to) Yasuhiro Daiku, Hillary Shulman, Allison Shaw, Doug
Messer, Frankie Carey, Kelli Asada, Mikala Hughes, Dave DeAndrea, Chris Carpenter, Alex Davis, Darcy Dietrich, April Li, David Yuan, Tracie Greene, Eric
Jickling, and the students of my Com 399 and UGS200H deception classes.
Yasuhiro made many of the high-resolution figures for the book.
Thanks also to the National Security Agency, the Baton Rouge District Attorney’s Office, and the US Customs and Border Protection office in Detroit
for their involvement in the research. Dan Baxter was especially helpful. Big
thanks to the National Science Foundation for the initial funding and to the
FBI for additional financial support.
Much of my own work summarized in this book originally appeared in journal articles over the past twenty-eight years. Numerous journal editors and
journal reviewers have provided invaluable feedback over the years. Credit is
given to specific journals in notes and the bibliography. Here, I express my appreciation and recognition to all the journals, editors, and reviewers who contributed to the ideas, presentation, and dissemination of TDT and research
behind it.
My friend Tom Hove provided valuable feedback on many of the ideas presented in the book. Dave DeAndrea has also read early drafts, provided wonderful feedback, and even assigned drafts in his classes. Torsten Reimer coined
the terms “truth-default” and “trigger.” Mark Knapp, Michael Beatty, and Howie
Giles have been very supportive of my work and my career. Harry David provided initial editing and proofreading.
Dan Waterman is my editor at the University of Alabama Press. Dan has
been terrifically supportive and helpful. He really got behind the project. I am
very fortunate to have Dan as an editor. Thanks for everything, Dan!
Credit also goes to former professors who taught me well: Buddy Whee-

ACKNOWLEDGMENTS

xv

less, Jim McCroskey, G. R. Miller, Frank Boster, and Jack Hunter. Finally, credit
also goes to four individuals who have especially influenced me through their
wonderful scholarship: Paul Meehl, Gerd Gigerenzer, Bob Cialdini, and Dan
Gilbert.
Tim Levine
Birmingham, Alabama

List of Studies and Experiments
Chapter Eight
IMT Study One: The First IMT Study
IMT Study Two: Replication and Inclusion of a Dichotomous Assessment
IMT Study Three: Effects of Deception Severity
IMT Study Four: Relationship among IMT Dimensions

Chapter Nine
TDT Study One: The Prevalence of Lying in America
TDT Study Two: Diary Studies Reexamined
TDT Study Three: A Replication with College Students
TDT Study Four: Teens Lie a Lot
TDT Study Five: The Prevalence of Lying in the UK

Chapter Ten
TDT Experiment Six: Selecting Truths and Lies
TDT Experiment Seven: Generating Truths and Lies
TDT Experiment Eight: Introducing the NSF Cheating Experiments
TDT Study Nine: Toward a Pan-Cultural List of Deception Motives
TDT Experiment Ten: Projected Motives One
TDT Experiment Eleven: Projected Motives Two
TDT Experiment Twelve: Projected Motives Three

Chapter Eleven
TDT Experiment Thirteen: Lovers Just Aren’t Leery
TDT Experiment Fourteen: Rachel Kim and Suspicion Redux
TDT Experiment Fifteen: David Clare and Evidence for the Truth-Default
TDT Experiment Sixteen: David Clare and Evidence for the Truth-Default Two

Chapter Twelve
TDT Experiment Seventeen: The First Base-Rate Experiment
TDT Experiment Eighteen: Accuracy Is a Predictable Linear Function of
Base-Rates

xviii

STUDIES AND EXPERIMENTS

TDT Experiment Nineteen: The First Interactive Base-Rate Experiment
TDT Experiment Twenty: The Second Interactive Base-Rate Experiment
TDT Experiment Twenty-one: The Third Interactive Base-Rate Experiment
TDT Experiment Twenty-two: The First Korean Base-Rate Replication
TDT Experiment Twenty-three: The Second Korean Base-Rate Replication

Chapter Thirteen
TDT Experiment Twenty-four: Cues-Biased Lie Detection Training Lacks
Efficacy (Bogus Training One)
TDT Experiment Twenty-five: Bogus Training Two
TDT Experiment Twenty-six: Lie to Me
TDT Experiment Twenty-seven: Senders Vary Much More than Judges
TDT Experiment Twenty-eight: Looking for a Transparent Liar
TDT Experiment Twenty-nine: Gaming Accuracy by Stacking the
Demeanor Deck
TDT Experiment Thirty: Replicating Demeanor Effects across Different Types
of Judges (Students)
TDT Experiment Thirty-one: Replicating Demeanor Effects across Different
Types of Judges (Professors)
TDT Experiment Thirty-two: Replicating Demeanor Effects across Different
Types of Judges (Korean Sample)
TDT Experiment Thirty-three: Replicating Demeanor Effects across Different
Types of Judges (Experts)
TDT Study Thirty-four: Uncovering the BQ
TDT Study Thirty-five: Uncovering the BQ Two
TDT Experiment Thirty-six: A Full Cross-Validation of the BQ

Chapter Fourteen
TDT Study Thirty-seven: How People Really Detect Lies
TDT Experiment Thirty-eight: A First Peek at Situational Familiarity
TDT Experiment Thirty-nine: Content in Context (Students, Cheating)
TDT Experiment Forty: Content in Context (Students, Mock Crime)
TDT Experiment Forty-one: Content in Context (Students, Real Crime)
TDT Experiment Forty-two: Content in Context (Experts, Cheating)
TDT Experiment Forty-three: Content in Context (Experts, Mock Crime)
TDT Experiment Forty-four: Content in Context (Experts, Real Crime)
TDT Experiment Forty-five: A (Failed?) Questioning Style Experiment
TDT Study Forty-six: Improved Accuracy with the Fourth Question Set
TDT Study Forty-seven: Improved Accuracy with the Fourth Question
Set Two

STUDIES AND EXPERIMENTS

TDT Study Forty-eight: Improved Accuracy with the Fourth Question
Set Three
TDT Experiment Forty-nine: Head-to-Head Comparisons
TDT Experiment Fifty: Head-to-Head Comparisons Two
TDT Experiment Fifty-one: Head-to-Head Comparisons Three
TDT Experiment Fifty-t wo: Smashing the Accuracy Ceiling with Expert
Questioning (Pete does the questioning)
TDT Experiment Fifty-three: Smashing the Accuracy Ceiling with Expert
Questioning (Students watch Pete’s Interviews)
TDT Experiment Fifty-four: Smashing the Accuracy Ceiling with Expert
Questioning (New Experts)
TDT Experiment Fifty-five: Smashing the Accuracy Ceiling with Expert
Questioning (Student Judges of Expert Interviews)

xix

PART I
The Social Science of Deception

1
The Science of Deception
On the morning of July 19, 2012, I listened with interest as two former
CIA agents, Philip Houston and Michael Floyd, were interviewed during an
episode of The Diane Rehm Show on National Public Radio about their new
book, Spy the Lie.1 The book was a popular-press attempt to share the secrets of
lie detection with the book-buying public. It seemed to me that some of what
they were saying was right on target, while some of their other advice was pure
bunk. What really caught my ear, however, was their response to one particu
lar caller who asserted that we might not be able to detect lies very well. Some
liars, this caller said, were really good at lying. The caller referenced Robert
Hanssen, the FBI agent who spied against the United States for Russia and
successfully evaded detection for more than twenty years. Didn’t Robert Hanssen exemplify our inability to catch some lies and liars?
The authors replied that their approach to detecting lies was not based on
scientific research but on anecdotes and personal experience. Experience had
taught them that their approach was highly effective.
Wow! I found this response really curious. First, the caller had not referenced academic research. The caller’s comments involved anecdote, not science. As we will see in chapter 3, much research shows that people are poor
lie detectors. Science clearly contradicts some of these authors’ assertions. But
why bring scientific research up at that time? Second, I did not expect the authors to volunteer information implying that their view might contradict scientific evidence, and to openly express their hopeful desire that listeners trust
their anecdotes over science. Is that really persuasive? Presumably, they were
on the radio to promote their book. To my ear, they had just undercut themselves. Third, while they might have had good reasons to believe that the lies
they detected were valid, how could they have known how many lies they had

4

CHAPTER ONE

missed? They had no way of knowing how often they had been suckered. The
best lies are never detected. In the lab, researchers know what is truth and
what is lie. In everyday life, we often cannot know what is truth and what is
lie with 100 percent certainty. Sometimes we are wrong and never know we
are wrong. This was the caller’s point, and it was a good one. As we will see
in chapter 13, some liars are really good at telling convincing lies.
Here is an observation from my own research that applies to using examples as evidence for what works in lie detection. From 2007 to 2010, I had
funding from the National Science Foundation to create a collection of videotaped truths and lies for use in deception detection research. I ended up creating more than three hundred taped interviews during that time. (I have made
more since then with funding from the FBI.) I have watched these three hundred interviews many times over the years. For every liar you can point to multiple things that seem to give the lie away. If you watch the tapes carefully, the
clues are almost always there to see.
There are, however, a couple important catches. First, what gives away one
liar is usually different from the signals that reveal the next liar. The signs seem
to be unique to the particular lie, and the science discussed later in the book
backs this up. Second, if you go through the tapes carefully, for every liar who
seems to be exposed by a telltale sign or collection of clues, there are honest
people who act the same way and do the same things. That is, most of the behaviors that seem to give away liars also serve to misclassify honest people.
That honest people can appear deceptive is one of the many insights I have
gained from watching so many tapes where the actual truth (called “ground
truth” by researchers) is known for certain. If you know some statement is a
lie, you can usually point to clues indicating deceit. That is because of hindsight.2 Pointing out clues with hindsight is one thing. Using those same behaviors to correctly distinguish truthful from deceptive communication is quite
another. Different liars do different things, and some honest people do those
things too. When I watch tapes of truths and lies without knowing in advance
which is which, whether some behavior indicates a lie is not entirely clear. I
find that when I don’t know who is a liar beforehand, I miss some lies, and I
falsely suspect some honest people of deceit. Many times, I am just not sure
one way or the other. Cherry-picking examples is easy and makes for persuasive and appealing anecdotes. Cherry-picked examples informed by hindsight
do not lead to useful knowledge and understanding that extend beyond the
specific example.
This makes me suspicious of knowledge by common sense, anecdote, and
personal experience. I want scientifically defensible evidence. If what I think

SCIENCE OF DECEPTION

5

does not mesh with the data, we have to question what I think. This principle,
by the way, is not only useful in assessing the quality of advice. It is also a
good way to detect lies. There is much more on the use of evidence in lie detection in chapter 14.
What the scientific research says (at least up through 2006; current findings are more nuanced) is that people are typically not very good at accurately
distinguishing truths from lies. The research behind this conclusion is extensive and solid, and that will be covered in chapter 3.
Nevertheless, we should not be too quick to dismiss professionals with expertise in interrogation and interviewing who believe there are ways to catch
liars and detect lies. Just because their evidence is anecdotal does not mean
that it is false or necessarily incorrect. In fact, my research described in this
book is, in part, an effort to use science to reconcile research findings with
practitioners’ experience. That is, rather than trying to debunk practitioners,
as so many of my fellow academics try to do, I began designing experiments
to explain the differences between successful interrogations and typical deception detection laboratory experiments. Much of the research, I have come to
believe, tells us more about lie detection in the lab than in real life.3
A more accurate scientific conclusion is that people were not very good at
detecting lies in lie-detection experiments published prior to 2006. The research did not prove that lies can’t be detected! The research showed that lies
cannot be accurately detected in the type of experiments that were used to study
lie detection. Conclusions from research are always limited by how the research
was done. In the case of research on the accuracy of deception detection, I
have come to believe that this is a critical, game-changing point (see chapters
12, 13, and 14, and compare the research reviewed in chapter 14 to that reviewed in chapter 3).
I have come to believe that many approaches to lie detection are ineffectual, especially those that involve what I call “cues.” Some approaches do have
more promise. Improving accuracy involves understanding what works, what
does not work, and why. Because I am a social scientist, anecdotes, yarns, and
good stories are not going to cut it as evidence. Scientific evidence is required.
Real-world observations are critical in generating the ideas that I research, but
such observations are only the starting point. I prove my points with controlled
experiments. I insist that my results replicate. I think my readers should expect this. And it is this insistence on scientific evidence that can be replicated
that makes my approach better than the alternative approaches and theories
out there.
This, however, does not mean I have an aversion to good stories. I began

6

CHAPTER ONE

the chapter with a story about listening to the radio one morning. Then there
was a second story about my repeated viewing of the NSF deception tapes.
Stories are great for explaining ideas, making ideas understandable, and generating research ideas. Stories are essential for making points interesting and
engaging. I will tell plenty of stories throughout the book. I will also present
hard data that are scientifically defensible and have passed the dual tests of
replication and publication in peer-reviewed academic journals. At the end of
the day, I am doing science, and this book is about a scientific approach to deception and deception detection.
Speaking of stories, here is another, and while it is a digression, I think it
addresses a question many readers may have at the outset. People tend to find
deception interesting. People are naturally curious about lies and lie detection.
And it’s not every day that people meet a deception detection researcher. Actually, there are not many of us around to meet. People who have sustained
careers studying the social science of deception probably number less than
two or three dozen worldwide. Anyway, when people find out that I study deception, one common question is how and why I got into deception research.
This is a question that I have been asked too many times to count, and this is
a good time and place to answer it.
The truth is that I stumbled into deception research. I became a deception
researcher largely out of serendipity. Remaining a deception researcher was
opportunistic. Back in grade school, I was very interested in the physical sciences. Other little kids wanted to be policemen or firemen or astronauts, but
I wanted to be a geologist when I grew up. That changed in junior high and
high school. I had a strong fascination for why people did things and with social dynamics. One of my nicknames in high school was Freud; but I wasn’t
interested in psychological disorders. I was curious about normal, everyday
social behavior. And I still am. What I call truth-default theory (TDT) is about
deception in the lives of normal people in their everyday social interactions.
When I was in high school, it was unclear whether I could go to college.
I’m dyslexic. A psychologist told my parents it would be a waste of money to
send me to college. I was sure to flunk out. Fortunately for me, my grades were
good enough, and I scored well enough on the ACT test, to be admitted to
all the colleges to which I applied. My parents agreed to give me a chance, as
long as I selected a public, in-state university with low tuition. I chose North
ern Arizona University.
When I went off to college, I knew I would be a psychology major. As I
learned more, I gravitated toward persuasion as a topic. I grew up the son of
a real estate salesperson, and sales and social influence intrigued me. Dur-

SCIENCE OF DECEPTION

7

ing my third year in college, I learned that persuasion was a topic of research,
and when I went on to graduate school, that was the topic that drew me in. I
switched from psychology to communication mostly for practical reasons. It
was easier to get into top-rated graduate programs with full-ride funding in
communication than in the more competitive field of psychology. I did both
my MA thesis and my PhD thesis on the topic of persuasion. I teach classes
on persuasion to this day. It was early in graduate school that I started picking
up interpersonal-communication processes as a second area of focus.
By the time I finished my first semester of graduate school, I pretty much
knew my career choice was in academia and that I wanted to be a professor.4
It turned out that I had some talent in research and that I enjoyed teaching.
I managed to get into the highly regarded PhD program at Michigan State
University, where two leaders in persuasion (Gerry Miller and Frank Boster)
were on the faculty. Miller’s health was in decline, and I ended up studying
under Boster.
About halfway through my PhD studies, Michigan State hired a new professor by the name of Steve McCornack. Steve and I were nearly the same age,
and we had much in common. More than that, I was really impressed by Steve.
I thought (and still do) that he was really smart. I like smart people. As an undergraduate student, Steve had done a research project on deception that had
won an international award and been published.5 Writing and publishing an
award-winning research paper as an undergraduate—wow! Even more than
just the award and publication, his ideas and findings were really cool.
Prior to Steve’s, there had been only one other study on lie detection among
people who knew each other.6 The prevailing wisdom at the time was that
the better you knew someone, the better you would be at detecting their lies.
Knowledge of another person was expected to enhance deception detection
accuracy. Steve, however, predicted the exact opposite. The better you know
someone, the more you tend to think you can tell when they lie, but also the
more you think they wouldn’t lie to you. Relationship closeness, according to
Steve, makes us truth-biased. This was intriguing. I read Steve’s research, I
heard him present his research, and I knew this was someone I wanted to collaborate with and learn from.
When Steve joined the faculty at Michigan State, I arranged to be assigned
as his research assistant. My advisor, Frank Boster, was graduate director, and
getting the assignment to Steve as his assistant was a simple matter. Over the
next couple of years, we did a number of studies together.7 I just got sucked
into deception research. Each study led to more questions. The more I learned
about deception, the more a set of challenging puzzles became apparent to me.

8

CHAPTER ONE

One thing led to another, and now I am writing this book twenty-five years
later. It took a quarter century, but I now have answers that hold up and are
worth sharing.
What I like most about deception research, and probably the biggest reason
I stuck with it, is that in the realm of deception research, most things are not
what they seem. Common sense is often wrong, and surprising twists come
one after another. Too much social science is content with documenting the
obvious. Deception research, in contrast, presents a challenging set of puzzles
to solve.
What drew me to deception research is similar to what attracts my wife and
me to certain television dramas. We get bored quickly with series that are conventional and predictable. We like complex plotlines and unanticipated developments. This is what I really like about Game of Thrones (both the HBO series and the books) and Lonesome Dove (book and miniseries).
The other thing that has kept me doing deception research is that the need
and potential for improvement have been apparent to me since my first involvement as a graduate student. It seemed to me that deception research could
do better. The theory needed improvement, the methodology could be made
better, and the findings could be stronger and more coherent. In short, there
was plenty of opportunity to make a scientific splash. So many areas of social
science research evolve into super-specialized endeavors looking at ever-more
microscopic issues of little interest to anyone outside the sub-sub-subspecialty.
But this was not the case in deception research. So I stuck with deception as
a topic and gradually solved one puzzle after another.
PRIOR DECEPTION RESEARCH AND THE NEED
FOR A NEW APPROACH TO DECEPTION
This book offers a new approach to understanding deception and deception detection: truth-default theory. The main impetuses behind the theory and this
book were my growing dissatisfaction with the prevailing theory and my desire to solve some challenging puzzles stemming from the research findings.
What was needed to really understand deception and deception detection was
a new theory. It has taken much research, much persistence, some talented
and insightful collaborators, and more than a little luck to get to this point.
I have several goals for TDT besides just offering an explanation of deception and deception detection. For one, the theory needs to solve some persistent mysteries. There are a number of odd things in the existing scientific literature that (until TDT) did not seem to make much sense. A coherent way
to make sense of the literature is needed. Second, there is a need for a coher-

SCIENCE OF DECEPTION

9

ent logic that points in new directions and yields new findings. Much deception research seems to be spinning its wheels, so to speak. The research needs
to get out of an intellectual rut. Most of all, the theory needs to make predictions that turn out to be right. It seems to me that older theories are better at
excuse generation than accurate prediction. Findings really don’t support the
older theories, but the failures are either ignored or explained away. I want a
theory that when put to the test will clearly and unequivocally pass. In short,
the aim is to provide a theory of deception that makes past findings coherent,
leads to interesting new discoveries, and, most of all, passes scientific muster.
The previous research on deception is diverse. In this and the next two
chapters, I will focus on four interrelated questions that have received large
amounts of attention. As research has progressed, well-documented answers
have emerged. The four questions are as follows:
1. What do people look for in order to distinguish between whether
someone else is honest or lying?
2. What, if any, specific behaviors actually distinguish truthful communication from lies?
3. How accurate are people at distinguishing truths from lies?
4. Under what conditions are people more accurate or less accurate at
lie detection, and what types of people, if any, are more skilled or
less skilled lie detectors?
Here is a sneak peek at the short answers to the four key questions above.
When explicitly asked, the thing that people most often believe gives away
lies is that liars won’t look you in the eye.8 Interestingly, this belief appears
cross-cultural.9 Also, it appears that eye contact has no validity as a reliable indicator of deception.10 There is no scientific evidence that liars look in some
particular direction when lying.11 Zero.
People look for more than just a lack of eye contact when deciding whether
someone is to be believed. My research has found a constellation of interrelated behaviors and impressions that people associate with honesty and deceit.12 People who seem nervous, anxious, hesitant, and uncertain and who lack
confidence are likely to be doubted, while people who come off as friendly,
composed, confident, and engaged tend to be believed. Based on these packages of behaviors and impressions, we can predict well who will be believed
and who is more likely to be seen as a liar. Further, we have found a number
of other interesting things about these believability markers. First, they are
highly intercorrelated, they occur in combination, and they are perceived as

10

CHAPTER ONE

gestalts. Second, they are not language dependent and appear to be cross-
cultural. Finally, while these behaviors strongly determine believability, they
are unrelated to actual honesty. Chapter 13 covers the details of my work on
honest demeanor. I believe I have discovered what amounts to a “believability
quotient.”
Research looking for specific cues that actually distinguish truths from lies
has identified numerous candidate behaviors. At the level of the results of the
individual published study, there is strong evidence for specific behaviors (cues)
that differentiate liars from honest speakers. However, as research has progressed, findings typically have failed to be replicated, or completely opposite
findings have been obtained. The net result is that as evidence has accumulated, the evidence for cues has become weaker.13 The more each given cue has
been researched, the less it has seemed to distinguish between truths and lies.
This trend has held over time. So, the answer to whether there are specific behaviors that actually distinguish truths and lies appears mostly negative. Taken
as a whole, the evidence suggests that such cues exist but are ephemeral and
lack the potency and consistency to be of much practical value.14
Given that research shows that what people look for in detecting lies is not
very strongly linked to actual lying, it should now be no surprise that people
tend to be poor lie detectors. Literally hundreds of studies have exposed people
to truths and lies and asked them to make a decision about which is which.
When the results of these experiments are scored as the percentage correct
and averaged across studies, what we get is just under 54%.15 People have a
better than fifty-fifty chance of detecting lies, but the odds are not much better than chance.
Finally, research has looked for exceptions to the conclusion of 54%, slightly-
better-than-chance accuracy. Until very recently, research has not found many.
It does not seem to matter whether the lies are read, seen, or heard.16 Video
taped lies yield about the same accuracy as face-to-face communication. It does
not seem to matter whether the judges are college students, police, friends,
romantic partners, or intelligence agents.17 The 54% accuracy result has been
remarkably stable, and most studies produce accuracy levels between 44
and 64%.18
To summarize, people have a constellation of behaviors that they look for
when assessing whether someone is lying. The behaviors people look for, however, do not seem to be behaviors that actually distinguish truths from lies.
Seemingly as a result, people are poor lie detectors. Forty years of research
failed to provide a reliable path to improved accuracy that has met the scientific standard of replication.

SCIENCE OF DECEPTION

11

Figure 1.1. Accuracy in deception detection experiments prior to 2006.

Although the research findings just described are very well supported, they
are not very satisfying: “People are poor lie detectors. They look for the wrong
things. But there really aren’t any right things. All is hopeless.” This is not exactly an encouraging, feel-good message. There is no TED Talk in my future
for that kind of conclusion. Rather than just give up and find a better topic for
research, I opted to try to discover a new way of understanding deception that
would make apparent that which had been missing. We, after all, do sometimes catch others in lies. How is this done? Past research told us much about
what does not seem to work. Research is needed that shows what does work.
Chapter 14 summarizes my research addressing this need.
Besides the practical goal of improved accuracy, a viable theory also needs
to solve two puzzles. I call these the mystery of normally distributed, slightly-
better-than-chance accuracy, and the mystery of deception accuracy in research
not about deception. From an academic and theoretical standpoint, these are
two places where existing theories come up short. These nevertheless are empirical facts that any good theory must make understandable.
One of the things about deception research that had really puzzled me is the
mystery of normally distributed, slightly-better-than-chance accuracy. I have
already explained that average accuracy in prior deception detection experiments is 54%. Most findings fall between 44% and 64%. As shown in figure
1.1, I took each of the 289 findings included in the Bond and DePaulo (2006)

12

CHAPTER ONE

meta-analysis of deception detection accuracy and graphed them with statistical software. The percentage correct found in each study is arrayed along the
horizontal axis. The number of studies finding a particular level of accuracy
forms the vertical axis. As you can see, the findings are neatly and normally
distributed around the average finding.19 I ask the reader to take a moment
to consider why this might be the case and why I find this graph odd and in
need of explanation.
Here is why I find this odd. For one thing, real findings from real research
in the social sciences are seldom this consistent and this orderly. What findings this consistent and this orderly mean is that all the studies are finding
the same thing but varying by some small random amount. Usually, of course,
findings vary from study to study not only because of random error but also
because of a number of nonrandom things such as who the subjects were, the
nature of the research design, other variables included in the study, and the
like. All this creates variability in results from study to study. Some studies
converge on stronger effects than other studies. In the language of social science, most areas of research have moderators. Moderators are other variables
that impact the nature of findings. They make things work differently. Moderators make findings conditional. The existence of moderators in a literature
functions to spread the findings out. Moderators are very common in social
science, and it is odd that the literature on deception detection accuracy is so
devoid of substantial moderators.
Another thing is that if people could not detect lies at all, findings would
be distributed around fifty-fifty chance. They are not. Look at figure 1.1. Findings are not centered on 50 percent. Accuracy is better than chance. So, it’s
not that people are totally incapable. At the same time, people do not seem to
be much better than chance. This too seems odd to me. Why are people only
a little better than chance—not more, not less? What can account for this robust finding of only slightly better than chance? I do not believe past theory
(see chapter 4) has a credible explanation. I will explain why the findings are
the way they are in chapter 13.
The second puzzle is that of deception accuracy in research not about deception. Among my many interests is a long-held affinity for classic old experiments in social science. One well-known example is Stanley Milgram’s famous
experiments on obedience to authority.20 Readers who are up on social science
will know this, but I will briefly summarize the study for those less familiar
with Milgram’s research. Subjects come into the lab with another person they
believe to be another subject. The study is ostensibly about the effects of punishment on learning. One subject is the learner, and the other is the teacher.

SCIENCE OF DECEPTION

13

The learner must learn some word pairs, and the teacher is told to deliver an
electric shock to the learner whenever there is an error. Each error is to be punished with an increasingly intense shock starting at 15 volts and increasing in
15-volt increments to 450 volts. If the teacher objects to zapping the learner
(who frets, screams, complains of a heart condition, and finally stops responding altogether), an experimenter in a white lab coat calmly tells the teacher to
continue. This goes on until the subject absolutely refuses to continue, or until
the 450-volt shock is delivered thrice. What Milgram found, of course, is that
a majority of subjects (65 percent) went all the way—delivering the maximum
shock to the poor victim. This study is considered to provide strong evidence
for the power of authority. The subjects were just following orders, and a majority did so in spite of the brutality and the learner’s protests.
This study was also a deception detection experiment, although it is usually not thought of as such. The learner was really an actor; the only one actually shocked was the teacher-subject, to convince them that the shock generator was real. Otherwise, everything was pretty much all staged. Just how
likely is it that some Ivy League professor is going to electrocute members of
the public in some on-campus torture chamber by getting other members of
the public to flip the switch? Yet apparently, no subject recognized the deception. Accuracy was zero. All the subjects were sucked into the storyline, and
no one saw through the ruse. That is not consistent with 54% accuracy in deception detection experiments. What gives?
Here is another famous example that is even more informative. Asch conducted a famous series of experiments on conformity.21 In these experiments,
subjects judged the lengths of lines. There was a standard line, and then, as
if on a multiple-choice test, there were three comparison lines labeled A, B,
and C. Subjects were asked which of the three comparison lines (A, B, or C)
was the same length as the standard. The subjects were asked to make these
judgments either alone or in groups. When they were in groups, other group
members would sometimes all give the same incorrect answer. When all the
others gave the wrong answer, the subject faced a choice as to whether to give
the answer that looked right to him, or to go along with the group and provide an incorrect answer. When alone, people were able to choose the correct
answer with more than 99% accuracy. After witnessing unanimous group errors, subjects gave the same erroneous answer as the group 36.8% of the time.
The results of this study are typically seen as strong evidence for the power of
conformity to group pressure. Again, although not typically considered in this
way, these results also tell us about deception detection.
The groups’ errors were, of course, preplanned and part of the experiment.

14

CHAPTER ONE

They were flat-out lies. The incorrect answers were knowingly and intentionally false statements meant to mislead the real subject. What’s more, they were
clearly and obviously objectively false. Subjects could see the right answers with
their own eyes. Responses in the control group verified that the truth was obvious. Yet few if any of the subjects came to the seemingly obvious conclusion
that the group errors were simply lies. As Asch described: “Instances of suspicion were rather infrequent. One would expect distrust to grow as the majority continued to err. [But] before his [the subject’s] suspicions had the opportunity to take root, he had unwittingly come to doubt himself and to seek
explanations in other directions. . . . Most subjects did not suspect that the
majority judgments were not genuine. Suspicion at times occurred only as
an hypothesis which, like many others, was rejected”22 (29, 31). So, as with
Milgram’s experiments, Asch’s also documented 0.00% lie-detection accuracy.
These two findings are far from unusual. Much experimental social science
uses research confederates (i.e., people who appear to be other subjects but
who are really working for the research team and are acting out a contrived
role) and other types of deception. In my own research, confederates are identified as such by research subjects less than 1.0% of the time.
So I ask you: Why is accuracy so reliably 54% in studies of deception detection designed to be about deception detection, yet near zero in studies that involve deception but are not about deception? This too is a puzzle that a viable
theory of deception needs to solve. I think I have solved this mystery too, and
the answer is provided in chapters 10 and 11.
A QUICK GLANCE AHEAD
This first chapter is meant as a teaser. We look here at how isolated examples
can be misleading and the advantages of systematic scientific investigation.
A few provocative findings are described, and some interesting mysteries presented. The rest of the book provides much more detail about social science
theory and research on the topic of deception. This book is about where deception theory and research has been and where it needs to go. I hope you
will read on.
The first half of the book (part 1) introduces readers to deception theory and
research. Part 1 does two big things. First, readers are provided with a detailed
and authoritative history and description of the social science of deception. The
next three chapters in particular provide what might be thought of as “Deception 101.” What is known about deception is summarized. How the facts are
most often framed and understood is explained. In short, readers are provided
with all the prior knowledge needed to really understand TDT and the schol-

SCIENCE OF DECEPTION

15

arly environment that predated it. Second, part 1 makes the case for why TDT
is needed. To preview my argument over the next four chapters, there exists
an unacceptably large mismatch between the understandings provided by previous theories and the results of prior research. Simply put, previous theories
run afoul of data in important ways. Bringing theory more in line with findings is among TDT’s more compelling selling points, and the need for theory-
data consistency provides the primary rationale for TDT and for this book. That
is, TDT does a better job of predicting and explaining facts than its rivals do,
and this more than anything else makes TDT valuable.
To these ends, chapters 2 and 3 summarize some of the most important and
most central areas of prior deception research. Chapter 2 focuses on “cues.”
We will take a close look at the research on (a) the behaviors that people think
distinguish truths and lies, (b) the behaviors that people actually rely on in
distinguishing truths from lies, and (c) the behaviors that do and do not actually distinguish truths from lies. Chapter 3 examines people’s ability to distinguish truths from lies in traditional deception detection experiments. In both,
priority is given to meta-analysis, looking at trends across larger numbers of
studies rather than at the findings of individual studies. I strive to provide a
coherent picture of what we know by focusing on findings that reliably replicate and by describing the big-picture implications of those results.
The fourth chapter is titled “Rivals,” and it takes a historical look back at the
other important theories of deception that precede TDT. Chapter 5 critiques
those theories and provides a detailed rationale for the book and TDT. If prior
theory were adequate and sufficient, there would be little to be gained from
yet another theory. The case is made that prior theories have serious deficiencies and that the need for TDT is real and pressing.
Part 2 of the book shifts the focus from prior theory and research to TDT.
Here, I explicate it and describe my program of research leading to, testing,
and replicating TDT.
Chapter 6 provides a succinct and rough summary of TDT. Key definitions
are provided. TDT is modular, by which I mean that it is an organized collection of stand-alone mini-theories, hypotheses, and effects. Each of the modules is briefly described, and the propositional structure weaving them together
laid out. But the chapter just provides an outline, with little explanation. The
detail comes in chapters 7 through 14.
Chapters 7 and 8 provide a careful conceptual analysis of deceptive communication. Chapter 7 takes a close look at issues in defining deception from the
TDT perspective. The eighth chapter examines deception as information manipulation. TDT’s companion theories by Steve McCornack, information ma-

16

CHAPTER ONE

nipulation theory (IMT) and information manipulation theory 2 (IMT2), are
summarized. Beginning in chapter 8, a series of numbered original empirical
studies are summarized testing relevant theoretical predictions. In chapter 8,
a series of four IMT studies are detailed. In chapters 9 through 14, TDT studies and experiments one through fifty-five are described. The TDT studies are
ordered to reflect the logical flow of the theory rather than chronological order.
The aim is to showcase TDT’s extensive and robust empirical foundation and
its predictive power.
Chapter 9 explicates TDT’s first two propositions and the Few Prolific L
 iars
module. The empirical support is detailed. Why people lie is examined in
the tenth chapter, which delves into proposition five and the People Lie for a
Reason module. And it provides the first part of the answer to the mystery of
accuracy in research that uses deception but is not about deception.
Chapter 11 gets to the core of TDT, focusing on truth-bias and the truth-
default and summarizing my research on them. The existence of the truth-
default and the idea of triggers provide additional insight into the mystery of
accuracy in research that uses deception but is not about deception. Chapter
12 focuses on two important implications of truth-bias, namely, the veracity effect and the Park–Levine Probability Model. The focus is on the empirical evidence supporting these modules and proposition three. Chapter 12 explains
why base-rates are so important.
The focus in chapter 13 shifts to offering a coherent explanation for the
prior detection-accuracy findings described in chapters 1 and 3. The companion modules A Few Transparent Liars and Sender Honest Demeanor are explicated, and the evidence consistent with proposition eleven is described. The
mystery of normally distributed slightly-better-than-chance accuracy is solved.
Improving accuracy is the topic of chapter 14. How People Really Detect
Lies is described, along with the Content-in-Context, Question Effects, and Expertise modules. In the process, evidence for the twelfth, thirteenth, and fourteenth propositions is provided.
Finally, chapter fifteen wraps things up.
