
11
Truth-Bias and Truth-Default
Here we discuss TDT’s namesake idea, the truth-default, and the closely
related (but conceptually distinct) variable, truth-bias. It was the empirical observation of truth-bias that started me down the path that eventually led to
TDT. In fact, early versions of the theory in academic talks I gave from 2006
to 2010 were called TBT (Truth-Bias Theory) rather than TDT. However, TDT
is a much better name for my idea.
Professor Torsten Reimer of Purdue University suggested the label “truth-
default” in a conversation a few years back. He told me that he thought “truth-
default” better captured my ideas than “truth-bias.” Torsten’s concern with
“truth-bias” as a label was that people were likely to get caught up on the word
“bias.” Biases, after all, are bad things, to be avoided. But I was no longer thinking of truth-bias as either a bias or a bad thing.
Back in the 1990s, I thought of truth-bias as distorted and lazy thinking.
Over time, however, I came to see truth-bias and the truth-default as adaptive
and not necessarily as biased in the usual sense of the word. Torsten’s points
were that the label “truth-bias” no longer fit my ideas well and that an alternative word or phrase might better capture the main idea. Calling the theory
“truth-bias theory” would mislead readers because of the connotation carried
by the word “bias.” “Truth-default,” Torsten suggested, captured my thinking
much better. He was right.
As I carefully thought about it, I came to see many advantages in taking
Torsten’s advice. I think he was right about people getting stuck on the word
“bias.” There are plenty of examples of that happening in the published literature on deception.1 But more than that, as I thought it through, I came to see
big theoretical and empirical payoffs in distinguishing between a truth-default
and truth-bias. They are not the same thing. The truth-default is one cause of
truth-bias, but people can still be truth-biased even if they are not operating

176

CHAPTER ELEVEN

from a truth-default. That is, the truth-default is sufficient for truth-bias but
not necessary for truth-bias. Believing another person’s communication can
be an unconscious default, or it can be actively based on exculpatory evidence.
Thus, truth-bias can be active or passive, but the truth-default is, by definition, always passive.
TDT’s perspective on truth-bias and the truth-default is captured succinctly
in proposition three.
TDT Proposition Three: Most people believe most of what is said by most
other people most of the time. That is, most people can be said to be
truth-biased most of the time. Truth-bias results, in part, from a default
cognitive state. The truth-default state is pervasive, but it is not an in
escapable cognitive state. Truth-bias and the truth-default are adaptive
both for the individual and the species. They enable efficient communication.
TDT proposition three sets forth five specific subclaims:
• People are typically truth-biased.
• People have a cognitive default state set to believing others—the
truth-default.
• The truth-default state is a primary causal mechanism leading to
truth-bias.
• The truth-default can be “switched off” as specified in subsequent
propositions.
• Truth-bias and truth-default are adaptive—that is, they are usually
good things. They evolved because they serve us well. Specifically,
they are necessary for efficient and effective communication.
The five subclaims are unpacked in this chapter. It is worth emphasizing
up front that it is this last point about truth-default and truth-bias being adaptive that really distinguishes TDT from most other approaches to human deception. While most prior theoretical perspectives acknowledge the empirical
existence of truth-bias, truth-bias in pre-TDT theory is typically viewed as an
error or bias reflecting flawed judgment. Truth-bias is often depicted as a distorted perceptual state that is maladaptive and interferes with deception detection accuracy.2 What is new and different in TDT is the claim that both the
truth-default and the truth-bias that results are functional and adaptive and
improve accuracy in most non-research settings.

TRUTH-BIAS AND TRUTH-DEFAULT

177

I see a parallel in the contrast between TDT and rival deception theories
(especially IDT) and the contrast between the Gigerenzer and the Kahneman-
Tversky approaches to judgmental heuristics under uncertainty.3 Cognitive
heuristics are relatively mindless decision rules that people use to make intuitive judgments under conditions of uncertainty. For example, imagine you are
at the grocery store shopping for shredded cheese. There is a more expensive
name brand and a less expensive store brand. You have not tried either, so you
don’t know whether the price trade-off reflects quality. There is no way at the
time to make a fully informed decision, so there is uncertainty regarding the
best choice. You could just adopt a simple decision rule such as “go with the
name brand” or “pick the lowest price.” Using a simple decision rule avoids
getting bogged down in weighing the pros and cons of an uncertain decision.
Kahneman’s research finds that the use of simple decision rules like these can
lead people to biased, less-than-statistically-optimal choices. The take-home
message is that heuristics make us dumb, biased, and wrong. Gigerenzer, in
contrast, offers a very different point of view. In a nutshell, he says people use
heuristics in situations where uncertainty is inescapable and that heuristics
evolved precisely because they lead to the best decisions in the situations where
they are used. According to Gigerenzer, heuristics make us smart and efficient
decision-makers. This difference is much like the different views of truth-bias
in deception theory. Like Kahneman’s view of heuristics, most deception theory
sees truth-bias as flawed thinking, while TDT, analogous to Gigerenzer’s view
of heuristics, sees truth-bias as functional and adaptive and as having evolved
precisely because it was functional and adaptive. As I mention in the acknowledgments for the book, I am a big fan of Gigerenzer’s work. He has deeply influenced my thinking, and I see TDT as very much in line with his work on
bounded rationality, heuristics, and the adaptive toolbox.4
The scientific evidence for the functional and adaptive nature of the truth-
default and truth-bias is explained further in the next chapter, where the focus
shifts to two important outcomes of truth-bias, the “veracity effect” and base-
rate effects. When these ideas and findings are considered in conjunction
with the findings on prevalence of deception reviewed in chapter 9, the adaptive and functional nature of truth-bias will become clear. In this chapter, the
focus is on conceptualizing and documenting the existence of truth-bias and
the truth-default.
TRUTH-B IAS
Truth-bias is the tendency to believe that another person’s communication
is honest, independent of its actual honesty. The term was coined by Steve

178

CHAPTER ELEVEN

McCornack.5 Steve scored truth-bias as the proportion of messages judged as
honest in some defined setting.6 So, if a subject in a deception detection experiment viewed and judged ten interviews, and if the subject judged six out
of ten interviewers to be honest, the truth-bias score is 0.6 (6 ÷ 10), or 60%.
Scored in this way, truth-bias scores can range from zero (100% of messages
judged as deceptive) to 1.00 (100% of communication rated as honest). Values
above the 0.50 midpoint are seen as “truth-biased.” The more a result is above
0.50 and the closer the value is to 1.00, the greater the extent of truth-bias.
Scores on truth-bias can, of course, fall below 0.50. Steve and I called this possibility “lie-bias” in a 1990 article.7 There are two points I want to make about
lie-bias. First, we think about truth-bias and lie-bias as the same variable—just
different ranges of values on the same continuum ranging from 100% attribution of honesty to judging 100% of communication as deceptive. Second, I
regret using the term “lie-bias.” It has caught on. The problem is that people
are seldom lie-biased, and when lie-bias is observed, it tends to be ephemeral.
Don’t get me wrong. Lie-bias can and does happen. But it tends not to happen, and it is hard to make it happen experimentally in a way that replicates.
Some researchers claim that police officers are typically lie-biased. But a close
look at the research shows that a more correct description is that police tend
to be less truth-biased than college students, but they are still truth-biased.8 By
naming something, the impression is created that that which is named is real.
These days, I see lie-bias as an ephemeral anomaly.9 Research tends to show
more or less truth-bias, rather than an actual lie-bias. My bad.
I define truth-bias as “independent” of actual honesty because it is scored
the same way regardless of the relative proportion of truthful and deceptive
messages judged. So, if all ten interviews were actually truthful, but only six
were judged as honest, truth-bias would still be 0.6. The same would be true
if the messages were all lies. Not all researchers score truth-bias this way,10 but
I want to be clear about how I conceive of and score truth-bias.
I also want to reiterate that truth-bias is only a “bias” in relation to the arbitrary 0.50 standard marking the fifty-fifty point on the scale. Even in deception detection experiments where messages are a fifty-fifty split between truths
and lies, this is still an arbitrary standard. We’ll look at this much more in the
next chapter, but please keep in mind that the word “bias” is merely a label
for a score obtained in research, and that one should not make the easy move
from the finding that people judge more than 50% of messages as honest in
deception detection experiments to the conclusion that people are biased in
the direction of truth outside the lab relative to the actual prevalence of deception in everyday interaction.

TRUTH-BIAS AND TRUTH-DEFAULT

179

TDT EXPERIMENT THIRTEEN: LOVERS JUST AREN’T LEERY
This experiment may be lucky number thirteen as presented in this book, but
in chronology it is number one.11 That’s right, we are about to talk about my
first-ever deception experiment. This is the research that started it all for me.
I mentioned some of the background in the first chapter. I was about halfway
through my PhD program, Steve McCornack had just arrived as a new professor, and I was assigned as his research assistant. We titled our first paper
“When Lovers Become Leery,” but looking back, that title was misleading. The
most important implication of our findings was that lovers just aren’t leery,
even when they should be.
As mentioned in chapters one and three, Steve’s prior work had looked at
how the closeness of the relationship between the sender and the judge affected deception detection accuracy. Steve had studied college dating couples
and found that the closer the relationship, the more confident the subjects
were in their ability to read their partners, the more they believed their partners (i.e., the greater the truth-bias), and (albeit indirectly) the lower the accuracy.12 This finding was surprising because at the time many researchers
thought that knowing a person would increase accuracy.
Steve reasoned that if truth-bias blinds us to the lies of those close to us,
suspicion might counteract that. More precisely, he thought (and we hypothesized) that a little suspicion might be a good thing for accuracy. Absent suspicion, truth-bias would prevail, and truth-bias would lower accuracy.13 Too much
suspicion, too, was predicted to hinder accuracy. While truth-bias might blind
us to others’ lies, we predicted that high suspicion would lead to lie-bias, and
honesty-blindness. But maybe there was a sweet spot in the middle. What if
there was enough suspicion to abandon truth-bias but not so much as to create a lie-bias? Maybe with just the right amount of suspicion, there would be
little bias in either direction. Accuracy would soar. Thus, we hypothesized a
nonlinear relationship between suspicion and accuracy such that moderate
suspicion would produce higher accuracy than either low or high suspicion.
We recruited 107 heterosexual college dating couples to our lab. The couples
were separated, and one was randomly assigned to be the sender, the other
the judge. The sender was asked to honestly answer twelve edgy (from a Machiavellian personality scale) attitude-belief questions. They were then videotaped discussing their answers to these twelve questions, one at a time. For
half of the questions (assigned at random), they discussed how they had actually answered the question. For the other half, they lied about how they had
answered the question and why.

180

CHAPTER ELEVEN

In a different room, the judges received one of three different sets of instructions (determined at random) designed to instill low, moderate, or high
levels of suspicion regarding the partner’s answers. For senders in the low-
suspicion condition, we never even mentioned lying or deception. Judges were
asked a question about whether their partner was lying or telling the truth,
but this question was imbedded in a set of filler questions disguising the true
purpose of the experiment.14 We told them (honestly) that we just could not
tell them what the experiment was about, but from reading the questions, it
appeared the research was interested in how well people know their partners
(and debriefing confirmed that this is what most of the low-and moderate-
suspicion subjects thought). In the moderate-suspicion condition, there was
brief mention of the possibility that the partner might be lying. In the high-
suspicion condition, subjects were directly and explicitly told that the experiment was about lie detection, that the partner would be lying about some of
their answers, and that it was their job as a subject in the experiment to identify the lies.
We showed the twelve videotaped segments, one at a time, to the partner-
judge, who answered a series of questions about each tape, including a question about whether the sender’s response was an honest reflection of the actual answer or whether the sender was lying. Truth-bias (simple percentage
rated as honest) and accuracy (simple percentage correct) were scored. The
results are shown in table 11.1.
Looking at the first row of values in table 11.1, we can see that the results
for accuracy are very much in line with our hypotheses. While overall accuracy was in line with the slightly-better-than-chance accuracy typical of the
larger literature reviewed in chapter 3, accuracy was improved in the moderate-
suspicion condition (65%) relative to the low-(53%) and high-suspicion (57%)
conditions. Contrary to what we thought at the time, in hindsight these were
not the important findings.
Check out the truth-bias scores in the second row of table 11.1. Generally,
suspicion reduced truth-bias. This makes good sense, right? It could not really
be otherwise unless we just did a poor job of varying suspicion. What’s important here, however, is not so much the strong effect of suspicion on truth-bias
but the power of truth-bias in the face of suspicion. When subjects didn’t know
they were in a deception detection experiment and were no more suspicious
than they would be in any other lab experiment, they circled “honest” on four
out five (80%) of the interviews (and hence judged messages as lies on only one
out of five responses). But even under high suspicion, truth-bias still prevailed.
It was lower, for sure, but judges still picked “honest” two-to-one over “lie.”

181

TRUTH-BIAS AND TRUTH-DEFAULT

Table 11.1. Results of TDT experiments thirteen and fourteen
Suspicion
Outcome Variable

Low

Moderate

High

Across Conditions

TDT experiment 13: College dating couples
Detection Accuracy

53.2%

64.6%

57.2%

58.2%

Truth-Bias

80.3%

72.0%

64.2%

72.2%

TDT experiment 14: Unacquainted college students
Detection Accuracy

55.7%

55.7%

48.1%

53.1%

Truth-Bias

78.0%

75.7%

58.7%

70.7%

The big news of experiment thirteen is the robust nature of truth-bias! Even
in a lab experiment where subjects are suspicious to begin with, even when
they know the experiment is about deception, and even when they are told to
expect lies, our subjects were still truth-biased. Truths and lies were equally
prevalent, but truth judgments occurred twice as often as lie judgments. Wow!
The results show the power of truth-bias. But what really drove the power of
truth-bias home does not show up in the tabled results. Since the experiment
used dating couples and because the study was about deception, Steve and I
had some real ethical concerns. We were worried about participation in our
experiment damaging our subjects’ relationships.15 Consequently, we adapted
an extensive debriefing protocol explaining the experiment and making sure
there was no relational damage or fallout. I did many of those debriefings.
Steve and I learned during the debriefing that our concern regarding relationship harm was misplaced. While I was happy that there weren’t adverse
reactions from the subjects and that they were not upset by their participation
in the experiment, I was quite shocked by the outright denial of the nature of
the experiment by some subjects. Several subjects refused to believe that the
experiment was about deception, explaining that their partner just does not
lie to them, experiment or not. These participants were given their research
credits, politely thanked, and sent on their merry way. But they left a lasting
impression on me. My take-home message from the 1990 suspicion experiment was the robust, pervasive nature of truth-bias. It was these results and
these experiences debriefing subjects that planted the first seed for TDT in my
mind. Truth-bias was a strong and important finding. Although I did not foresee where it would lead me, I wanted to understand it better.

182

CHAPTER ELEVEN

TDT EXPERIMENT FOURTEEN:
RACHEL KIM AND SUSPICION REDUX
We now warp ahead two decades. I was a tenured full professor at my alma
mater (Michigan State University) with my own research team, and Rachel Kim
(former undergraduate student of mine at University of Hawaii) was my PhD
student and my valued lab assistant. For her preliminary research paper, Rachel
did a replication and extension of Steve’s and my suspicion experiment.16 There
are several differences between experiments thirteen and fourteen, but two are
important here.17 Rachel’s version used strangers rather than dating couples,
and the truths and lies came from our NSF cheating tapes rather than truths
and lies about personality-related attitudes, beliefs, and values. The results of
experiment fourteen are provided in the bottom half of table 11.1.
The accuracy findings didn’t replicate the earlier findings neatly. Accuracy
was overall about five points lower, and the pattern was different. Whereas
moderate suspicion was clearly the highest in the 1990 study, in the 2011 version, low and moderate suspicion produced about the same accuracy, and the
high-suspicion condition was the stand-out, with only 48% correct. But let’s
focus on the truth-bias findings.
While the accuracy results were different, the truth-bias results were quite
similar. Just as was the case in the first experiment, suspicion reduced truth-
bias but did not eliminate it. Both experiments show a linear decrease in truth-
bias as a function of increased suspicion,18 but even under high suspicion,
judges pick honest more often than lie. Truth-bias is robust.
WANT MORE DATA?
Experiments thirteen and fourteen document the robust nature of truth-bias.
The importance of experiment thirteen for the current discussion is largely
historical, and experiment fourteen shows that the conclusions about truth-
bias are not unique to the nature of the subjects (dating couples or strangers),
the type of lies (attitudes-beliefs or covering transgressions), or the times (late
1980s or early 2000s). These experiments make the point about the power of
truth-bias nicely because both show truth-bias even under suspicion. But when
specific studies are selected as examples, a critical reader might wonder how
representative the results really are. To preempt any concern regarding cherry-
picking results, table 11.2 provides observed truth-bias scores in my research
over the past twenty-five years. As you can see, subjects in my experiments
are always truth-biased.

Table 11.2. Truth-bias in my research
Experiment

Truth-bias

Experiment

Truth-bias

TDT experiment 10

72%

TDT experiment 29

54%

TDT experiment 11

68%

TDT experiment 30

56%

TDT experiment 12

70%

TDT experiment 31

66%

TDT experiment 13

72%

TDT experiment 32

61%

TDT experiment 14

71%

TDT experiment 28

69%

TDT experiment 15

58%

TDT experiment 39–441

54%

TDT experiment 16

88%

TDT experiment 45

70%

TDT experiment 17

68%

TDT experiment 46

67%

TDT experiment 18

66%

TDT experiment 47

60%

TDT experiment 19

64%

TDT experiment 48

53%

TDT experiment 20

65%

Group experiment

2

66%

TDT experiment 21

63%

59%

TDT experiment 24

63%

LSS2010 background
questioning3

TDT experiment 25

62%

LSS2010 direct question

60%

TDT experiment 26
TDT experiment 28

56%
56%

4

LSS2010B

Probing experiment 1
Probing experiment 3

61%
5

72%
56%

1

Control conditions only, averaged across studies.

2

Ernest S. Park, Timothy R. Levine, Chad M. Harms, and Merissa H. Ferrara, “Group and Individual

Accuracy in Deception Detection,” Communication Research Reports 19, no. 2 (2002): 99–106, https://
doi.org/10.1080/08824090209384837.
3

Timothy R. Levine, Allison Shaw, Hillary C. Shulman, “Increasing Deception Detection Accuracy

with Strategic Questioning,” Human Communication Research 36, no. 2 (April 2010): 216–31, https://
doi.org/10.1111/j.1468-2958.2010.01374.x.
4

Timothy R. Levine, Allison Shaw, Hillary C. Shulman, “Assessing Deception Detection Accuracy

with Dichotomous Truth–Lie Judgments and Continuous Scaling: Are People Really More Accurate
When Honesty Is Scaled?” Communication Research Reports 27, no. 2 (2010): 112–122, https://doi.
org/10.1080/08824090903526638.
5

Timothy R. Levine and Steven A. McCornack, “Behavioral Adaptation, Confidence, and Heuristic-

Based Explanations of the Probing Effect,” Human Communication Research 27, no. 4 (October 2001):
471–502, https://doi.org/10.1111/j.1468-2958.2001.tb00790.x.

184

CHAPTER ELEVEN

MODERATORS OF TRUTH-B IAS
While truth-bias is very robust in existence, as we saw with suspicion, it does
vary systematically in degree. Look at table 11.2 again. Subjects are always
truth-biased (honesty judgments are over the 50% threshold), but they are
not always truth-biased to the same extent. Values range from as high as 88%
to as low 53%. Clearly, sometimes people are more truth-biased than at other
times. Below are some of the more important variables known to impact the
extent to which people are truth-biased.
• Experimentally primed suspicion—The more suspicious, the lower the
truth-bias (as shown in TDT experiments thirteen and fourteen). As
can be seen in table 11.1, primed suspicion can make almost a 0.20
difference in truth-bias.
• Closeness of relationship—Truth-bias increases as the relationship between communicators becomes closer.19
• Face-to-face interaction—Truth-bias is higher when communicating
face-to-face than otherwise. Within various media, truth-bias is
higher when there is audio than when there is video only. Truth-bias
averages 0.55 with no interaction, 0.65 with direct face-to-face interaction, 0.52 with video only, 0.56 with audio-visual, and 0.63 with
audio only.20
• Mere question asking—In a finding called “the probing effect,” senders who are answering a heard question are seen as more honest
than when the same answer is judged, just absent the question. The
size of the difference is a little less than 0.10.21
• Students vs. experts—Student judges are more truth-biased than experts (like police). The difference, however, is fairly small: 0.56 for
students down to 0.52 for experts.22
• Sender demeanor—Some senders are much more believable than
others regardless of actual honesty. Demeanor seems to be the
strongest of the moderators, creating differences larger than 0.30
(from 0.36 for insincere demeanor to 0.69 for sincere senders).23 I
cover demeanor findings in detail in chapter 13.
In each case, the general conclusion is that human judges are truth-biased,
but truth-bias is more or less pronounced under some conditions. Further,
the six variables listed above affect truth-bias much more than they impact
accuracy.24

TRUTH-BIAS AND TRUTH-DEFAULT

185

THE TRUTH-D EFAULT
The truth-default involves a passive presumption of honesty. People typically
presume without conscious reflection that others’ communication is honest.
My thesis is that the possibility that a message might be deception does not
even come to mind unless suspicion, skepticism, or doubt is actively triggered.
The truth-default state has three parts: truth, default, and state. By a default,
I mean a passive starting place. You don’t have to do or think anything. For example, as I type this sentence, I have the default font in my word-processing
software set to twelve-point black Calibri. I can actively change the font to make
it bold, or italic, or larger, or smaller, or some color other than black. If I do
nothing and just start typing, black twelve-point Calibri print shows up on my
screen. This default usually works well for me, and I don’t change it unless I
need to. Further, I don’t even need to think about the font most of the time.
I can focus on what I am trying to say, sentence structure, word choice, and
the like. As I type this, I wouldn’t be thinking about the font at all if I weren’t
offering it as an analogy.
TDT holds that when communicating with others, the default cognitive state
is belief. This is the truth part. If we don’t change the default, we presume that
what we hear (or see or read) is honest and truthful.
By state, I mean the particular condition at a particular time. Since the
truth-default is a cognitive state, it is a particular state of mind at a particular
time. States exist “at the moment,” and states can change. Putting this all together, the truth-default is a default state of mind where we accept or believe
others’ communication.
We believe other people unless we actively decide not to. Changing or temporarily turning off the truth-default state requires some sort of trigger.25 A trigger is anything that catches our attention and gets us to consciously consider
the veracity of some communication. We will talk about some specific triggers
later when we lay out TDT proposition seven, but for now it is sufficient to
say that some triggers, once pulled, can switch off the truth-default autopilot
and get us thinking about whether some communication might be deceptive.
Once active consideration of the possibility of deception is triggered, three
additional cognitive states become possible: a belief that some communication
is deceptive, an active assessment that the communication is honest, or an intermediary state of suspended belief and uncertainty. We start with the initial
presumption of honesty—the truth-default. If we are kicked out of the truth-
default by some trigger event, either we can become suspicious and uncertain
about honesty, or if there is good reason to do so, we go straight to the belief

186

CHAPTER ELEVEN

that the communication is in fact deception. If there is a suspicion-uncertainty
state, we will not stay in that state indefinitely. The suspicion state will end in
one of three ways. We might make an active determination of deception. Or,
if exculpatory evidence is discovered, we will make an active determination of
honesty. However, lacking evidence one way or the other, we will eventually
revert to a passive truth-default.26 The idea is akin to the sleeper effect in persuasion research in which a low credible source, over time, can become more
influential as people forget the source but remember the message.27
Putting this all together, there are four cognitive outcomes related to inferences about the honesty and deceitfulness of others’ communication. The
most common situation is that the question of deception never occurs to us.
The truth-default stays in place, and we passively presume the communication was honest. Second, something can spark suspicion, and we actively consider the possibility of deception but consciously decide that the person was
honest and that the suspicion was unfounded. Third, we can become suspicious but never really find out one way or another. Over time, the suspicion
will fade, and we will unconsciously revert to the truth-default. Finally, a trigger event can kick us out of the truth-default, and we can decide that we were
deceived (or at least that the other was trying to deceive us).
The we-judge-something-is-deception outcome can play out before the message is even received, immediately upon receipt, or (most commonly) well after
the fact. We can, of course, go into situations expecting deception. Or, the suspicion or assessment of dishonesty can occur as the message is received. This
typically happens when there is something in the content or presentation that
does not seem right. Perhaps the message contradicts prior knowledge or
seems too implausible. Maybe the person is acting oddly. Finally, assessment
of dishonesty can occur well after the fact when new information comes to
light showing that a previously believed message was deceptive. The reverse
is also possible; new information can lead us to change our minds and conclude that a message once thought deceptive was actually honest. Inferences
about honesty and deception need not be final, and trigger events can happen
before, while, or after the communication takes place.
The idea of the truth-default is consistent with Harvard social psychologist
Dan Gilbert’s Spinozan model of belief, in which incoming information is believed unless subsequently and actively disbelieved.28 Gilbert was interested in
how people mentally represent true and false information. A mental representation simply means thinking about or understanding something and holding that thought in mind. In line with the fifteenth-century Dutch philosopher Baruch Spinoza, Gilbert’s idea is that the belief that some information is

TRUTH-BIAS AND TRUTH-DEFAULT

187

true is a default that comes automatically with comprehension. To understand
something, we must, at least momentarily, accept it. People can unbelieve, but
unbelieving comes later and is conscious and controllable; initial belief is automatic. Gilbert and his colleagues published six experiments showing that if
people are distracted from evaluating information, they tend to mistake truth
for fiction more than mistaking fiction for truth.29
The truth-default is also consistent with Grice’s logic of conversation (discussed in chapter 8), wherein people generally presume communication is
fundamentally cooperative. That is, people typically make sense of what others
say based on the premise that others are trying to be understood. We must do
this to make sense of what others say, because what is literally said and what
is meant are not always the same.
The TDT perspective is that we humans evolved to have a truth-default.
The reason we evolved this way is that the truth-default is adaptive. The truth-
default works well for us both as individuals and as a species.
Humans are, at our very core, social beings. Our survival as individuals
and our success as a species depend on in-group cooperation. Cooperation requires efficient communication. The truth-default enables efficient communication. It is a prerequisite. Without the truth-default, communication falters. It lets us form friendships, lasting spousal relationships, and cooperative
work groups. It lets us maintain family ties, engage in commerce, and pass
on useful knowledge. Efficient communication serves us well, and this is why
the truth-default evolved.
As I said, we humans are social down to our cores. I can’t emphasize this
enough. Social interaction with other humans is our nature. We are born with
an amazing ability to pick up language and to learn to communicate with other
humans. Our whole lives are spent interacting with others. Nothing is as important to us as our social ties with other humans. Without others, we can’t
survive. Even if you are a competent hermit-survivalist who can hunt, gather
and grow your own food, and make your own weapons, clothes, and shelter,
you didn’t learn those skills on your own. You learned things from others. We
humans not only cooperate but also pass down knowledge. Cooperation and
passing along knowledge are central to the human condition.
Try this thought experiment. Consider for a moment the alternative to a
truth-default. What would life be like? Absent a basic and deep presumption
of honesty and validity of communication, cooperating with and learning from
others would be perilous and uncertain. We’d constantly be second-guessing
everything. Why cooperate if you have no reason to expect cooperation in return? What is the point of learning if what is learned might be disinformation?

188

CHAPTER ELEVEN

The very fact that you are reading my book would make little sense if you had
to second-guess every word and idea.
I’m currently reading Liars and Outliers by Bruce Schneier.30 The subtitle is
Enabling the Trust That Society Needs to Thrive. The ideas Schneier talks about
are very much in line with TDT, although TDT is more narrowly focused on
communication and deception, and Schneier’s focus is more macro and at the
level of society. The basic logic is the same. Society requires trust to function
well. The erosion of trust leads to chaos and anarchy. Schneier calls people who
play well with others, who follow the rules, and who are trustworthy “coopera
tors.” Most people are cooperators. But where there is trust, there are those
who exploit others. Schneier calls such noncooperative people “defectors.” Society creates and enforces rules to punish defectors and keep the harm they
do to a minimum. The fewer defectors, the more trust. The deeper the trust,
the more gained from violating trust, and the greater the incentive to defect.
Societies get to an equilibrium state, with some proportion of cooperators and
defectors. The fewer the defectors, the better for society.
Just as society requires trust to function, so too does communication require
the presumption of honesty, the truth-default. Without a truth-default, communication would lose efficiency and, ultimately, utility. Most people are honest,
so the truth-default works well for most people most of the time. Communication works. But the presumption of honesty enables successful exploitation
by deception and deceivers. Society makes and enforces rules to discourage
deception, thereby facilitating efficient communication. This makes deception
much less prevalent than honesty, but it does not prevent deception altogether.
The truth-default makes us vulnerable to deception. The truth-default and
the risk of deception involve a trade-off. But the trade-off is a good one. This
is where TDT departs from almost all evolutionary thinking about deception.
I have heard and read the argument many times that since humans evolved to
deceive, we must have evolved the ability to detect deception. Evolution, it is
argued, necessitates a coevolutionary arms race between the ability to deceive
and the ability to detect. While I don’t doubt basic evolution and the idea that
humans have evolved, I do not think that accepting evolution requires accepting a coevolutionary struggle between the ability to deceive and the ability to
detect deception in real time.
There are at least four reasons why I don’t buy the coevolutionary arms-race
argument. First and foremost, TDT sees the tradeoff between the truth-default
and the risk of deception as a great deal for us. What we get in exchange for being vulnerable to an occasional lie is efficient communication and social coordination. The benefits are huge, and the costs are trivial in comparison. Sure,

TRUTH-BIAS AND TRUTH-DEFAULT

189

we get deceived once in a while. That is just the cost of doing business. It’s
like going through security at an airport. We get much benefit out of smooth
and efficient travel. We could evolve a security screening system where every
passenger is strip-searched, every bag is triple checked, and every passenger
is fully interrogated every time. No doubt we would be safer. But that would
bog down the system, and most times the harm caused by being deceived isn’t
fatal. Most deception is not as serious as a terrorist with a bomb boarding a
plane. Being deceived once in a while is not going to prevent us from passing
on our genes or seriously threaten the survival of the species. Efficient communication, on the other hand, has huge implications for our survival. The
trade-off just isn’t much of a trade-off. The risk simply doesn’t justify a coevolutionary struggle.
Second, evolving the cognitive ability to detect lies in real time is not the
only evolutionary solution for dealing with the risk of deception. By analogy,
there is no need to evolve resistance to a new disease if we can invent a vaccine. This is what we humans have done. We have created cultures, religions,
and socialization that seek to prevent deception. Parents everywhere teach
their children not to lie. Every major world religion has prohibitions against
deception. Prevention is not 100% effective. There are the few prolific liars
out there. Prevention reduces the prevalence and risk of deception to make
the truth-default payoff stronger. It’s more efficient to prevent deception than
to evolve brains well suited to real-time deception detection. Evolution favors
the more efficient solution.
Third, social interactions in social species are often not one-offs. People talk
among themselves about other people. This reduces the need for real-time deception detection and creates further deterrence against dishonest behaviors.
As we will see in chapter 14, many if not most lies are discovered well after
the fact. As we have seen already, most lies are told by a few prolific liars. It’s
the prolific liars we need to worry most about. So, once a prolific liar has been
identified, we can know to be on guard when dealing with him or her. Better
yet, maybe we can just avoid that person. We can also warn others; the word
gets out. What I am suggesting here is that the truth-default means we will
get burned by deception once in a while. But we can learn and not repeat past
mistakes, and we can pass that information along. Once a prolific liar is outed,
his or her ability to deceive is reduced. Also, prolific liars may be shunned and
shamed, enhancing deterrence. This also reduces the need for coevolution.
Fourth, empirically, we are not good real-time lie detectors. This was the
take-home message from chapter 3. If there was a coevolutionary struggle mandated by evolution, this would not be the case. We would expect much better

190

CHAPTER ELEVEN

performance in lie detection experiments. Research findings are much more
in line with a truth-default view than the arms-race speculation.
The bottom line is that as long as the prevalence of deception is low and
the harm caused isn’t catastrophic, a truth-default makes good sense. But how
can we research a cognitive default? It is, after all, passive and operates outside conscious awareness. Even thinking about it makes it go away. We know
people are typically truth-biased, but documenting truth-bias does not provide
convincing evidence for the truth-default because they are not the same thing.
The truth-default offers one explanation for the empirical observation of
truth-bias, but the concepts are not interchangeable. Truth-bias need not reflect a cognitive default, especially as measured in deception detection experiments. The results in table 11.2 and other prior deception research involved
prompted active assessment of honesty. In fact, if TDT is correct, truth-bias
rates (i.e., the proportion of messages believed) would be much higher in research if the possibility of deception was not primed by the research setting
and measurement instruments. Knowing that one is in a deception detection
experiment and requiring truth-deception assessments as part of the research
protocol should create an active assessment of honesty and deceit that often
may not occur in communication outside the deception lab. Prompted judgments are antithetical to the very idea of the truth-default.
TDT EXPERIMENTS FIFTEEN AND SIXTEEN:
DAVID CLARE AND EVIDENCE FOR THE TRUTH-D EFAULT
In experiment fourteen, I introduced Rachel Kim, my student, research assistant, and lab coordinator. David Clare started his graduate work about the time
Rachel moved on, and David took Rachel’s place as my lab assistant. David did
both his master’s degree and his PhD under my direction. As of this writing,
Dr. Clare is a data scientist working in Washington, DC. We collaborated on
many experiments. For his preliminary research paper, David set out to provide direct evidence for the truth-default.31 Well, sort of.
I think David and I were interested in experiments fifteen and sixteen for
different (but related) reasons. Documenting the truth-default state was my
main interest. I see these experiments through the lens of TDT. I think David
was more interested in the methodological issue of prompted truth–lie judgments as related to ecological validity. He was also (or at least became) very
interested in the issues addressed in TDT propositions seven through nine,
discussed at the close of this chapter.
The last chapter examined ecological validity in relation to deception motives and the instructed lies that populate most experiments. Prompting truth–

TRUTH-BIAS AND TRUTH-DEFAULT

191

lie judgments also raises ecological concerns by explicitly asking research subjects whether a source is lying. If there really is a truth-default, questions of
honesty and deception typically do not come to mind during normal communication situations. The very act of asking about deception therefore makes
the task in the lab very different from many non-research settings.
TDT propositions seven through nine talk about trigger events and the conditions under which people infer that others are lying. David was very interested in when people believe others and when people don’t. David and I designed two experiments to try to get at the twin questions of (1) whether the
very act of prompting deception judgments affects assessments of honesty
and deception, and (2) absent prompting, whether issues of honesty and deception even come to mind.
We predicted, of course, that prompting deception judgments by asking explicit truth–lie questions would reduce truth-bias in comparison to no prompting. We also predicted evidence for the passive truth-default. That is, we predicted that thoughts of honesty and deception might not come to mind without
prompting. We thought that thoughts about honesty and deception might some
times come to mind even absent experimental prompting or priming, but we
just didn’t know how often. The idea of a truth-default requires that we don’t
constantly monitor communication for deception. But would thoughts of honesty and deception come to mind one-third of the time or only one in ten times?
Experiments fifteen and sixteen had very similar (and complex) designs.
In both experiments, subjects were in both prompted veracity judgment and
unprompted veracity conditions. In the prompted condition, subjects were explicitly asked whether they thought the communication was honest or deceptive. Subjects were instructed to circle either “truth” or “lie” after each in a series of messages. In the unprompted condition, we just asked subjects to list
open-ended what they were thinking. Then we coded the thoughts for anything related to truth, lies, honesty, or deception. Half the subjects did the
prompted first, then the unprompted. The other half did the unprompted,
then the prompted.
In both experiments, the communication was a get-to-know-you interview
where the interviewee told truths and lies about autobiographical information. Besides prompting, the lack thereof, and order (prompting first or sec
ond), the other variables in the experiments were plausibility of content and
actual honesty. All subjects were exposed to plausible and implausible truths
and lies. There were seventy-two participants in experiment fifteen and sixty-
eight participants in experiment sixteen. The difference between the two experiments (besides just that different subjects participated) was that experi-

192

CHAPTER ELEVEN

ment fifteen involved watching videotapes, and experiment sixteen involved
live face-to-face interaction between the subject and a confederate.
In experiment fifteen, prompted judgments yielded typical levels of truth-
bias (58% of messages judged as truthful). Regarding the unprompted thoughts,
when the unprompted thoughts were first, thoughts related to honesty or deception occurred in response to only 4.23% of the messages. That is, more than
95% of the time, the thoughts people listed had nothing to do with truths and
lies, honesty, or deception. Things were very different, however, for the people
who did the prompted explicit truth–lie judgments first. Those subjects mentioned something related to veracity on 39.58% of the messages.
The results of experiment sixteen were even more extreme. Even with
prompted judgments, there was massive truth-bias: 88.43% of the prompted
judgments were honest. When unprompted assessments were first, fewer than
1% of the messages (0.57%) generated listed thoughts related to honesty or deception. There were more veracity-related thoughts when the prompted task
was first, but most of the time nothing related to honesty or deception was
mentioned (average = 8.46%).
These results are stunning. The truth-default looks stronger than even I
expected. In pretty much every prior deception detection experiment, subjects made truth-deception determinations because they were asked to. When
asked, people think about it and circle “honest” more often than “deception”
or “lie.” But without prior prompting, when asked the open-ended “What are
your thoughts about the person’s answer?” participants’ thoughts (or at least
the thoughts that they listed) usually had nothing at all to do with honesty or
deception. Questions of honesty, veracity, lying, and deception didn’t come
to mind. Unprompted consideration of anything related to honesty or deceit
came to mind less than 5% and 1% of the time in experiments fifteen and sixteen respectively.
From my point of view, the results of experiments fifteen and sixteen pretty
much seal the deal for the idea of the truth-default. Before TDT, no one ever
thought to do this sort of study. It is an obvious experiment to do, yet no one
did it. Once the experiments were done and the results were in, there seemed
to be absolutely compelling evidence for a truth-default. That veracity-related
thoughts were listed only 5% and 1% of the time absent prompting is perfectly in line with TDT. This held even with implausible truths and lies! Wow!
The results also align with David’s concerns regarding the ecological validity of typical deception experiments. There seems little doubt that directly
asking subjects about honesty and deception prompts thoughts that do not
otherwise occur to the subjects.
Although we will get into this more in the final chapter, David’s experiments

TRUTH-BIAS AND TRUTH-DEFAULT

193

also move us much closer to solving the previously noted mystery of deception accuracy in research not about deception. Certainly a key difference between research about deception detection and deception in research that is not
about deception is that in deception research, subjects are asked about deception, bringing the question of deception to mind. So simple.
BREAKING OUT OF THE TRUTH-D EFAULT:
SUSPICION AND LIE JUDGMENTS
Experiments fifteen and sixteen show that a truth-default state can exist. The
results also show that absent prompting, the truth-default is pervasive. Prompting made a big difference. People can and do abandon the truth-default when
prompted. In the lab, prompting is accomplished by research instructions and
questions asking subjects to assess whether someone is honest. TDT holds
that prompting happens outside the lab too. Trigger events can lead people
to temporarily abandon the truth-default and actively assess others’ honesty.
TDT proposition seven lists five triggers.
TDT Proposition Seven: The truth-default state requires a trigger event
to abandon it. Trigger events include but are not limited to (a) a projected
motive for deception, (b) behavioral displays associated with dishonest
demeanor, (c) a lack of coherence in message content, (d) a lack of correspondence between communication content and some knowledge of reality, or (e) information from a third party warning of potential deception.
We have discussed projected motives and will later address in detail sender
demeanor, coherence, correspondence, and third-party information, all of which,
according to TDT, can trigger suspicion. Surely these are not the only things
that can trigger suspicion. My goal is not to provide an exhaustive or comprehensive list but instead to prioritize by offering a short list of triggers that fit
well within the logic of TDT.
TDT Proposition Eight: If a trigger or set of triggers is sufficiently potent, a threshold is crossed, suspicion is generated, the truth-default is
at least temporarily abandoned, the communication is scrutinized, and
evidence is cognitively retrieved and/or sought to assess honesty–deceit.
I define suspicion as a state of suspended judgment and uncertainty regarding the honesty or deceptive nature of a communication. It is an inter
mediate cognitive state between the passive truth-default and a firm judgment
of deceit. Proposition eight sets up the first of two thresholds. The first thresh-

194

CHAPTER ELEVEN

old is when the truth-default state gives way to suspicion. The second threshold is established in proposition nine.
TDT Proposition Nine: Based on information of a variety of types, an evidentiary threshold may be crossed, and a message may be actively judged
to be deceptive. The information used to assess honesty and deceit includes but is not limited to (a) communication context and motive, (b)
sender demeanor, (c) information from third parties, (d) communication coherence, and (e) correspondence information. If the evidentiary
threshold for a lie judgment is not crossed, an individual may continue
to harbor suspicion or revert to the truth-default. If exculpatory evidence
emerges, active judgments of honesty are made.
Propositions seven and nine offer similar lists. The difference is in intensity. It takes more to see a message as deception than to trigger the suspicion
that a message might be deceptive.
I debated whether to explicitly list message plausibility in propositions seven
and nine. Plausibility is among the strongest cues related to assessments of
honesty and deception, and it is among the most valid.32 However, I’m not
sure mere implausibility is sufficient as an initial trigger. In experiments fifteen and sixteen, once prompted by the explicit requirement to assess honesty,
implausible information was more likely to be judged as dishonest (regardless of actual honesty) than plausible messages. However, absent prompting,
plausibility made little difference. This might suggest including plausibility in
proposition nine but not proposition seven. Although I didn’t formally include
plausibility in proposition nine, I’m OK with adding it. Or perhaps plausibility
could be included within correspondence information, because implausible
statements lack correspondence with what is typical or normal.
Toward the end of chapter seven I tell the amusing story of being named
September’s researcher of the month, and of the poster with the fake biographi
cal information. Even though the content was far-fetched (I was a star basketball player selected in the NBA draft and a member of a famous rock bank),
many people were duped. This account exemplifies the impotency of plausibility as an initial trigger.
IS THE TRUTH-D EFAULT JUST AN IN-G ROUP THING?
The logic behind the truth-default makes the most sense in the context of in-
group interaction. Our in-groups are people with whom we share some common identity or group membership. In-groups might include people of the

TRUTH-BIAS AND TRUTH-DEFAULT

195

same ethnicity, the same political affiliations, the same religious beliefs, people
we work with, family, and the like. Members of our in-groups are the people
with whom we cooperate and most frequently interact. As work on intergroup
conflict and prejudice shows, members of out-groups can be seen as threats
and viewed with suspicion.33
Contemplating the application of the truth-default in intergroup interaction
is challenging for TDT. It exposes an ambiguity. Here are my current, albeit
tentative, best guesses. I would expect that as a general rule both truth-bias
and the truth-default would be stronger and more persistent in in-group interaction than in intergroup interaction. I would not think that the mere fact that
someone is a member of an out-group would be sufficient to dissolve truth-
bias and the truth-default, unless there was intense hostility or conflict between groups. I would nevertheless expect the thresholds for suspicion and attributions of deceit to be lower for communication by out-groups or out-group
members than for in-groups. That is, I expect TDT to hold for both in-group
and intergroup interaction, but I expect trigger sensitivity to be higher in intergroup communication relative to in-group interaction.34
CHAPTER SUMMARY
This chapter is all about the two most central ideas in my thinking about deception: truth-bias and the truth-default. Truth-bias is the tendency to believe
others regardless of whether or not they are honest. Truth-bias is definitely a
tried-and-true finding in deception research. It was the realization of just how
strong truth-bias is, and the curiosity about why this is the case, that sent me
down the path toward TDT.
Back in the old days, twenty to thirty years ago, when I first started to research truth-bias, I thought of it as a product of flawed and lazy thinking. Bias
loomed large in my understanding of truth-bias. But gradually my thinking
began to change. This change is further described in the next chapter, when
we get to the veracity effect and base-rates. For now, it is sufficient to say that
I believe that truth-bias is good for us. Truth-bias and the truth-default let
us communicate efficiently with other humans. They are essential for social
functioning.
The truth-default state is the idea that we often passively believe others’
communication, and the thought of deception does not come to mind unless suspicion is triggered. TDT experiments fifteen and sixteen showed that
this was case. Nevertheless, trigger events can kick us out of the truth-default
state, and this chapter describes the conditions under which suspicion and lie
judgments happen.

196

CHAPTER ELEVEN

The next chapter follows up by discussing the two big implications of truth-
bias for deception detection research. These I call the veracity effect and base-
rates. Chapters 9 (prevalence of deception), 11 (truth-bias and truth-default),
and 12 (veracity effects and base-rates) combine to form the core of TDT. Together, the ideas and research findings described in these three chapters make
the case for why the truth-default and truth-bias are functional and adaptive.
So, let’s get on to chapter 12 to wrap up this part of TDT.
