
5
Critiquing the Rivals
The previous chapter describes several prior theories of deception. In
this chapter, I evaluate those theories. I also offer here the idea of cue theories
as a meta-theoretical umbrella that captures the core logic underlying most
deception theory and research in the social sciences.
CRITERIA
Since this chapter involves assessing the viability of several theories, I briefly
address here my criteria for assessing the quality of theory. Good theories
have many desirable qualities that contribute to their theoretical merit. A good
theory, for example, must be coherent. That is, all the parts of the theory must
fit within a common logic, and all parts of a theory must be logically consistent with one another. A good theory must also be unambiguous. It needs to
be clear what a theory predicts and why. Wishy-washiness and fence-sitting
are not virtues when it comes to theory. Instead, theoretical ambiguity leads
to confusion and a lack of falsifiability. A good theory is also efficient and will
explain a lot with relatively few principles. The more ground covered with the
fewest moving parts, the better.1 Good theory needs to be generative. A theory
points researchers in new directions and leads to new findings that people
would not have otherwise considered.
Most of all, good theory needs to lead to new predictions that turn out to be
right. That is, theories need to provide valid knowledge, prediction, and explanation. A theory’s predictions need to be testable and verifiable. When tested
against data, empirical findings must be consistent with the theory. Supportive
results need to replicate. Theories that offer explanations, no matter how assertive, coherent, elegant, efficient, creative, and unambiguous, that turn out to be
empirically false are myths. Correspondence with evidence is the bottom line

CRITIQUING THE RIVALS

75

for scientific theories. Research findings must not contradict the theory, and
if research findings repeatedly contradict the theory, the theory must be modified or discarded, and new, more empirically adequate theories must be sought.
The word “verisimilitude” captures well the most important consideration in
evaluating a theory. The trick, of course, is distinguishing verisimilitude from
“truthiness.” The author-researchers behind all the major competing theoreti
cal perspectives in the academic study of deception claim empirical support
for their ideas. Authors have ready answers for apparent failures, and they
are often quick to point out the empirical deficiencies of their rivals. What is
a reader to think? Debates over theories can seem like scientific he-said-she-
said. There is a risk of research consumers concluding that everything is just
a matter of opinion, that all theories are “just theories” in the sense that they
are mere conjecture, and that all approaches are equal in scientific merit (or
lack thereof ).
Consistency with data is the primary goal of my theory-building endeavors, and it is the primary criterion I use to judge the adequacy of rival theories. The main questions I ask in evaluating each theory are: (a) are the data
consistent with the theory’s predictions, and (b) do the findings contradict the
logic of the theory? As we learned in chapters 2 and 3, there are vast quantities
of data from prior research, and those data provide a reasonably coherent empirical picture. It is my contention that many of the theories reviewed in the
previous chapter do a poor job of explaining the existing empirical findings
and that a very different set of empirical findings would be expected based on
the logic and predictions of the various theories.
There is one criterion for evaluating theory that I purposely avoid. I am
not going to ask, “Is it even a theory in the first place?” Personally, I prefer a
strict and narrow definition of theory. My preferred definition of theory might
be something like “a unifying, logically coherent set of interrelated conjectures that makes novel predictions and explains some phenomenon or phenomena.” Other scientists and scholars use the term much more loosely. As
a consequence, some “theories” are theories under some definitions of theory
but not others. It has been my observation that a great many academic arguments are just disagreements about how something is defined, and such arguments often lead nowhere. So I leave it to other authors to debate what counts
as theory in deception.2
CRITIQUING THE RIVALS
It is time to explain what problems need to be overcome and why my new
theory is needed. My critique begins by presenting the idea of cue theories as

76

CHAPTER FIVE

a meta-theoretical approach to understanding deception. Cue theories, I argue,
lack verisimilitude and have retarded theoretical advances by trapping new generations of researchers in the same old intellectual ruts.
Cue Theories
I introduce the idea of cue theories as an umbrella term that captures and integrates the basic ideas running through so much of the research on deception detection.3 I see the divide between cue theories and non-cue theories as
perhaps the most fundamental issue in deception theory. I believe that breaking out of cue-theory mind-lock is the best chance for progress. Thinking in
terms of cues and the psychological processes that produce cues blinds researchers to useful alternatives and weds them to limiting research designs
that have led to repeated dead ends in the past.
The core logic of cue theories goes like this:
1. Truths and lies are psychologically different. How truths and lies are
different varies from theory to theory, but examples include emotional states (fear of detection, guilt about lying, duping delight),
autonomic nervous system arousal, cognitive load or effort, strategic
efforts to appear honest, planning for deception, and willingness to
be forthcoming.
2. T he psychological states produced by deception, in turn, are behaviorally signaled by observable cues. Thus, the psychological states
in number 1 above mediate and explain the relationship between
truths–lies and cues.
3. T herefore, deception can be detected (albeit indirectly and probabil
istically) through observation of the cues arising from the mediating
psychological states associated with deception. This is either possible through passive observation or requires additional prompting.
But deception can be detected under certain conditions (e.g., high
stakes in Ekman, prompting in Vrij, long naturalist interaction in
Burgoon, etc.) through the observation of cues.
Examples of cue theories include Ekman’s work, four-factor theory, IDT, and
the Vrij approach. The various psychological mediators are different. Ekman
focuses primarily on emotion, Vrij focuses mostly on cognitive effort, and IDT
talks about strategic and nonstrategic processes. I have no doubt that the advocates of the various cue theories will vehemently object to being lumped to-

CRITIQUING THE RIVALS

77

gether with rival cue theories. The authors of specific cue theories are typically
very critical of other cue theories. But all of the theories have the same fundamental logical structure and differ only in the fine print.
Not all deception theories, however, share cue theory logic. DePaulo’s self-
presentation approach is predicated on honest and deceptive self-presentations
being (mostly) psychologically similar. Everyone wants to make a good impression and to be seen positively by others. IMT2 sees the message production
processes for truths and deception as the same. And in my own TDT, cues
and the psychological processes that produce cues play no role in accurate lie
detection.4 In my view, the motives that guide communication are the same
for truths and lies, and the path to improved deception detection is through
contextualized communication content and persuasion rather than the observation of cues.
The empirical failure to document cues that reliably distinguish between
truths and lies seems, on its face, to deal a fatal empirical blow to cues theories. But, both theoretically and empirically, things are not so simple. D
 ePaulo’s
5
famous cue meta-analysis was far from a clean kill. Instead, I believe the academic literature on deception is populated by several undead cue theories,
some of which are in advanced states of decomposition (four-factor theory),
while others are quite active and ravenous (IDT and especially Vrij).6 These
undead theories cannot be stopped merely with disconfirming scientific evidence. If that were the case, they would be dead and would have stayed dead.
They would not attract so much taxpayer funding, and they would not repeatedly survive scientific peer review.
Empirically, one problem is that at the level of the individual study, there
are almost always strong cue effects.7 Because there are almost always significant cue findings at the level of the individual study, and because the “significance” of a specific test in a specific study is unfortunately the conventional
currency marking scientific worth, authors of individual studies can almost always claim support for their hypotheses. Review articles summarizing the literature can provide long lists of citations as evidence for a preferred theory. Ultimately, of course, such findings lead precisely nowhere because specific cue
findings are ephemeral and don’t replicate. For every supportive finding, there
are findings suggesting just the opposite. Meta-analysis eventually shows that
the emperors and empresses have no clothes. Still, it is difficult to launch decisive empirical arguments against cue theories because their advocates can provide long lists of supportive evidence from individual studies. It comes down
to one group of scientists listing evidence for one view while another group

78

CHAPTER FIVE

cites loads of evidence for the exact opposite position. What is a research consumer to think? The empirical deficiencies of cue approaches require sophisticated understandings of things like overfit models8 and p-hacking9 that can
be lost on the casual bystander or the average researcher. I hope to convince
the reader, however, to see past the smoke and mirrors and the he-said-she-
said, to the empirical big picture that led me to reject cue theories.
Theoretically, as the philosopher of science Imre Lakatos describes, theories often have a self-defensive logic built in that lets them explain away problematic findings.10 Perhaps the best example is Ekman’s perspective, where
the role of stakes and, to a lesser extent, the use of student data provide a convenient data-dismissal mechanism that can vaporize pesky anomalous findings.11 The circular logic goes like this:
1. Cues are expected only when lies are high-stakes.
2. Because cues were not observed, the deception was not high-enough-
stakes.
3. T he deception was not high-enough-stakes because no cues were
observed.
Or, more generally:
1. Our theory is right.
2. If the data are inconsistent with our theory, that’s because you did
the research wrong.
3. We know there was a problem with your nonsupportive study because the data didn’t support our predictions.
In IDT the vague use of strategic and nonstrategic actions, eschewing
percentage-correct accuracy as a bottom line, the degrees of interactivity, and
the duration of communication all play protective roles. Vrij’s work, too, often
avoids easily understood metrics like percentage-correct accuracy. The result
is that most cue theories have internal logics and research practices that protect them from the data. These adaptations allow them to survive in an otherwise uninhabitable empirical world.
Before presenting more of my own critique, two strong and historically noteworthy critiques of the deception literature are briefly summarized. In rereading Kraut and McCornack articles for this chapter, I was struck by how ahead
of their time each was. I can’t help thinking that if Kraut and McCornack had

CRITIQUING THE RIVALS

79

had greater influence, deception research would be in so much better shape
today. They are spot on-target.
KRAUT 1980 CRITIQUE
Here is how Kraut began his argument in 1980: “I will argue that much research on human lie detection has been misguided. Specifically, researchers
who have expected high accuracy in perceivers’ judgments of deception or
valid and easily observable cues to deception have been misled in their expectations by the expressive approach to nonverbal communication and by psycho
physiological work on lie detection. The standard assumption of most nonverbal communication research, that nonverbal behavior expresses a person’s
internal states, has blinded researchers to a priori arguments that no such cues
should exist as indicants of deception.”13
Note that the quotation of Vrij and Granhag in the previous chapter placed
the turning point for them at 2003. Kraut was making the case twenty-three
years earlier! Kraut pointed out way back in 1980 the now very well-documented
findings that accuracy is only slightly-better-than-chance,14 and that “few behaviors are strongly and consistently associated with deception across studies.”15
Relevant to TDT and critical of cue theories, Kraut speculated: “The ability
to discover deception does not necessarily imply an ability to decipher nonverbal arousal cues, although this may be part of it. Instead, the skills may be in
remembering personal information and noting inconsistencies, in interrogating others, in setting traps, or in inferring ulterior motives from other social
information. None of these skills are tested in the typical lie detection paradigm.”16 And, “In any case the assumption implicit in much research on naive
detection of deception, that there are some easily observable verbal and nonverbal behaviors which are signs of deception per se, is implausible, and the
search for these cues to deception may therefore be futile.”17
Kraut was also critical of individual differences in lie detection that would, a
decade later, start to play a critical role in Ekman’s a-few-can-catch-a-liar think
ing. “These findings, that the same people are not consistently good at judging
deception across liars or affects and that people with very different experiences
with deception in their professional lives use similar cues and combination
rules to judge deception, are inconsistent with any simple notion of stable and
general individual differences in detecting deception. Indeed, my conclusion
is that most deception judgments (and many other personal perception judgments based on actual behavior) are stimulus driven. What a liar does and
the motivational context in which a lie occurs compel most observers to agree
about whether he or she is lying.”18
12

80

CHAPTER FIVE

MCCORNACK 1997 CRITIQUE
Steve McCornack19 begins his 1997 chapter “The Generation of Deceptive Messages” by distinguishing what he characterized as “hopeful myths” from “extant data.” His list of hopeful myths includes the following:20
• the encoding of deceptive messages entails active, strategic, and detailed cognitive processing;
• the encoding of deceptive messages requires greater cognitive load
than the encoding of truthful messages;
• the encoding of deceptive messages is more physiologically arousing
than the encoding of truthful messages;
• there is an identifiable and consistent set of deception-arousal-based
behavioral cues that deceivers “leak” when encoding deceptive messages;
• human beings are innately capable of deception detection, and
• deceptive messages have specifiable characteristics that render them
distinct from truthful messages.
The first two hopeful myths contrast sharply with the reasoning of Aldert
Vrij and colleagues, while the last few apply most directly to IDT. These myths,
McCornack argues, are reified through nonecological research design and selective interpretation of data. But they are, according to McCornack, myths, and
not science. Each myth rests on unsound reasoning, and each was undercut
by data that existed back in 1997.
McCornack argued that deception occurs fairly often in normal conversation
and is often enacted casually. Most deception is not especially effortful, arousing, or strategic.21 He is especially critical of the idea that deception is more
cognitively effortful than honesty. His arguments are both theoretical and empirical, and they are too detailed to repeat here.22 The short version involves
an important and useful distinction between bald-faced lies, bald-faced truths,
packaged deception, and packaged truths. The idea is that research tends to
study the differences between bald-faced truths and bald-faced lies, whereas
normal conversation typically entails packaged truths and packaged deception.
Given the conversational situations in which deception naturally occurs, packaged deception is enacted precisely because it is easier than trying to package
the truth in a palatable manner. In the typical mock-crime experiment, for example, honest senders are asked about recent events fresh in memory where
the truth is completely unproblematic and easy to recall. Liars, on the other

CRITIQUING THE RIVALS

81

hand, need to make stuff up. This leads to a comparison between bald-faced
truths and bald-faced lies. But, McCornack argues, people don’t lie when the
truth is unproblematic. And, McCornack argues, most deception is not blatant
fabrication, but instead a subtle shading of the truth—maybe just leaving out
a critical detail in an otherwise truthful statement. Further, says McCornack,
when people do outright lie, they are often not making things up, but instead
pulling from true memories.
Try this little thought experiment. Out loud, quickly and spontaneously,
answer the following question: What did you do two weeks ago, Thursday
night? Now, follow-up questions: How easy was an honest response? If you
were to lie, might you say what you typically do on weekday evenings? Which
involves more cognitive effort: recalling a specific evening a few weeks ago or
recalling a typical evening? According to McCornack, what is cognitively easy
is what is more accessible in memory, and what is easiest to bring to mind
may not be “honest.”
EVALUATING EKMAN ET AL.
Paul Ekman’s theoretical contributions have been incredibly influential in how
deception theory and research have progressed over the past forty or so years.
The ideas of leakage, deception clues, lie stakes, and wizards are deeply ingrained in the social scientific lore of deception and, to a lesser extent, in popular
culture. Ideas like the Othello error have real utility. But, as a scientific theory,
data in general have not been kind to the Ekman approach. If the bottom line
is reliable, replicable theory–data match, then I think we must consider the
theory sufficiently falsified. To summarize: bits and pieces have merit (e.g.,
Othello error, leakage), the verdict is still out on other parts (e.g., wizards), but
too many key elements conflict with too many data for the whole to stand as
a coherent, scientifically sound theory.
The cue meta-analyses reviewed in chapter 3 are not especially supportive of
the existence of deception clues, especially those linked with emotions. There is
less independent evaluation of microexpressions, and at least one experiment
failed to identify any evidence for full microexpressions in a sample of emotional deceptions.23 Evidence was reported for partial microexpressions, but
they were infrequent and did not differ in frequency between genuine and deceptive emotional displays. More generally, in the journal Nature, Weinberger
offers a nice summary of scientific controversy regarding facial leakage as it
applies to the TSA’s SPOT program.24 The upshot is that Ekman’s ideas are,
at best, regarded as scientifically controversial.
Evidence has generally not supported the key Ekman contention that high-

82

CHAPTER FIVE

stakes lies exhibit more deception clues or are more detectable than low-stakes
lies. Meta-analysis shows that cues are no more predictive of deception under
high sender motivation than otherwise.25 Even Frank and Ekman report that
threatening punishment did not affect displayed emotions in facial measures
or any other outcome in their experiment.26 Finally, meta-analysis finds no
differences in deception detection accuracy as a function of stakes (motivated
lies, 53.9% accuracy compared to 53.4% for no motivation).27 However, consistent with DePaulo’s motivational impairment effect,28 motivated lies are
slightly less believable (believed 53.4%) than lies absent motivation, which are
believed 57.2% of the time.29
Research has also not found support for differences in deception detection
accuracy based on occupation or experience. Meta-analysis has failed to substantiate reliable differences between student and nonstudent populations, in
cluding law enforcement, the intelligence community, and other professional
populations. In my own data, I have failed to find reliable differences between
professionals and students in passive lie detection,30 and I sometimes found
that experts do worse than students.31 Meta-analysis also finds too little variance in accuracy to support much in the way of individual differences in detection accuracy.32
IDT
IDT scores poorly on every metric of theory assessment except two. If theory
is judged based on the number of published articles and the number of US tax
dollars invested in research, then IDT has been remarkably successful. People
who value such metrics above all else will greatly appreciate IDT work. I have
only half-jokingly told students in graduate methods classes that there are now
four types of validity: internal validity, external validity, construct validity, and
grant validity.33 IDT research excels on the fourth type.
If the criteria for evaluating theory are clarity of specification, logical consistency and coherence, the scientific quality of the research generated, and
consistency of the theory with data, then IDT is arguably the worst social scientific theory I know. IDT has been widely criticized in the academic literature.34 I could write a whole chapter on the problems I have with IDT and still
not have enough space. There are plenty of other things to cover in this chapter, so I will try to prioritize but still make my point.
In terms of lack of specificity, ambiguity, and coherence, let us consider the
following quotes from Buller and Burgoon as they lay out their first proposition and some hypotheses that might follow from the proposition:

CRITIQUING THE RIVALS

83

Proposition 1: Sender and receiver cognitions and behaviors vary systematically as deceptive communication contexts vary in (a) access to social
cues, (b) immediacy, (c) relational engagement, (d) conversational demands, and (e) spontaneity.
Sample hypotheses derivable from this proposition are that (a) receiver
truth-biases decrease as communication contexts move from high interactivity (e.g., face-to-face) to low interactivity (e.g., electronically mediated communication), and (b) sender detection fear and (c) deception
displays differ between dialogic (e.g., face-to-face) and monologic (e.g.,
videotaped presentation) contexts.35
On one level, it is undoubtedly true that people have different thoughts and
different behaviors in different social situations and that the nature of social
cues, conversational demands, and relationship status no doubt affect how
people think and feel. On the other hand, this is so vague and imprecise as
to be scientifically pointless. Buller and Burgoon offer the sample hypothesis
that receiver’s truth-bias might decrease as interactivity decreases. But the
exact opposite hypothesis is equally consistent with proposition one: receiver’s truth-bias might decrease as interactivity increases. Proposition one does
not specify the direction of effect. We can also derive absolutely ludicrous hypotheses from proposition one. Evidence that increased conversational demands are negatively correlated with the frequency and valence of thoughts
about goldfish would be consistent with and support proposition one. Proposition one is also consistent with the observation that nose-picking decreases
(or increases) with access to social cues. Proposition one does not specify types
of thoughts or behaviors, so systematic variance in any thought or behavior is
consistent with the theory.
Consider the conditions under which proposition one might actually be
false. Disconfirming evidence would logically be possible only in two completely implausible situations: (a) thoughts and behaviors are constants and
do not vary, or (b) variability in thoughts and behaviors is completely random
and unaffected by social context.
In the places where IDT does actually make meaningful predictions about
deception, it performs even more poorly than other deception theories. At its
core IDT presumes that interactive, face-to-face deception is different from
mediated deception, and that variables such as access to social cues and conversational demands affect outcomes such as deception detection. Proposition

84

CHAPTER FIVE

eleven, for example, predicts that accuracy is inversely related to interactivity.
Yet we know from meta-analysis that mere interaction makes little difference
with respect to accuracy, and neither does communication medium.36 Interaction can make a big difference, but IDT does not tell us where to look for
it, nor has IDT been able to produce large effects for interaction. When interaction does make a difference, the direction of the effect is opposite to that
predicted by IDT. Interactivity can improve accuracy.37
Proposition three states: “Compared with truth tellers, deceivers (a) engage
in greater strategic activity designed to manage information, behavior, and image, and (b) display more nonstrategic arousal cues, negative and dampened
affect, noninvolvement, and performance decrements.”38
Proposition three makes IDT a cue theory, and thus the general concerns
about cue theories apply to IDT. Like other propositions, this too makes IDT’s
predictions hard to pin down, because liars do strategic things that make them
look more honest and nonstrategic things that make them look deceptive at
the same time. Specific activities and cues are not identified.
Proposition four qualifies the predictions of proposition three by specifying that (at least initially) as interactivity increases, liars do even more strategic activities and fewer nonstrategic things like leakage and deception cues.
If this is true, then liars but not honest senders should be more believable as
interactivity increases. It is the case that senders are believed with greater frequency in interactive situations (65.3% vs. 54.5% truth-bias),39 but it is not clear
that this stems from dishonest sender behavior. Meta-analysis shows that the
magnitude of cue effects does not vary by interactivity,40 and even IDT research
suggests that the trend holds for honest communications too.41
Proposition seven contrasts with Bella DePaulo’s motivational impairment
effect. The motivational impairment effect holds that people who are more motivated to lie successfully are less successful at lying. IDT predicts and claims
to find the opposite: motivation improves lie success.42 Meta-analysis reports
that across forty-two tests of this issue, motivation decreases believability, a
finding consistent with DePaulo’s work and inconsistent with IDT.43
Proposition eleven predicts, among other things, that accuracy is lower as
interactivity increases. Again, this prediction has not held up in meta-analysis.
Proposition eleven also predicts that detection accuracy and truth-bias are inversely related. As we will later see, TDT and IDT make very different predictions about the relationship between truth-bias and accuracy. In TDT, truth-
bias makes us more, not less, likely to be right.
In one of the most obviously false hypotheses in IDT research, the Interpersonal Deception IV experiment actually predicted “H1: Receivers perceive

CRITIQUING THE RIVALS

85

deceit when it is present.”44 Meta-analysis and the literature reviewed in chapter 3 show vast quantities of data inconsistent with this IDT prediction. But,
for IDT to function as specified, both senders and receivers need to maintain
vigilance, both need to recognize deceit and suspicion in others, and both
need to adapt and counter-respond to the other in a game of cat-and-mouse.
In this sense IDT and TDT are polar opposites. In IDT, receivers are suspicious souls, quick to pounce at any sign of deceit, but also prone to leaking
their suspicions to liars, who strategically react on the fly with more-honest-
looking behavioral displays. In TDT, receivers are more often than not accepting of what others say, and the thought of deception only rarely even enters
conscious awareness. In IDT, truth-bias is lazy, flawed thinking that lowers
accuracy.45 In TDT, truth-bias is adaptive, it fosters communication and cooperation, and it usually leads to correct beliefs.
Empirical tests of IDT are also problematic.46 Consider, for example, the Interpersonal Deception V experiment.47 The first hypothesis was “Deception accuracy differs across deception types.”48 The article reports significant effects
for a dependent variable other than accuracy. On the basis of this, it is concluded that “results strongly confirmed Hypothesis 1.”49 The second hypothesis
predicts that suspicion will lower accuracy. There were no effects for suspicion on any of the dependent variables, accuracy or otherwise. However, they
report a significant effect for suspicion within a subset of subjects that would
not be significant with conventional tests.50 This gets interpreted as “qualified
support.” The discussion starts by asserting: “A guiding premise of interpersonal deception theory is that the act of communicating face-to-face alters deception relative to noninteractive contexts. The current results document several ways in which it does so.”51 Yet the study they discuss here did not even
test context interactivity. All data were collected face-to-face. There is just no
correspondence between the claims made, the actual design of the experiment,
and the actual results found. Statistics are tortured to obtain statistical significance and dubious but impressive-looking effect sizes,52 and when that is insufficient, things are just made up. IDT is truthiness on steroids.
IDT’s strength is its focus on interaction. Interaction is critically important
in deception detection, and IDT was way ahead of the times in prioritizing
interaction. I fully agree that interaction is of critical importance, and I think
research over the past several years has really proven that. But the big breakthroughs have come not out of IDT research, but from programs of research
that reject IDT logic, methods, and findings. IDT is absolutely right in the general sense that interaction is critical and that a dynamic process orientation
is needed. I agree fully that a communication perspective is not only needed

86

CHAPTER FIVE

but well suited to overcoming psychology-centric cue theories. But I think IDT
gets all the details wrong. It does not prioritize the right variables and ignores
critical considerations. It muddles understanding more than it clarifies. And,
bottom line, it is contradicted by the data in too many instances.
VRIJ AND THE LEGAL PSYCHOLOGY WORK REVISITED
Vrij and colleagues represent the latest version of cue theory. Much like IDT
researchers and perhaps even more so, they have been highly successful in getting a huge number of papers into print in recent years. In sheer quantity of
peer-reviewed journal articles, Vrij et al. are unrivaled. The substantive yield,
however, is not commensurate with the volume of publication.
Vrij often cites the DePaulo cue meta-analysis as evidence against arousal-
based deception cues but then embraces cognitive load as a basis for cues.53
My reading of the results of the DePaulo cue meta-analyses is that cues linked
with cognitive load fare worse than arousal cues. It seems to me that the arguments rest on a selective use of evidence, where helpful evidence is embraced
and contrary evidence is ignored. It also seems to me that if liars are really
more likely to plan their stories than are honest people, then we might expect
less cognitive load in a planned and rehearsed lie than in a spontaneous truth.
I find McCornack’s criticism of Vrij’s position that lying is typically more
cognitively difficult than honesty compelling. Since the logic of instilling additional load as a cue-prompting strategy requires that lying is naturally more
cognitively demanding, I just don’t accept the premise of Vrij’s argument. If
the premise is false, the argument is unsound.
At the time I wrote the first draft of this chapter, cognitive load induction
studies did not report levels of accuracy notably better than passive approaches.
One study compared asking honest and deceptive mock-crime suspects to recall events in either chronological or reverse order.54 Reverse order interviews
(58%) yielded significantly higher accuracy than control interviews (46%), but
the 58% accuracy obtained in the reverse-order condition is consistent with the
slightly-better-than-chance levels observed in passive studies. A second study
reported accuracy of 53.5% with a maintain-eye-contact instruction, compared
with accuracy of 52.3% in controls.55 A third study had adults assess honest
and deceptive children who were asked anticipated and unanticipated questions.56 Accuracy for unanticipated questions was 58.7%, compared with 56.5%
in controls. Whereas inducing load produced higher accuracy than controls in
each of these studies, accuracy was still well within the range typical of passive lie detection. Thus, there is little evidence that actively inducing cognitive

CRITIQUING THE RIVALS

87

load produces any real bottom-line improvement. Unfortunately, most cognitive load experiments report only cue differences and not accuracy, making
the effectiveness of the approach difficult to compare to other approaches.57
Although it is not specific to the work in legal psychology per se, I caution researchers to be aware of an issue I call exploitation of aberrant controls.
We know that absent any special intervention, accuracy is usually better than
chance (about 54%). An apparent trend I have noticed is that accuracy in control groups is often poor compared to the across-study average. Experiments
are reported touting some approach or phenomenon that improves accuracy.
The experiments show that the new approach is statistically superior to a control group. But, when the results are examined closely, it’s not so much that
the approach produced much improvement over the status quo; instead the
statistical difference is the result (at least in part) of the control being usually
low. To the extent that aberrant controls reflect a trend, some skepticism may
be warranted. Aberrant control findings are prevalent in the legal psychology
work on deception, which to me suggests questionable research practices or
publication bias.58
Pragmatically, I think the application of Vrij’s approach is very likely to encourage a version of the Othello error. Truthful people can have honest difficulty in remembering things or have other things on their minds. In such
cases, adding additional load and looking for load cues will lead to systematic
errors. Similarly, people may not want to be forthcoming for reasons other
than being guilty of some offense. Further, research on imagined interactions
shows very clearly that honest people plan and rehearse what to say too.59 Planning is not limited to liars. Adding cognitive load and looking for load cues
may make honest people, especially those who are below average in intelligence, look guilty.
The concern about adding load and false positives is a much greater risk
outside the lab then in controlled research settings. In the lab, all lies are
about the same thing (usually a mock crime); all honest accounts are about
the same, recent, easy-to-remember truth; and all subjects (usually college students) are presumably above-average in intelligence and practice memory tasks
(college exams) regularly. The inducing-load logic makes some sense in the
lab, where the task difficulty is controlled and where the variance in cognitive
ability is limited. But the same logic that might make adding load work as a
deception detection tool in the lab suggests that adding load should impair an
honest person trying to be honest about a difficult-to-remember truth. That
same logic also suggests that the approach will impair honest but cognitively

88

CHAPTER FIVE

less gifted individuals. Instilling load should backfire when honest memories
are not fresh and easy to recall or when individuals vary in preexisting cognitive ability. Therefore, I have grave concerns about the utility of the instilling-
load approach in practice and think it is highly vulnerable to false positives
in the field.60
Vrij and colleagues are highly critical of accusatory approaches to questioning and assert the superiority of nonaccusatory questioning. The evidence
seems much less clear-cut to me. In the original probing-effect research, asking skeptical questions actually made senders look more honest.61 Vrij’s own
research reports no significant differences in accuracy between information-
gathering, accusatory, and BAI questioning styles.62 And, in my own research,
I too find no differences in accuracy between accusatory and nonaccusatory
questioning.63 Thus, Vrij’s objections seem counterfactual and unresponsive
to actual findings.
Beyond Vrij’s cognitive approach in particular, I have concerns about deception research in the area of legal and criminal psychology more generally.
The group of researchers operating in that space strikes me, as an outsider,
as very cliquish and provincial. Researchers coauthor and review one another’s work. They seem to have what I call a “publication circle” going. In publication circles, people alternate authorship, citations, and positive reviews with
the goal of everyone maximizing publications and citations. It’s basically enforced mutual back-scratching. New meta-analysis shows that aberrant controls have become widespread in the legal and criminal psychology literature.64
Findings that don’t follow the party line can’t be published in legal and criminal
psychology journals because of peer review practices. As a consequence, evidence of strong publication-bias is mounting.65
I do, however, much admire the work of Pär Anders Granhag. His work on
logical consistency in statements is quite good and influenced TDT.66 The strategic use of evidence (SUE) strategy is a major advance, and I think it is very
compatible with the TDT approach.67 I suspect I disagree with Granhag a bit
on the mechanisms involved, but there is no doubt that SUE is effective. I also
think Granhag’s new work on the Scharff technique is very interesting.68 Hanns
Scharff was a highly effective German interrogator during World War Two. In
an upcoming chapter I provide more detail on his approach to interrogation.
SUMMARY: DECEPTION THEORIES AS CULTS
I close this chapter with a metaphor of prior theories of deception as cults.
When I did a Google search on the word “cult,” the following definitions
came up:69

CRITIQUING THE RIVALS

89

• a system of religious veneration and devotion directed toward a particular figure or object;
• a relatively small group of people having religious beliefs or practices
regarded by others as strange or sinister;
• a misplaced or excessive admiration for a particular person or thing.
I think all three apply. Various camps of deception researchers have leaders
who are revered by followers (e.g., Ekman, Burgoon, Vrij). The members of
the various groups are very devoted to the system of beliefs that form the tenets of the various theories, and they see disagreement by outsiders over core
issues as heresy. Each of the groups is relatively small in number, and each
group sees the doctrines of rival theories as strange, sinister, and threatening.
And, at least from my point of view, I think the admiration that the followers
of the various theories have for their theories is both excessive and misplaced.
Each of the rivals falls short in verisimilitude.
The rest of the book describes the scientific evidence pertaining to truth-
default theory in detail. I hope this chapter has made a strong and valid case
for why a new theory is needed. I further hope that TDT overcomes the problems and limitations of its rivals.
This ends part one. The ending of this chapter marks a transition from
previous research and rival theories to the TDT view of deception and deception detection. Chapters 7 and 8 make the transition by moving beyond intent
and lies, discussing issues in defining deception and deception as information
manipulation. By chapter 9, the transition will be complete, and the focus will
be squarely on TDT. But first, an overview of TDT is provided in chapter 6.

PART II
Truth-Default Theory
