CHAPTER

8

Crossing the Line: How Evil Starts The Ku Klux Klan is recognized as one of the most evil organizations ever to flourish in the United States. And flourish it did: At various times, it boasted of having millions of members. Harry Truman joined the Klan (although he soon quit) before he become president. Warren Harding became a member while he was president, and his initiation ceremony was performed right in the White House. As for being evil, the Klan’s record speaks for itself. Although the Klan supported some good works and community service, it committed many violent acts, including lynching, whipping, raping, maiming, and murdering people it classified as enemies (such as blacks, carpetbaggers, and Republicans). It damaged or ruined the businesses, reputations, and careers of many others (such as Catholics). 1

Yet the Klan did not begin as a violent organization. According to Wyn Craig Wade’s history of the Klan, it was founded in 1866 by a group of young men who had fought on the losing side in the Civil War and who were simply bored and lonely now that the war was over. Jobs were scarce and there was very little in the way of action or opportunity, given the military occupation of their region and the economic collapse of the Confederacy. Most people were sitting at home with nothing to do, trying to survive. These six young men started a club to pass the time. They came up with the idea of wearing ghostly costumes, made from bedsheets decorated with meaningless occult symbols and conical hats, as a lark. The club had no purpose beyond self-entertaining. Like many other clubs of young men, the organization was designed only to “have fun, make mischief, and play pranks on the public.” 2

Like a fraternity, the Klan put new members through elaborate hazing rituals and enjoyed some good laughs at their expense. These amusements were not enough to keep the organization going, however, possibly because there were not enough initiation ceremonies to take up all their time. And so the young men hit upon the idea of playing their pranks on outsiders, especially black people, most of whom were recently freed slaves with little education and little familiarity with such humor. Early Klan stories described with great hilarity how the members would pretend to be ghosts or spooks and thereby frighten the gullible, unsuspecting black citizens. For example, a member might wear his white sheet over his head and put a phony head on top. At night he would approach a former slave and then pretend to remove his own head, handing it to the black man and asking him to hold it for a while. Later, the club members would sit around over drinks and laugh about how that silly black man ran off in fright from a ghost who could detach his own head.

In retrospect, we can see a malicious aspect to such pranks, and perhaps this maliciousness was even apparent at the time to thoughtful, sensitive individuals. Yet these pranks may have seemed quite harmless to the less morally sensitive fun-lovers. Practical jokers are not Satans. Even today, there are plenty of innocent and friendly pranks that are based on throwing a scare into someone, and what these first Klansmen did was not so different from the modern rituals of Halloween and April Fool’s Day, at least in their own estimate and among their friends.

How did the Klan progress from a group of pranksters to perpetrators of murder, rape, and violent assault? Playing pranks was neither illegal nor immoral; some line was crossed when the pranks turned harmful and violent.

The transition probably occurred something like this. The freed slaves may have been superstitious and lacking in formal education, but they were not stupid, and they probably soon came to know that such nocturnal encounters with these apparent ghosts were actually pranks by living people. Soon the pranksters would find that their intended targets failed to provide a satisfactory amusement. Instead of running off into the woods shrieking in fright, a mark might simply say he did not want to play their games. To elicit the fear they had sought, they might then do something more threatening.

One can well imagine a group of late-adolescent white males dressing up in goblin costumes and anticipating how much fun it would be to scare some ignorant blacks—and then finding out that the blacks were not scared, that they had learned about these pranks, and that they told the young men to grow up and quit these childish games. The fun was spoiled, and the hoped-for pleasure of frightening their intended victims was lost. They themselves had been made to look foolish (in other words, their egos suffered a blow), instead of their intended victims. To recapture this pleasure, they did something violent, which did finally frighten the victims. Perhaps they merely brandished a gun or knife. The point is, they did what was necessary to cause fear in their targets. Probably they knew at this point that violence is morally more objectionable than playing pranks, but then they were provoked by the insulting tone the blacks took in response to their pranks when they were just pursuing innocent fun. If a morally sensitive person were to reproach them, they could honestly say that it was all harmless fun. But they had actually threatened violence: a line had been crossed.

Alternatively, maybe that decisive line was crossed when they chose a target for some particular reason. Threatened egotism, which we have seen is a powerful cause of violence, could well have helped motivate such young men to strike out at black citizens. There is little denying that the former Confederate soldiers felt that their privileged place in the world was in jeopardy. Their army had been defeated, their would-be nation dissolved and occupied, their honor lost, their social status undermined. A black man who seemed to them too eager to assert his new legal equality to whites might be chosen as a target of a prank; the Klansmen might think that scaring him would be a good way to intimidate him. Imagine having your former slaves suddenly be your equals! It is difficult to appreciate today how unsettling that was, because today we believe that slavery is wrong. The new equality of former slaves was probably close to unthinkable to many members of the old southern ruling class.

The Klansmen might approach such an ambitious fellow some night and try to frighten him, if not with their ghostly costumes, then by their weapons and menacing attitude. In such a situation, if his response failed to satisfy their expectations, someone might well strike him to drive the lesson home. Even if no one was seriously hurt, the seeds of later Klan violence would already be apparent: A victim was targeted for political reasons, and force was used to intimidate him.

These scenes are speculations and reconstructions, not proven facts, but they do offer a possible bridge between the two well-documented versions of the Klan that have been established: the harmless club of young men looking for amusement, and the organization that used brutal violence to prevent black citizens from enjoying their legal and moral rights. The first founders of the Klan were not working from some vision of a large organization of white people who would terrorize, injure, and kill innocent black (and white) victims throughout the South and Midwest; in fact, I suspect those first few young men would have been aghast at such an idea. They just wanted to make mischief and ease that ubiquitous curse of youth: boredom. Somehow, though, the pranks subtly began to turn mean. From that point, the step to systematic cruelty was perhaps just a matter of degree.

The question “What causes evil?” has to have at least a three-part answer. First, it is necessary to describe the root causes. Second, one must explain the immediate, precipitating causes. Third, it is vital to understand what escalates the initial deed into cruelty or oppression. The previous four chapters examined the root causes. This chapter will examine how perpetrators get started, and the next will examine the processes of escalation.

Evil can be compared to a plant or tree that requires both the planting of a seed and a set of favorable conditions for growth. If either the seed or the conducive environment is lacking, there will be no tree. As we will see in Chapter 9, the factors that help evil to grow are quite powerful, which implies that the initial seed does not have to be anything spectacular. Great evil can come from small, unremarkable, seemingly innocent beginnings. Contrary to the myth of pure evil, one does not have to be at all evil to cross the line. Once one has done so, there are powerful forces that sweep one along into greater acts of cruelty, violence, or oppression.

Blurring the Line: Ambiguity, Uncertainty, Misinformation Henry II of England was irritated when he heard from others (in distorted versions) how his former friend and helper, Thomas à Becket, now Archbishop of Canterbury, was defying the king’s will and excommunicating the archbishop’s own personal enemies (including some of the king’s men). Henry is said to have remarked, “The man ate my bread and mocks my favors. He trampled on the whole royal family. What disloyal cowards do I have in my court, that not one will free me of this lowborn priest?” 3 Several of the king’s barons took this as a sign of a royal wish for them to murder the archbishop, and they did.

After the fact, King Henry did penance, condemned the murder, and began to praise the memory of “the irreplaceable Saint Thomas.” 4 Thus, he acted as if he had not intended for his men to murder the archbishop. Whether he had intended the murder is much harder to say. The point is that the ambiguity of his remarks left ample room for sinister interpretations by others, and so some of his men acted on those interpretations.

If evil begins when someone crosses a moral line, then it may be promoted by anything that tends to make the line fuzzy or unclear, including ambiguity and misinformation. When the line between right and wrong is clear, most people will consistently do what is right. They cross the line into doing wrong most readily when they cannot even see for certain that the line is there.

The role of ambiguity does not end with the initial action; indeed, as we will see shortly, it is centrally involved in the escalation of evil and violence. Still, ambiguity is often a decisive factor in getting someone started in immoral or cruel acts. This fact is recognized by powerful people who want others to carry out their own malicious wishes. It is easier for people in power to give commands that lead to harm if they are ambiguous, because the authorities can later deny that they intended those outcomes. They can repudiate the evil that their words have caused, as Henry did. It is hard to know for certain whether Henry really intended to bring about the murder of the archbishop, but if he did, he certainly went about it very effectively. He was able to maintain his own apparent innocence and even bemoan the violent act, all the while benefiting from it.

Ambiguous, uncertain commands have continued to play a role in evil down to our own time. It is apparent that Lieutenant Calley and the men who directed the famous massacre at My Lai in Vietnam believed they were following orders, although their superiors have consistently denied that they issued any such commands. The initial commands from Lieutenant Colonel Barker apparently implied but did not specifically say that the villages in the area were to be obliterated. The initial ambiguity was retained and passed along as the orders were transmitted down through the chain of command, although at some point a literal and drastic interpretation was made to the effect that the mission involved shooting the villagers en masse. 5

One crucial aspect of ambiguity is that it enables people to justify and rationalize their actions. Many laboratory experiments have been done to study aggression, but rarely has it been made clear to the individual participant that he (or, less often, she) is being aggressive. A subject might be asked to deliver painful electric shocks to someone else, for example, but usually these shocks are described by the researchers as being part of a procedure to help someone else learn (such as by punishing mistakes), as a way of distracting people from another task, or as a way of furnishing helpful data for scientific progress. Subjects in such studies can behave aggressively without facing up to the fact that that is what they are doing, because the situation offers them ready-made alternative ways of thinking about their actions. Chapter 10 will look much more closely at how people rationalize and justify their violent actions. For now, the important point is that ambiguity can make such rationalizations easier and thereby weaken some of the inner restraints against aggression.

No doubt, part of what made John Dean’s memoir Blind Ambition a bestseller was its portrayal of how easy it was to cross fuzzy moral boundaries on the path that led to complicity in the Watergate scandal and the fall of the Nixon presidency. As Dean tells it, he started out as merely another bright, ambitious young lawyer who was thrilled to get the job as White House counsel. One of his first assignments was to target a magazine, Scanlan’s Monthly, that had printed something embarrassing about Vice President Agnew, including the absurd charge that Agnew was scheming to cancel the upcoming presidential election and repeal the Bill of Rights. Dean was told that Nixon was furious at the magazine and wanted to strike back at it. Dean advised against the lawsuit that the president wanted, but the president’s second plan (after the lawsuit idea was abandoned) was to get the Internal Revenue Service to investigate the magazine.

Dean was not certain whether it was legal or ethical to do that. The IRS has an official job to do: collecting and correcting tax returns. It is not supposed to be a weapon for the president to use to harass people or groups whom he dislikes. Dean consulted a friend, who was a lawyer as well as one of the president’s advisors. The friend told him bluntly, “If the President wants you to turn the IRS loose, then you turn the IRS loose. It’s that simple.” When Dean said it wasn’t necessary, his friend corrected him again: “I’ll tell you this, if Richard Nixon thinks it’s necessary, you’d better think it’s necessary. If you don’t, he’ll find someone who does.” 6 When Dean asked about the legality of such a tactic, his friend said it was legal as far as he was concerned. He said Lyndon Johnson had used such tactics against Nixon’s people when he was in power, and it was only fair that Nixon be allowed to do the same. “It’s the way the game is played,” he said, possibly suggesting that moral scruples such as Dean’s were naive and out of place at this high level of power politics.

Dean had a former police detective (now an administrative investigator) working with his office. He mentioned the problem to him, and the man cheerfully said he’d take care of it. He reported back that the magazine was only a few months old and so the IRS had nothing on them, but he had suggested that the IRS investigate the people who produced the magazine: owners, editors, publishers. Nothing came of these investigations, and the magazine went out of business a few months later for reasons that had nothing to do with its enemies in the White House. Still, Dean was able to report that he had checked into the possibility of an IRS investigation, as he had been instructed to do, and that it had yielded little; but on his own initiative, he had taken the further step of having the private citizens who produced the magazine investigated, too. Thus, he had performed his duties perfectly well. And yet, “Within a month of coming to the White House, I had crossed an ethical line.” 7 His objections to using the IRS to harass the president’s enemies had all been technical and pragmatic, and he now took credit for an operation that had been an easy success—but had compromised him both legally and morally.

Another way of helping people cross the line into committing violence is to keep them in ignorance of what they are doing for as long as possible. When people do not know what they are doing, they have no basis for objecting to it. This tactic can work even if the deeds themselves will be clearly objectionable. If the instructions become clear only moments before the deed is to be done, then there is minimal time or opportunity for protest.

One of the best examples of this tactic was provided in Browning’s account of how German policemen became participants in the mass murders of Polish Jews during World War II. The Germans involved were mostly middle-aged, working-class policemen who were conscripted and sent into action in Poland as “Order Police” (as in “law and order”), officially just to perform standard police duties in the conquered territory. They were not given specific instructions until the last minute. There had been occasional, vague comments about “special actions” and such things, but nothing was said that clearly indicated committing atrocities.

The naked truth of the matter—that their duty was going to include rounding up and shooting civilians—was not revealed until one day at 6 A.M., when the major assembled the battalion and explained that those were the regrettable orders to be carried out at once. Had they been told a month in advance that they would be shooting innocent, helpless civilians, they might perhaps have objected, but it is hard to leap onto a moral high horse in response to a blind surprise at six in the morning when everybody is preparing to do a tough job. Of course, and ironically, the victims were kept in the dark in the same way. Apparently, the men who ran the show had learned that the most effective way to get one group of people to kill another, in an orderly and cooperative fashion, was to avoid giving either side any advance notice.

Keeping people in the dark is thus one form of the more general pattern of manipulating ambiguity and misunderstanding to promote evil. An example of how simple misunderstandings can lead to violence (although in this case, fortunately, no one was hurt) was provided in another recent history of the Ku Klux Klan. 8 At one of the Klan rallies in Indiana in the heyday of the organization there (the 1920s), one of the men was making a speech about the dangers of Catholicism, and he repeated the fairly standard assertion that the Pope was plotting to take over the United States. To drive home the point, he added the presumably hypothetical suggestion that the Pope might be on the train from Manchester (Indiana) tomorrow, the implication being that the dastardly pontiff was surveying the lands he expected soon to rule. Unfortunately, the speaker made his point so vividly that it was much repeated by the audience, and it quickly lost its hypothetical character.

The next day, about a thousand people were there to meet the train from Manchester. As it turned out, it was mostly a freight train, having only one passenger car with a single occupant. That unfortunate man, actually a carpet salesman headed for Chicago, was pulled off the train and found himself urgently trying to convince the potential mob that he was not the Pope. Once proved innocent, perhaps aided by his suitcase full of carpet samples, he escaped unscathed and was permitted to resume his journey on a later train.

In the absence of reliable information, people often resort to rumor and guesswork—and the chance for false information to dictate events increases. Suppose, for example, that Henry II had not really intended to have Thomas Becket killed. His remarks might have been misquoted, and the murder would have been basically a mistake. Today, with effective communications and news media, it is hard to appreciate fully how uncertain and misinformed people can be. One contemporary example is violent youth gangs, because the information about events that concern them does not come fully reported on television or documented with computer printouts. Jankowski’s book on such gangs contained plenty of incidents in which rumors about other gangs led to violent reprisals that were misdirected or wholly inappropriate. Some of these were simple cases of mistaken identity, in which a crime or offense had been committed and the wrong person was identified and targeted, usually without having the chance to prove his innocence. These actions often led to disasters for the gang, because to go around attacking innocent people is a sure way to make enemies and get into trouble with one’s own community, the police, and rival gangs.

Once You’ve Accepted the Premise …

People often enjoy the exercise of asking “What would I do in that situation?” with regard to moral dilemmas. They ask themselves whether they would go along with orders to torture a dangerous enemy, shoot prisoners, or the like. As I have said, people tend to conclude that they would not commit such acts, but when the circumstance actually arises, most people do go along. Something is wrong with the way people play these hypothetical games.

One factor is that the luxury of reflection allows people to contemplate details and to see the choice framed in stark moral terms, on a high level of moral principle. In reality, however, people often find themselves unexpectedly thrust into situations that require them to make these highly consequential decisions. Moreover, they do not always recognize the issue as a great moral test of character at that crucial moment. Other factors and concerns are often present. If you were an American soldier in the Vietnam War, would you shoot civilians on mere suspicion that they were aiding the enemy? Probably you would say, of course not—from the vantage point of time and distance, with leisure to reflect, and with a clear perception that a moral dilemma is involved. Many soldiers might have to face the same decision under circumstances that were far less ideal. They might have been tired, under stress, hung over, disoriented by drugs, afraid for their lives, and badly upset about having seen a close friend killed by villagers recently. The moral issue of respecting civilian innocence until guilt is proved may have been obscured by other factors, such as a pragmatic concern with one’s own survival or a desire for revenge.

Even when people do object, however, they often avoid phrasing their objection in moral terms. Instead, they focus on a lower level objection. Such an objection can trap the person into subsequent compliance. To fail to make the objection on the highest level the first time is often to implicitly accept the broad assumptions. Thus, in Dean’s account of the Nixon White House, the president wanted to use the apparatus of government to harass and punish a magazine he detested. Dean phrased his objections in practical terms: A lawsuit was too risky, and the magazine was too new to have a record at the IRS. He did not tell the president or even the superiors who passed him the president’s orders that what was being proposed was illegal and immoral. This pragmatic approach worked for him at first but gradually got him implicated in the crimes of the Watergate cover-up, which ultimately cost him his job and landed him in prison.

Several writers have made this point about the vexing question of why the victims of the Holocaust cooperated so extensively and fatally in their own destruction. From our enlightened perspective today, we can see that the victims should have refused very early in the process. Had no Jews cooperated with the authorities, such as by showing up at the train station ready for deportation or by walking in an orderly fashion to the killing sites, the killings would have been much more difficult to carry out and would not have resulted in anywhere near the same body count. When faced with the demands to comply, however, people sought to find an objection that would be accepted as valid by the perpetrators. Instead of saying, “No, it is wrong to deport me to a camp, because it is wrong to deport anyone, and I refuse to comply,” they said, “I cannot go now because I am working on such-and-such a job that is important to the war effort,” or “I am caring for an aging mother.” Such objections seem safe because they do not offend the authorities in the same way as saying “What you are doing is criminal and wrong” would do. They seem to be phrased in the way most likely to persuade the authorities to agree with your position. To get the authorities to agree, you have to communicate on the basis of their assumptions.

Yet such excuses implicitly accept the premise. You say you cannot go to the camps because you need to care for your mother; the authorities respond by arranging for your mother to go to the camps, too. At this point, you cannot easily say, “The entire enterprise is wrong,” because if you really believed that, you would presumably have said that at first and not wasted time on specific excuses. The excuse about caring for your mother implicitly acknowledges that some people can legitimately be sent to the camps, and you are merely seeking an exception from the rules that you otherwise accept. As a result, once the objection was handled, the victims tended to go along, hoping to find another valid excuse or exemption at a later stage. When they were standing in line for death, naked and shorn of hair and helpless, it was too late to raise broad philosophical objections to the entire enterprise. One should have brought them up long ago.

Similar processes operate on perpetrators. The sergeant tells you to shoot the Vietnamese prisoners. You know it is generally against the rules of war to kill prisoners, but obviously this war is different, and these prisoners may have killed some of your buddies. Maybe they committed some other crimes that your superiors know about and you do not. In any case, as a nineteen-year-old high school graduate, you are not about to enter into a moral debate with your superiors. Instead, you think frantically of the best excuse you can find: You do not have the right kind of weapon or ammunition, or you have been temporarily assigned another duty. These excuses try to appeal to the person giving the order by invoking some principle that he will accept.

In seeking to make such excuses, however, you implicitly accept the common assumptions behind his order. You do not say that it is absolutely wrong to shoot prisoners. Instead, you merely say that you cannot perform that duty right now. But this form of excuse-making traps you. Obviously, if you thought it was always wrong to shoot prisoners, you would not bother with making a specific excuse. If you would never shoot prisoners under any circumstances, it doesn’t matter whether you have the right kind of weapon or not. By making the excuse, you imply that you would shoot the prisoners if only you had the correct ammunition. You use the excuse because you think it will get you off the hook at the moment and at least buy time, but in the long run it ropes you into accepting the evil assumption. Next week, when the sergeant gives you the same order and brings you the right weapon, you have no basis for objecting again.

There seems to be a sort of social trap at work in these situations. When confronted with the demand to do something that is possibly immoral, people usually look for a reason to object. And for obvious reasons, they don’t tend to object by saying that the entire authority structure (and its uniformed troops with all those guns) is doing something horribly, morally repugnant. They look for objections that will not require such a radical breach, or they simply look for the reason they think will work best. In either case, the eventual effect is to get them caught up in discussing and considering the problem on the terms of the authorities who are initiating the evil, which is likely to be a low level of practical procedures rather than a high level of moral principle. And once one has abandoned the high level of moral principle and thus implicitly accepted the authorities’ broad assumptions, one’s latitude for returning to it later is reduced. Even if one’s excuse is accepted this time, one will probably have to go along next time.

Why Isn’t There More Evil?

Before going any further, let us consider a serious problem that plagues most theories about evil or violence: Why isn’t there more of it? In Part I, I explained that—contrary to the myth of pure evil—very few violent people think of their actions as evil or are deliberately devoted to inflicting harm as an end in itself. This raised the question of why there is so much violence in the world. Part II sought to answer that question by explaining the root causes of evil, which include greed, lust, ambition, egotism, idealism, and perhaps a touch of sadism. There are plenty of reasons for evil to exist.

Yet maybe these explanations were too effective. After all, greed, lust, ambition, and egotism are extremely common, and idealism is fairly widespread, too. If all these cause evil, why isn’t there more evil?

Many theories about evil suffer from this problem: They point to some cause that is so common that it seems as though there should be a great deal more violence or oppression than there is. For example, it is almost a truism that poverty breeds crime, and poor people are certainly more likely than rich people to commit crimes. But most poor people do not commit crimes. So there is a serious flaw in the theory that poverty causes crime: Usually poverty doesn’t cause crime. Likewise, it is now well established that abused children are more likely than others to grow up and become abusive parents themselves, so one might easily conclude that victimization causes abuse—but most abused children do not become abusers. Why not?

Violence Starts When Self-Control Stops Evil or violent tendencies are usually met with strong restraining forces, most of which can be conveniently categorized as self-control. Greed, ambition, egotism, and the rest may be powerful factors that promote evil, but they can be met with equally powerful inner restraints.

The immediate, proximal cause of violence is the collapse of these inner restraining forces. This point is crucial, because it means that many of our efforts to understand violence are looking at the question the wrong way. To produce violence, it is not necessary to promote it actively. All that is necessary is to stop restraining or preventing it. Once the restraints are removed, there are plenty of reasons for people to strike out at each other.

Some experts have begun to recognize this fact. In 1990, A General Theory of Crime, by Gottfredson and Hirschi, two eminent criminologists, appeared. 9 The general theory that they proposed was essentially one of low self-control: Most crimes are the result of a lack of inner discipline and restraint.

To flesh out their theory, Gottfredson and Hirschi noted that criminal acts are quick and easy ways of getting what one wants. The best way to get economic security is probably by pursuing a long and thorough education and then working steadily at some professional job for years. But that takes a great deal of patience, hard work, acquisition of skills, and other forms of self-control. In contrast, it takes no skills and minimal time to point a gun at someone on the street and demand his or her cash. Crime is marked by the short-term focus and simplicity that are common to people who lack self-control. It also furnishes excitement and thrills, which is another feature that appeals to such people.

In support of their theory, Gottfredson and Hirschi presented a great deal of evidence about people who commit crimes. One of the most compelling facts is that criminals do not tend to be ordinary citizens who resemble everyone else in most respects except for having an illegal specialization. Rather, they show a lack of self-control in many other areas of their lives, both legal and illegal. Criminals are more likely than other people to smoke and drink (to excess), to abuse drugs, to have impulsive sex, to become involved in unwanted pregnancies, to have unstable marriages, to get into petty fights, to be involved in automobile accidents, and so on. When they do make a large sum of money from some crime, they tend to blow it in short order, as opposed to, say, investing it in interest-bearing mutual funds. Moreover, criminals usually do not specialize in one type of crime. Instead, they tend to commit many different kinds of crimes, depending on whatever opportunity presents itself. There is a whole criminal life-style, marked by the search for quick, easy gains and the easy yielding to temptations.

Thus, people whose inner restraints are relatively weak are the ones most likely to commit crimes. It is not that criminals’ desires differ greatly from everyone else’s: money, sex, pleasure, and a feeling of superiority. Good citizens want those things and know that violent or illegal means might bring them, at least in the short run, but they have inner restraints that prevent them from resorting to criminal means to get them. For someone who lacks self-control, however, violent and illegal means may seem like the most attractive way to get them.

Conflicting Obligations Why, then, does self-control sometimes fail to prevent violence? One common problem arises when there are conflicting, inconsistent, or ambiguous obligations. Even someone with an exceptionally strong capacity for self-discipline will find it difficult to exercise that capacity in a situation marked by such a conflict. When the rules contradict each other, it is hard to do the right thing, and so it becomes far easier to do something that may turn out in the long run to have been wrong. 10

Moral dilemmas based on conflicting obligations have been debated for hundreds, probably even thousands, of years. During the Middle Ages, such a dilemma concerned the vassal’s obligation to join his lord in military action. This duty was widely recognized and very strongly supported. When the lord went to war, it was the sacred duty of his vassals to help him out. But what was the vassal to do when the lord initiated an unjust or wrongful war? Disobedience and disloyalty were crimes (and sins); but then again, it was surely wrong to hurt or kill innocent people. People in the medieval times believed strongly that only one side in a war (at most) could be in the right, and so all actions by the other side were wrong and sinful.

A dramatic illustration of such a dilemma involved Richard the Lion-Hearted, the famous crusading king of England who was immortalized by his portrayal in the Robin Hood stories. Before he was king, however, he actually fought in a war against England (and against his own father, who was king at the time). Richard happened to be the lord of some lands in southern France, and he lived there as a vassal of the French king. When France and England went to war, his duty to his French lord superseded any obligation to his father (or to the nation whose ruler he was to become), and so he brought his troops into battle on the French side.

Another form of this dilemma is the difficult choice faced by a soldier who is given orders to commit actions that may be evil. I say “may be evil” because if the commanded actions are clearly, definitely evil, then perhaps the dilemma is resolved: One should not perform evil actions. But things are not usually so clear. It is wrong to hurt or kill people, and indeed the Ten Commandments specifically prohibit killing, but all wars involve killing, of necessity. Soldiers learn early on that ethical principles are generally limited by situations. They also learn that people in their position do not always have all the relevant information. Thus, a command to shoot a prisoner may seem morally wrong; but what if the prisoner can inform the enemy of your position and thus bring death to your entire unit? What if the prisoner is a terrorist who has illegally killed dozens of innocent people or committed other capital crimes? What if the enemy is killing prisoners, including one of your buddies who had saved your life? No doubt, many people would argue that killing prisoners is still wrong despite such circumstances; but these and similar circumstances have sometimes made the injunction against killing prisoners a little less certain.

The great Christian thinker St. Augustine concluded that soldiers do have an ultimate obligation to carry out all commands, wicked or not. Augustine recognized the moral dilemma of the soldier who receives unjust commands as an especially difficult one, but he finally concluded that the obligation to obey orders given by proper authorities overrides other obligations. He decided that soldiers could not be held responsible for their actions, as long as those actions were carried out under orders. Later medieval thought upheld Augustine’s conclusion. 11 Your Christian duty was to carry out your orders even if they seemed wrong or evil to you.

It is difficult for modern Americans to appreciate this view, for our society has largely come to the opposite conclusion. To say “I was only following orders” has become almost the prototype of an inadequate excuse. But this view resulted from the retrospective outcry against the Holocaust, the My Lai massacre, and similar events, which forced modern citizens to recognize how important it is to reject any justifications for participating in such acts, including following orders. Earlier eras came to the opposite conclusion. No doubt St. Augustine would have been shocked by the actions of Calley or Eichmann, but he might well have accepted their self-justifications based on the need to obey commands. St. Augustine would have voted to acquit them.

The point is not to exonerate the perpetrators of atrocities but rather to emphasize the difficulty of doing the right thing when there are conflicting obligations. Obedience has long been recognized as an important and far-reaching obligation. Our modern American attitude toward obedience and authority is probably at the far extreme of skepticism, and even so the injunction to obey orders is compelling. Again, I am not arguing that people ought to obey illegal or immoral commands. The point is that the obligation to obey may come into conflict with other obligations, and there is no clear or universal conclusion about which obligation should prevail. Conflicting moral obligations pose a fundamentally unsolvable dilemma.

Moral conflict was another of the neglected aspects of Stanley Milgram’s obedience studies, in which ordinary people complied with instructions to deliver severe electric shocks to another person. Those who hesitated or objected were told that they must continue giving shocks, and most of them did so, even up to levels that could have proved fatal to the victim.

The people who took part in those experiments were typically neither sadistic nor indifferent. Many of them exhibited severe signs of inner conflict, including distress and agitation. Their hands shook, they began to sweat, and their voices became shaky. Often Milgram’s studies are cited as evidence that people will willingly perform immoral actions out of mindless respect for authority; but if that were the case, one would not have expected so many signs of inner struggle. In my view, such interpretations ignore the moral obligation of obedience. To follow the clear instructions of a legitimate authority figure is an obligation that is learned along with the very first moral lessons about right and wrong that parents teach their children. From the thoughtful standpoint of sophisticated ethical philosophy, one might conclude that the moral obligation to show concern for the welfare of others should take precedence over obedience to authority, but ordinary people caught in a moral conflict may not have the time for such reflections. The automatic response is to do what you’re told.

There are several other factors that contribute to the obedience pattern. First, most people probably learn very early in life that obedience should take precedence over one’s own doubts. Doubt and reluctance are nearly always bound up with obedience; after all, if you wanted to do something anyway, there would be no need for somebody to command you to do it. Parents teach children that the obligation to obey takes precedence over what they may want to do. Again, upon reflection, one should conclude that there is a fine distinction between reluctance based on selfish inclinations and reluctance based on a principled moral objection; but this is not a distinction that usually occupies the attention of an ordinary person caught in a moral dilemma. The habit of setting aside one’s reluctance to follow orders is instilled early (and more strongly in most other cultures in the history of the world than in our own).

Second, even if the person can think through the decision according to abstract moral principles, the choice is often between a possible wrong and a definite wrong—in which case, it may seem rational and sensible to do the possible wrong rather than the definite wrong. Children, soldiers, and other subordinates often do not have enough information to make a fully informed evaluation of all the moral niceties surrounding an order they have been given. The order may seen immoral, but perhaps there are factors they do not understand or appreciate. Thus, although it may seem wrong to carry out a particular order, it is hard to be certain.

In contrast, disobedience is clearly and definitely wrong, per se. The moral obligation to obey is implicit in the very concept of command. When the colonel commands you to sweep the floor or make your bed or stand over there, you are supposed to obey, which is why a command alone is sufficient (as opposed to requiring the colonel to try to persuade or induce you to sweep the floor). If you disobey, you can be charged and punished, and the court-martial is not likely to investigate whether the floor needed sweeping or whether you were satisfied with the colonel’s reason for giving the order. Every child whose parent has answered “Because I said so, that’s why!” will recognize the same moral premise: Disobeying the commands of legitimate, recognized authority figures is wrong.

Hence, a soldier who might be moved to question a command on moral grounds faces a dilemma, because both obeying and not obeying carry moral risks. Either course of action may be wrong, but one course is more surely wrong than the other. Moreover, disobeying the command puts the moral burden of proof squarely on you. Obeying might turn out to be wrong, but the burden of proof (and seemingly of responsibility) is not on you, at least not just then.

A third and related factor is the wrongness of second-guessing one’s superiors. This factor is also difficult for modern Americans to appreciate. Those of us who grew up in the 1960s and 1970s learned to challenge and question authority as a matter of course. From iconoclastic theories to the impeachment of a president, there was a strong pattern of attacking established authority. In the history of the world, however, it has been far more common to hold the attitude that the people in authority have superior knowledge, understanding, and virtue, and that it would be absurd and pretentious—not to mention insulting and treasonous—for a lesser person to question them.

Here and Now Another factor that reduces self-control and fosters the crossing of moral boundaries is a certain kind of mental state. This state is marked by a very concrete, narrow, rigid way of thinking, with the focus on the here and now, on the details of what one is doing. It is the state that characterizes someone who is fully absorbed in working with tools or playing a video game. One does not pause to reflect on broader implications or grand principles or events far removed in time (past or future).

I will have more to say about this mental state in Chapter 10 (Dealing with Guilt), because people do seek out this state to avoid emotions. For now, the relevant point is that this state may blind people to the crossing of a moral line. It may seem ironic to suggest that people can pay so much attention to what they are doing that they do not fully comprehend what their actions mean, but that is precisely what happens. By attending to the how, they may fail to think about the why—and especially the why not. To perceive that one is crossing a moral boundary into something that may be wrong, it is necessary to step back from what one is doing and think about one’s actions in the context of broad moral principles. Actions do not come labeled right and wrong, and they only acquire those moral qualities when evaluated from the perspective of meaningful principles. If one remains focused on the acts themselves, one may scarcely notice their moral aspect.

Put another way, self-control requires the person to see beyond the immediate situation. The term transcendence is commonly used to refer to this mental activity of perceiving the broader implications of current events. Thus, if you are hungry and you are offered some tasty food, you eat it. Self-control requires stopping this natural response and saying to yourself that eating this food would violate your diet and thwart your attempts to look appealing in a swim suit next summer. Or, as another example, it is normal and natural to take a rest when one is tired of working, but self-discipline can override that response if one needs to meet a deadline or prepare for a test.

There is a tendency for people to shift to low levels of meaningful thought while carrying out morally problematic, dangerous acts. In the words of John Douglas, one of the FBI experts on serial killers, “Crime is a moral problem. It can only be resolved on a moral level.” 12 The other side of that coin is that low-level thinking is amoral.

A smattering of evidence suggests that such concrete, here-and-now mental states facilitate crime and violence. One relevant sign is that when participants in major killing actions speak about what they did, they generally focus on techniques. This is true even when they are not trying to evade moral responsibility or defend themselves. It was probably the way they thought about their activities while they were doing them. Focusing attention on how to do something forces the mind to stay at a low level of meaningful thought, concerned with practical details rather than broad implications. 13 Thus, Nazis who discuss their actions during the Holocaust tend to emphasize the practical and logistical problems, which were often quite formidable. Likewise, a recent television special by Oprah Winfrey on child abuse showed several men describing the sexual molestation of children, and again their explanations focused on just how one carries it out: first gaining the child’s trust, then intimidating the child into remaining silent, and so forth.

We have seen previously that the notebooks of self-criticism kept by Khmer Rouge torturers in the notorious Tuol Sleng prison focused on technique. 14 Self-criticism is an important part of Communist practice. It obviously holds the potential for making people face up to their misdeeds and acknowledge the need to change themselves to become better citizens. Yet what these torturers criticized themselves for was ineffective torture techniques: sloppiness, deviating from standard procedures, failing to keep pencils sharpened, or causing the prisoner to die before a full confession was obtained.

Was this a defense? A disingenuous practice of criticizing minor faults to shift attention away from heinous actions? Possibly. But it is also necessary to recognize that these individuals were not encouraged by the Communist authorities to develop serious moral objections to the goals of the regime. Had they said, “Torturing someone is inhumane and unethical,” it is doubtful that their self-criticism would have been approved. Focusing on the technical failures and shortcomings in their job performance enabled them to perform more effectively.

Emotional Distress Another factor that may make it easier to cross the line is emotional distress. Emotion by itself does not produce evil, but in combination with several of the factors we have already noted, it can help to facilitate evil. In particular, it is well established that emotional distress breaks down self-control in many spheres. When people are upset, they say or do things that they would ordinarily hold back from saying or doing and that they may regret later.

Emotional distress is unpleasant, and people want to escape from it. Few people like to wallow in unpleasant feelings indefinitely; most will exert themselves to find some way to feel better. These efforts may even involve taking some chances or trying various activities that might hold the chance of improving one’s mood. All of this exertion is draining, and it weakens the capacity for self-control. When there is a violent impulse, the person is less able to restrain it.

Also, emotions can cause something akin to the here-and-now mental state I just described. When in an emotional state, people are often thoroughly wrapped up in what they are doing and feeling, and so they do not see beyond the immediate situation to broader issues, principles, and implications. There is a fair amount of evidence that when people are upset—that is, during an emotional state marked by unpleasantness and high arousal—they do not think things through adequately before acting. Instead, they seem to act on the first impulse or option that strikes them in a positive way. 15 The emotion seems to narrow their focus to their own immediate concerns, and they do not consider all the alternatives or other outcomes. Thus, one experiment showed that when people are under stress, they do not look at all the answers on a multiple-choice test; they simply take the first one that looks right. In other studies, people who were emotionally distressed tended to take stupid, costly risks because they were drawn to the potential for gaining something good—and they ignored the risk of having something bad happen.

Thus, emotion weakens one’s self-control and other defenses. Does it also increase aggressive impulses? Undoubtedly, some emotions do. Anger and frustration seem to give rise to the urge to hit someone or something, or to lash out in some other way. Indeed, it seems likely that the natural emotional response of rage was instilled in the human psyche by evolution as a way of prompting people to fight when necessary. True, not all anger or frustration leads to aggression, but aggressive responses are far more common when people are in such emotional states. In a sense, that is what the emotion of anger is: The feeling of an aggressive impulse. Emotions predispose people toward action, and anger involves the potential action of attacking or defending. 16

Alcohol and Evil Alcohol may also contribute to violence in a variety of ways. It is well established that many, perhaps most, violent crimes are committed by people who are under the influence of alcohol. Some other drugs (such as crack cocaine) may have similar effects, although research with such drugs is sparse, vague, and inconclusive compared to the large body of evidence about alcohol. 17

Does alcohol lead to aggressive impulses? The answer appears to be no. A well-known compilation of the research on alcohol concluded that alcohol by itself does not produce wild behavior. 18 Instead, alcohol produces wild behavior only when the person under its influence has some sort of inner conflict. If you feel like insulting your boss but normally hold back because doing so would be bad for your career, alcohol may make you more willing to express the insult. But if you like your boss and have no desire to insult him, alcohol will not cause you to do so. Alcohol seems to reduce self-control and thereby free impulses that are already there. It does not create new impulses or desires.

The effect of alcohol on aggression has been confirmed by laboratory studies. In one, college students took turns delivering electric shocks to one another. Some of them had been given alcohol to drink before the experiment, while others remained sober. Alcohol did not uniformly increase the level or severity of shocks that people gave. It did, however, increase the severity of retaliation. That is, if the other person was nice to you, you held back on shocking him, regardless of whether you had had any alcohol or not. If the other person gave you a nasty shock, though, you were more inclined to retaliate by giving him a hefty zap in return—and if you had been drinking, your response was even more extreme and aggressive. Thus, alcohol did not produce aggressive tendencies, but it increased them if they were prompted by the situation. 19

Alcohol weakens self-control, and this effect is abundantly documented. Alcohol seems to contribute to almost every form of self-control failure, from aggression to gambling, from smoking to emotional outbursts. Like people who are emotionally upset, people who drink cease to think through the implications of their actions. They stop keeping track of what they are doing (indeed, sometimes they cannot remember the next day what they did). They lose the ability to transcend the situation and instead respond to immediate pressures, impulses, or temptations.

The implications for understanding violence are important. It is incorrect to blame violence or aggression on alcohol. Intoxication is at best a contributing factor. Drinking is neither necessary nor sufficient to cause aggression, but it does reduce the inner restraints that normally prevent violence. Alcohol does not create violent impulses; it merely removes the inner blocks that normally stop someone from carrying them out. Alcohol will make violent people act more violently than they would normally.

A Culture of Violence?

Until now, I have emphasized individual factors and causes of violence, but cultures and subcultures undoubtedly shape the actions of individuals, too. There is no question that some cultures have higher levels of violence than others. Indeed, by most measures, modern America is one of the world’s most violent cultures. A bad weekend in New York or Washington will produce as many murders as many as an entire country will have in a full year. Faced with such variations, one has to suspect that the values, attitudes, and norms of a community can help determine its level of violence.

Yet the matter is not so simple, and the links between culture and violence are currently a focus of hot debate by experts. The current controversy is partly a result of the gradual collapse of the theory of “subcultures of violence.” The notion that there are violent subcultures was proposed in the 1960s as a possible explanation for the fact that certain groups, such as poor people living in the inner city, have higher levels of violence than others. This theory proposed that such groups must have more positive attitudes about violence than others, and so people who grow up in such cultures learn that violent activity is a proper way to gain respect and prestige (and possibly other benefits). Although the argument was aimed at subcultures within the United States, it could readily be extended to entire cultures, such as the Yanomano tribe, which has been identified as especially violent.

The Fruitless Search for Subcultures that Endorse Violence Initially, researchers embraced the theory that violence was learned as a positive value in certain subcultures, but the theory gradually lost favor and was discredited. One of the most decisive reasons the theory was dropped was that it proved impossible to find groups or subcultures that held positive or favorable attitudes toward violence. In particular, surveys found that inner-city black people did not endorse violence or report favorable attitudes about violent actions any more than suburban whites or other comparison groups. (Even if only some of the members of any particular group were favorably disposed toward violence, that still should have shown up in the overall averages, but there was no sign of it.) Although certain groups did have higher levels of violence, they did not seem to hold positive attitudes about it.

The theory of the subculture of violence also lost ground as studies showed that people who behaved violently did not seem to regard these actions as a means of gaining prestige or making a positive impression on others. 20 If the subculture were somehow encouraging violence, then presumably people would do violent things to gain approval, but this did not seem to be the case.

More recently, there has been a little evidence to the effect that in violent youth gangs and other groups who live violently, certain individuals do cultivate reputations for being dangerous and aggressive. 21 Possibly these findings could support the theory of a subculture of violence. Still, it is not clear that even these individuals seek such reputations because of a positive value placed on violence. The reputations may be sought strictly for pragmatic reasons. They may even be sought because of a generally negative attitude toward violence. Jankowski concluded that members of youth gangs who wish to avoid fighting can do so best by building a reputation for extremely dangerous, unpredictable aggressiveness, because such a reputation causes others to leave one alone. If you are known for an odd propensity to do remarkably nasty and cruel things unpredictably, people will become reluctant to trifle with you. In contrast, the individual or group that is perceived as reluctant to fight may become a target for the violence and exploitation of others. Thus, Jankowski cited several instances of gang members who, ironically, were known as exceptionally violent and who therefore hardly ever fought. No one dared provoke them.

As a result of these and other findings, researchers largely gave up on the notion of a subculture of violence. Today it is not among the major or prominent theories about aggression. 22

Subcultures, Irresistible Impulses, and Self-Control In my view, however, the notion of a subculture of violence deserves another look—but with a few changes. The idea that certain groups place positive value on violent behavior may be wrong, but that does not mean that cultural and subcultural values are irrelevant. The most important relevant values may be those concerned with maintaining versus losing self-control.

Thus, modern America may be violent not because it approves of violence (which it clearly doesn’t) but because it supports the belief that people will inevitably lose control on many occasions. Our culture has lately become increasingly fond of notions of “irresistible impulses” and genetic causes of addiction. But in research on self-control, one conclusion stands out over and over again: People acquiesce in losing control. In other words, they let themselves lose control, and they become active participants. Whether it is a matter of breaking a diet, going on a drinking binge, or abandoning an unpleasant task, usually the person somehow allows it to happen. The same applies to violence. The concept of an irresistible impulse is somewhat misleading, because most violent behavior is not truly the result of irresistible impulses. People allow themselves to lose control. And they do so in part because they learn to regard certain impulses as irresistible.

Often the person’s acquiescence in losing control is cleverly disguised. For example, people speak as if an eating or drinking binge were simply a matter of being overwhelmed by strong impulses that rendered them passive and helpless. Yet during these binges, they continue to procure food or drink, prepare it for consumption, put it in their mouths, and swallow it. These are active, not passive actions. Resisting the impulse may have been too difficult for them, but they have not simply quit resisting, they have become active accomplices in indulging their desires.

The same is often true of violence. Many people speak as if certain provocations produce an unstoppable rage that make violent action impossible to stop. Since the legal system has often given lighter penalties to people who commit crimes in the heat of passion, it is hardly surprising that people often claim that their actions were provoked. The point is not that they are lying; rather, they know in advance that certain provocations produce acceptable reasons for becoming so passionate that one can lose control and commit violent acts. Most of the time, they do actually retain some degree of control. For example, an angry husband may say that he was so provoked by his wife that he could not stop himself from beating her severely, but in fact he does usually stop himself before he permanently injures or kills her. Whatever his heat of passion, he usually does know when to stop.

A vivid illustration of the hidden operation of self-control was provided by a young man interviewed in a study of violent offenders in a British prison. 23 This man described meeting his wife’s lover in a bar and attacking him in a wild rage. At one point he took a bottle and broke off the end to create a dangerous weapon with sharp points of broken glass. But then, as he recalled, he realized that if he were to use that weapon he would probably kill the other man, which would send him to prison for a long time. And so he put down the bottle. Then he resumed attacking the other man with his fists, beating him quite severely. The man ended up in prison after all, but of course with a sentence that was much lighter than he would have received had he used the broken bottle to kill the man. Even in the heat of rage and violent combat, the man could and did resist a very violent impulse.

The irresistible impulse notion was likewise rejected by FBI expert John Douglas. After spending his career studying hundreds of serial murderers and other killers, he said there was no way to believe that they were temporarily insane and out of control. For one thing, he noted that none of these killers had ever murdered someone in the presence of a uniformed police officer. Such a murder would be foolish, of course, but if the impulse were truly irresistible, it would not be deterred by the threat of arrest. 24 For another, he described several cases in which a serial killer would choose a victim and then cancel the abduction because circumstances did not seem favorable (for instance, witnesses might be nearby). Finally, he said, it is simply implausible that someone who was out of control and temporarily insane could get away with 10 murders without getting caught. Avoiding capture takes too much careful planning and caution for a psychotic or even for an uncontrolled person to manage.

Nor are these arguments limited to individuals. Mobs, too, seem to be able to know when to stop. At the beginning of 1993, Rwanda, Africa, was in the grip of escalating violence against the Tutsi minority. The number of victims was small in comparison with what came later, but there were deaths, burnings, and refugees. On January 7, an International Commission on Human Rights arrived to investigate claims of abuses. The violence stopped abruptly. The commission left two weeks later, and immediately a “murder rampage” killed several hundred people and inflicted many lesser atrocities over the next six days. 25

In such cases, it is hard to avoid the conclusion that people know just how much they can allow themselves to lose control. Yet that point is not firmly determined by natural law; rather, it is influenced by cultural beliefs. This is where the theory of a subculture of violence needs to be revised. It is not that cultures place a positive value on violence but that culture dictates when and where (and how much) it is appropriate to lose control.

The provocations that make people angry do not vary all that much from one person or culture to another, but the degree of violence in the response may vary quite a bit. Is it appropriate to punch someone who insults you? What about running him through with a sword? Is it reasonable to kill someone you catch in bed with your spouse? Should a man strike his wife or child who willfully disobeys him? (And if so, should he use the palm of his hand, his fist, or a small stick?) If someone attacks you, can you fight back, and if so can you use other weapons than the ones he used? May a woman stab, maim, or kill a man who tries to rape her? Must you challenge someone to a duel if he insults your mother (or does it depend on the degree of insult)? Different cultures have varied widely in the answers they have given to these and similar questions.

Thus, violence occurs when people allow themselves to lose control of angry, violent impulses. A culture of violence does not have to place a positive value on violence. It can encourage violence merely by making it appropriate to let oneself go in response to a broad range of provocations. Culture does not have to encourage violent behavior in order to produce it (and this may be where the previous theories about subcultures of violence went wrong). People will have violent tendencies or impulses without needing a culture to instill them. All the culture has to do is stop restraining them, and these tendencies will emerge.

Indeed, the very notion of an “irresistible impulse” seems to me to be a cultural construction and one that is highly questionable on psychological grounds. There is such a thing as an irresistible impulse, but usually such impulses are limited to biological necessities. If you require someone to stand up for an indefinite period of time, eventually the urge to sit or lie down will become irresistible. Likewise, the urge to urinate can eventually become irresistible. To me, “irresistible” means that you would do it even if someone were aiming a gun at you and forbidding you to do it; and indeed people will eventually lie down or urinate despite such a threat. But such cases are rare and exceptional. There are very few other impulses that are truly irresistible.

There are, however, plenty of impulses that people can learn to treat as if they were irresistible. Resisting impulses is hard work, and if people have a readily available excuse for not doing that work, they will often be only too happy to give in. If your culture tells you that a normal and reasonable person would not resist a certain impulse, you may feel free to act it out. This can mean gambling large sums of money, eating too much, drinking to excess—or hitting or shooting someone at whom you are angry.

How Cultures Exert Influence There are many ways in which cultures can teach people that it is appropriate to lose control and become violent under particular situations. We have already touched on the role of laws and courts. In some countries, for example, it was not considered a crime for a man to kill his wife’s lover or the wife herself, as long as he had certain proof of their indiscretion. In our culture, such an act would be illegal, but defense attorneys are steadily expanding the scope of irresistible impulses to excuse an ever broader range of crimes.

There are two other major ways that the culture can exert influence over individual decisions. The first, most fundamental and most universal, is through social learning. One sees what other people do, and one learns to do the same. Children learn a great deal about managing anger and violence right in their own families. Some children grow up in families where they never see either parent raise his or her voice, and the notion of physically striking a family member would be appalling. Other children are exposed to shouting and slapping almost daily. It is hard to imagine how children could emerge from such widely different backgrounds and hold identical views about the self-control of anger.

Indeed, this sort of learning is probably the most potent factor in the intergenerational transmission of domestic violence. In recent years, a great deal of discussion has been devoted to the research findings that people who were abused as children are more likely than others to become child abusers themselves. Research has also found that children who saw their parents fight with each other physically are more likely than others to engage in physical violence in their own marriages. 26 Rather than postulate a genetic cause or a Freudian unconscious compulsion to explain this violence, I would say it seems likely that the main cause is learning. The child simply learns that this is how one treats family members.

Again, I doubt that children who observe their parents fighting come to the conclusion that beating one’s spouse or other family member is good. Some researchers have suggested such conclusions, but I have not seen evidence to support it. Indeed, the evidence seems to indicate that most children think violence between their parents (or other family members) is frightening and upsetting. But it is not necessary to encourage violence in order to produce it; it is merely necessary to stop discouraging it. When children see their parents fight, they learn that hitting is one way to resolve a conflict or win an argument, and they may learn that love does not end and families do not break up simply because of a few blows. They saw their parents lose control in response to certain provocations, and they may allow themselves to lose control when similarly provoked.

The second way in which culture can influence individuals is through the mass media. The topic of violence in the media has been debated (with good reason) for several decades. At present, the main conclusions are as follows. Media violence can have a small but genuine effect on aggressive behavior: Specifically, people who are exposed to media violence are sometimes more violent in their own subsequent actions. These effects appear to be short-term and depend on cues to connect the film violence with one’s own situation—such as if you are angry at someone who reminds you of the villain in the film.

Television and movies also provide people with evidence about what life is like and how people deal with problems. This information may be inaccurate, but it is nonetheless influential. Heavy television viewers are prone to various misconceptions about the world. For example, they tend to believe that there are many more physicians and lawyers than there actually are, because such characters are common on television. Also, and more to the point, people who watch a great deal of television gradually come to develop a greater fear of crime than other people, because there is so much crime on television. Still, the spread of television through the United States has not seemed to lead to any direct increase in violent crime; instead, it has produced an increase in property crimes, such as auto theft. Apparently, television does not have its effects by producing copycat criminals who perform the deeds they see on the tube. Instead, it makes people desire material things and suggests to them that many people might turn to crime to satisfy such desires. 27

The copycat phenomenon deserves further study, however. Probably only a few people are inspired to commit violent deeds that they see in the mass media, but these few can be quite important. This aspect is missing from much of the debate about media violence. The debate is usually phrased in terms of whether watching violent entertainment will inspire violent behavior in the average person. Although there are a few such effects, they seem to be weak, limited, and temporary, and on that basis, one cannot blame the media for society’s violence. But a few people who may be inclined toward violent action may find that the mass media affect them and inspire them to commit crimes.

One FBI expert on mass murderers and serial killers believes that the media do play a role. Robert Ressler 28 notes that the spread of serial killing in the United States coincided with a historical shift in the film industry. Up through the 1950s, most horror movies featured supernatural villains such as Dracula and Frankenstein. Beginning in the 1960s, however, films began to depict ordinary people committing monstrous crimes. Alfred Hitchcock’s Psycho was famous in this regard, because the bloodthirsty killer was the apparently quiet and friendly clerk in a motel. Ressler thinks that lonely, violently inclined individuals scattered around the United States may not have been inspired to identify with Dracula, and so watching the earlier horror films had little effect on them. But when they began to see ordinary people killing victims in the movies, something clicked. These films planted something in their imagination and made them begin to think about how they might do similar things.

Ressler’s argument does not mean that movies planted the urge to kill. Instead, he thinks that these people may have had vague violent urges that remained shapeless and ambiguous for a long time. Movies enabled these people to imagine themselves tormenting and killing victims. Imagining something is an important step toward actually doing it. For that reason, Ressler thinks that the modern epidemic of serial murder coincided with the rising popularity of horror films that feature violent acts by seemingly ordinary people.

Recent experimental work paints the same picture. The serious effects of media violence are found only in a small minority of highly aggressive individuals. To be sure, there is a short and temporary effect of watching a violent film that may make almost anyone a little more aggressive if provoked soon after in a way that is reminiscent of the film. 29 But nonaggressive people are only slightly affected.

So media violence seems to affect people who are inclined toward aggression anyway. The effects are multiple, as shown in recent work by Brad Bushman. 30 First, aggressive people are more likely to seek out violent films. Second, such films have a more arousing and anger-producing effect on aggressive people than on others. Third, such individuals are more spurred to violent or aggressive actions by such films than are other people.

One way to understand these effects is to imagine a lonely, unhappy man with an abusive childhood behind him and a vague anger against other people, or against some particular category of other people (such as women who remind him of his mother). Without television or movies, his anger might smolder for a long time, but it does not get formed into clear impulses for particular attacks and tortures. Yet if the man begins to see violent films, he may start to flesh out his vague angers into specific and vivid fantasies. He finds himself drawn to watch such movies more than other people, and he finds them very arousing. He begins to imagine himself capturing a woman and doing particular things to her. Over time, these acts become more and more cruel. It may be a long time before he acts on them, but the day of action has moved much nearer.

Robert Ressler’s long-time colleague and friend John Douglas, another FBI expert on serial killers, made a telling comment in a recent discussion of his work. He was describing a very brutal murder on which he had been called to consult. The victim, Francine Elveson, was a 26-year-old teacher. She was shy and lived with her parents in an apartment building. One day she went out to work and apparently disappeared. Her wallet was found in the stairwell, and when her mother called the center where she worked, she was told that Francine had never shown up. A search of the area found her body on the roof landing at the top of the stairwell. She was nude and had been severely beaten with some blunt object. Her nose, jaw, and cheeks had been fractured and her teeth had been loosened. She had been tied in a spread-eagled position with her own garments, apparently after she was already dead. Her nipples had been cut off and placed on her chest. Her underpants had been cut off and put over her face. There were small knife wounds all over her body, and there were bite marks on her thighs. She had not been raped per se, but traces of semen were found on her body, which suggested that the killer had masturbated, presumably onto the corpse. Her vagina had been penetrated with her umbrella and her pen. Her comb was left on her pubic hair, and her earrings were arranged symmetrically on the floor by her head. Douglas’s comment: “This advanced a sexual fantasy would take years to develop.” 31

Douglas concluded (correctly) that Francine Elveson had been this particular killer’s first victim. But he had obviously been thinking about it for a long time. The exorbitant attention to detail, including all the things he did with the corpse, reflected the working of a twisted imagination over a long period of time. By labeling this fantasy “advanced,” Douglas was acknowledging that the path from vague hostility to ritualistic murder is a long and slow one. Unfortunately, though, the media can help bring people along this path. The media are, after all, tools to help the imagination. Normally this is a wonderful gift and a marvelous advantage to living in the modern era. When the imagination turns to evil, however, the media’s influence can be just as harmful.





