Chapter 6
Decision-Making Under Uncertainty

Dominik R. Bach




Abstract All decision-making takes place under uncertainty, even in controlled
laboratory circumstances. The Bayesian brain hypothesis, a widely accepted the-
oretical framework of brain function, prescribes that the brain uses probability
distributions to store parameter values, rather than point estimates, and is thus able
to use uncertainty on various parameters. This allows for investigating value-based
decision-making under natural circumstances when information needs to be
extracted from noisy input, and it may also impact on decisions based on propo-
sitional information. In this chapter, I present experimental approaches to neural
representations of uncertainty in value-based decision-making.



6.1    Introduction

Economists often distinguish risk from uncertainty. Risk quantiﬁes the uncertain-
ness of outcomes to be realised from a decision. Uncertainty denotes all imprecision
on propositional aspects of a decision-making situation. Following this distinction,
many economic theories treat decision-making under uncertainty as a special case.
However, for biological agents, all decision-making takes place under uncertainty.
   Imagine a controlled laboratory experiment where an agent can make a simple
choice between two options. Option A is to win either €10, or €20, depending on
whether we draw a black or a white ball from an urn with 50 black and 50 white
balls; option B is a sure amount of €15. B. There is no uncertainty in this abstract
presentation of the decision problem, other than the risk associated with the out-
come of the urn draw, if option A is chosen. To analyse this situation, classic
economic theories will rely on the propositional information given to the
decision-maker. Consequently, experimenters will try to convince agents that the

D.R. Bach (&)
University of Zurich, Zurich, Switzerland
e-mail: dominik.bach@bli.uzh.ch
D.R. Bach
University College London, London, UK

© Springer-Verlag Berlin Heidelberg 2016                                           99
M. Reuter and C. Montag (eds.), Neuroeconomics, Studies in Neuroscience,
Psychology and Behavioral Economics, DOI 10.1007/978-3-642-35923-1_6
100                                                                         D.R. Bach

abstract, propositional information given to them is accurate, such that classic
theory is applicable.
    However, human’s brains are equipped to solve far more complex problems,
extract information from noisy input, and infer the structure of the world. Moreover,
typical adults will have multiple experiences with situations similar to the labora-
tory choice. For example, why should they believe that the urn used by the
experimenter really contains equal numbers of black and white balls?
    In the next section, I will review a probabilistic framework for how the brain
retrieves and stores information, to form the basis for a model of economic
decision-making. The neural implementation of these algorithms has been reviewed
both on a microscopic/neuronal (Pouget et al. 2013) and on a macroscopic level
(Bach and Dolan 2012). Here, I will give an overview of the different kinds of
uncertainty that are experimentally manipulated in neuroeconomic investigations.



6.2   A Probabilistic Model for Economic Decisions

Abstract models of value-based decision-making often assume that a
decision-making agent receives propositional information in the form of particular
numbers, such as values, utilities, probabilities, risk attitudes and so on, and a
problem structure that links these numbers. The agent uses this information, for
example, to maximise utility. The ﬁgures that deﬁne the decision problem either
arise from current information (for example, the possible outcomes of the urn draw)
or from stored values (for example, risk attitudes). Of course, under everyday
circumstances, most information is not provided in the form of abstract, proposi-
tional information. This begs the question: how does a biological agent extracts the
relevant economic information from a continuous stream of sensory input? How
does it store and update this information to yield stable preferences and attitudes?
This question is relevant also for controlled laboratory experiments because
decision-making usually relies on attitudes or preferences acquired previously in
real-world contexts—such as a risk preference in our initial example.
   It turns out that biological agents use two fairly general principles of processing
information: probabilistic computing, and hierarchical causal structures (Dayan and
Hinton 1996; Dayan et al. 1995; Friston 2010). Our sensors provide information
that is both very noisy and redundant (Kording and Wolpert 2006; Vilares and
Kording 2011). This is a challenge for any system, biological or man-made. In
order to make inference on the outside world given rich and noisy input, the task is
to combine information from various noisy sources. As an example, imagine you
are in price negotiations on a bustling street market when the trader announces his
ﬁnal price, and a bystander steps forward to grab the opportunity and buy the item.
You have to make a quick decision whether or not to express your interest, but your
sensory system is not quite certain whether what the trader said was “thirteen” or
“thirty”. Although we are never consciously aware of this, our sensory system will
combine the auditory information with visual information from observing the
6 Decision-Making Under Uncertainty                                                               101

traders mouth, and with previous information on the course of the price negotia-
tions. This integration of redundant information reduces noise. In order to make the
best possible inference, it is necessary to take the level of uncertainty on each
information source into account: more reliable information should be given more
weight. The auditory information should count less when it is noisy; but if it is dark,
on the contrary, then the visual information should be discounted. A principled
framework for making inference under these circumstances is Bayesian Decision
Theory (Orban and Wolpert 2011; Trommershauser et al. 2011).
   In Bayesian statistics, probabilities represent degrees of belief. This makes it
possible to represent uncertainty on parameter values (Fig. 6.1). In an inference
problem, a parameter value is given but unknown to us—it needs to be inferred.
Classical statistics represents an estimate of a true parameter value as point esti-
mate. For example, if we want to know whether the urn in the initial example is fair,
we can draw many times and calculate the probability of drawing white from the
sample mean. This is one single number, hence it is called a “point estimate”
(Fig. 6.1). Bayesian statistics allows directly expressing our beliefs in particular




Fig. 6.1 Illustration of point estimation for a parameter value (left) and probabilistic represen-
tation of parameter values as in Bayesian statistics (right). In the initial example, an agent is told
that the urn contains 50 black and 50 white balls. He then samples 20 balls and receives 11 white
balls. A point estimate of the number of white balls is 55 (black, left). The agent has to decide
whether to follow this estimate, or the propositional information (dark grey, left). A probabilistic
estimate expresses the uncertainty associated with the limited number of samples (black, right).
The agent may also combine the sampling information with a strong belief that the propositional
information on the urn is correct (dark grey, right) or with his private belief that the experimenter
will actually fob him off with an urn that just contains 30 white balls (light grey, right). The
dispersion of these distributions corresponds to the uncertainty on the number of balls
102                                                                          D.R. Bach

parameter values, and updating them from experience. For example, from our
knowledge, we may start with a strong prior assumption that the urn is fair, and
update this after each draw. This will give us a probability distribution over dif-
ferent probabilities of drawing white. Importantly, we are now also able to express
skewed priors—for example, because we think that the experimenter will fob us off
with a biased urn. We may therefore express an initial belief that the urn contains
only 30 white balls, and update this with experience. It appears from sensorimotor
research that neural systems compute with probability distributions (Pouget et al.
2013), and use them to express prior beliefs (Brouwer and Knill 2009; Kording
et al. 2004; Kording and Wolpert 2004; Tassinari et al. 2006), some of which may
be in-built or acquired early during development (Parise et al. 2014). This has been
proposed as a general computing principle of the brain (Friston 2009, 2010; Knill
and Pouget 2004).
    The principle of probabilistic computations provides a particular view on eco-
nomic decision-making. Take, for example, the famous St. Petersburg paradox
(Bernoulli 1738; Camerer 1995). This describes a gamble against a casino with
unlimited resources. The player tosses a fair coin until heads appear for the ﬁrst
time. If heads appear on the ﬁrst throw, he gets €1. If heads appear on the second
throw, he gets €2, on the third throw €4, €8 on the fourth throw and so on. Because
the casino has inﬁnite resources, the coin tossing can continue forever, until heads
appear. It is possible to mathematically show that the expected value of this gamble
is inﬁnite. Yet, most people would pay only a very limited amount of money to play
this kind of lottery, despite the expected inﬁnite value. This appears paradoxical.
Expected utility theory explains this with the assumption that people do not max-
imise expected value; instead they maximise expected utility. Given a particular set
of utility functions, the difference in utility between any two subsequent coin tosses
becomes smaller and smaller (a phenomenon called “diminishing marginal utility”,
Fig. 6.2), and hence the expected value of this gamble can be shown to be ﬁnite.
Hence people only pay a ﬁnite (and rather small) amount of money. While this is a
widely accepted explanation of this paradox, there is an alternative interpretation.
This is based on the commonsensical notion that there exists no casino with
unlimited resources. Using Bayesian statistics, one may formulate prior assump-
tions about possible payout values, and the possibility of magnitudes above a
certain threshold will be assigned zero probability. Combining these prior
assumptions with the actual data (the description of the St. Petersburg gamble) will
yield a probability distribution for every possible gamble outcome—this distribu-
tion describes how likely the outcome will have this or that monetary value. The
mean of this distribution will have ﬁnite value, different from the abstract infor-
mation about the problem. Thus, in a Bayesian framework this paradoxon can be
explained without invoking non-linear utility functions.
    Experimental research has focused on how the brain stores and manipulates
probability distributions, and their associated uncertainty. In the following sections,
I will review experimental approaches from economic and noneconomic contexts.
6 Decision-Making Under Uncertainty                                                                 103




Fig. 6.2 Example of a non-linear utility function which transforms objective value—here in €—
into utility. The lines indicate values with equal intervals of €5. However, because the utility
function is non-linear, the corresponding utilities have unequal spacing—the intervals become
smaller with increasing utility. This phenomenon is termed “diminishing marginal utility”. Ticks
on the utility axis indicate expected utilities of three different situations. The utility corresponding
to a value of €15 (light grey line) is larger than the expected utility corresponding to a 50 % chance
of obtaining €20 and a 50 % change of obtaining €10 (medium grey lines)—this is the initial
example in the text. The expected utility of a 50 % chance of obtaining €20 and a 50 % change of
obtaining €10 (dark grey lines) is even smaller. Given a choice between any of these three
situations, a utility-maximising decision-making agent would choose the situation with higher
utility, and this corresponds to the situation with lower outcome uncertainty (risk). This explains
how risk preference (in this case, risk aversion) can be explained with a non-linear utility function


6.3     Uncertainty of Decision Outcomes

Uncertainty of decision outcomes is arguably the most investigated type of
imprecision in value-based decision-making. Given the irreversibility of time, there
appears an epistemic difference between uncertainty of future outcomes which are
unknowable, and uncertainty on present and past events which are in principle
knowable. Most empirical research is on future outcomes, but it is not clear whether
decision-making systems make this distinction, for example, whether they represent
the risk of a past lottery different from the risk of a lottery to be played out in the
future. I will ﬁrst consider economic approaches, and then briefly discuss the
non-economic aspects.
(a) Risk in expected utility and ﬁnance theory: The dispersion of predicted
    utility or value is usually termed risk in economic (von Neumann and
    Morgenstern 1944) and ﬁnance theory (Markowitz 1952), and quantiﬁed as
104                                                                          D.R. Bach

    variance of the outcome distribution. A large body of evidence indicates that
    risk influences choice behaviour (Camerer 1995). Standard economic models
    (expected utility theory, EUT, and its variants) explain this with non-linear
    utility functions (Fig. 6.2), without an explicit notion of risk. Risk-return
    models in ﬁnance theory, on the other hand, directly represent risk in calcu-
    lations (Markowitz 1952). Overt choice behaviour can be equally well
    described in both frameworks. However, to implement EUT neurally, an agent
    must explicitly encode magnitudes and probabilities of all possible outcomes,
    while to implement a risk-return model, only mean and variance of the out-
    come distribution need to be encoded (d’Acremont and Bossaerts 2008).
    Encoding all possible outcomes might be feasible in a structured economic
    gamble, but is inefﬁcient when the number of possible outcomes becomes
    large. Interestingly, implementing EUT, or risk-return models, makes different
    predictions for exploration behaviour, which were tested experimentally
    (d’Acremont and Bossaerts 2008). Participants played a repeated lottery. Each
    time, they were instructed about the magnitudes of all possible outcomes, but
    not about their probabilities. By paying some money, they could sample from
    the lottery to experience the probabilities of these outcomes. Then, they were
    given a chance to bet on that lottery in order to gain money. In some trials,
    outcome probabilities and magnitudes changed from the previous trial. In
    other trials, participants were informed that outcome magnitudes had changed
    from the previous trial, but that outcome probabilities were held constant. Had
    participants encoded all the outcome probabilities from the previous trial, there
    would have been nothing to gain from sampling the new lottery (because the
    magnitudes, the only thing that changed, were stated explicitly). However, in
    about half of these trials, participants did sample the probabilities, which
    suggest that they did not encode all individual outcome probabilities. To be
    risk-sensitive nevertheless, they would have encoded mean and variance of the
    outcome distribution. This connects neuroeconomics to reinforcement learning
    theory: Biological agents can learn with experience to predict the mean of an
    outcome distribution. To do so, they appear to use algorithms that compute a
    difference between predicted outcome and actual outcome, termed prediction
    error (Mackintosh 1983; Pearce and Hall 1980; Rescorla and Wagner 1972;
    Sutton and Barto 1998). When the outcome distribution has a high dispersion,
    prediction errors are expected and do not imply that the prediction is wrong;
    when the outcome dispersion is low, prediction errors are more informative.
    Hence, the dispersion of the outcome distribution is important for reinforce-
    ment learning and has been termed “expected uncertainty” (Yu and Dayan
    2005). To acquire a notion of outcome dispersion, update algorithms have
    been suggested that rely on “risk prediction errors” (d’Acremont et al. 2009;
    Preuschoff et al. 2006).
(b) Uncertainty on future states: A simplifying model of the world is to describe
    it as a series of discrete states that are connected by transition probabilities (a
    Markov chain). If the future state is one with economic value, then this model
    captures a typical economic gamble, but this framework is more general. One
6 Decision-Making Under Uncertainty                                              105

    can, for example, quantify uncertainty over future states as entropy (Aron et al.
    2004).
(c) Motor uncertainty: Value-based decisions in biological environments usually
    involve motor actions. Sensorimotor control theory is concerned with the
    planning and implementation of uncertain motor action under uncertain sen-
    sory guidance (Orban and Wolpert 2011). For example, when catching a ball,
    if we observe longer, we will have more precise information on the ball
    trajectory—but if we initiate the movement earlier, the movement will be more
    precise. Choosing the optimal observation interval requires integrating the
    uncertainty of the future movement with the uncertainty of past observations
    (Battaglia and Schrater 2007; Faisal and Wolpert 2009). More generally, when
    the result of a decision is implemented with an uncertain motor action, nor-
    mative accounts mandate that motor uncertainty is factored in for the decision.
    This may be relevant for economic experiments done in non-human species.
   How does the brain represent uncertainty of decision outcomes? Phasic ﬁring in
dopaminergic midbrain neurons is consistent with prediction error signals during
reinforcement learning (Schultz et al. 1997); and these signals are scaled by out-
come uncertainty (Tobler et al. 2005), consistent with a reinforcement learning
account of expected uncertainty. Neurons in orbitofrontal cortex carry outcome
uncertainty signals in their ﬁring rate, independent of value signals (O’Neill and
Schultz 2010), although see Ogawa et al. (2013). Third, BOLD fMRI studies have
implicated more than ten distinct brain regions as representing outcome uncertainty
in various different experimental situations (Abler et al. 2009; Dreher et al. 2006;
Fitzgerald et al. 2010; Mohr et al. 2010; Preuschoff et al. 2006; Rolls et al. 2008;
Symmonds et al. 2010, 2011; Tobler et al. 2007). These heterogeneous ﬁndings
may justify speculating that neural encoding of outcome uncertainty depends on the
process by which the outcome distribution is estimated (Fig. 6.3).



6.4   Uncertainty on Decision Circumstances

Most decision circumstances are known to the decision-maker only with some
imprecision. In the context of value-based decision-making, uncertainty of gamble
probabilities has been investigated most. A related concept from reinforcement
learning is volatility (Behrens et al. 2007; Mathys et al. 2011). Another is the
presence of rule violations indicating reinforcement rule change, and thus, uncer-
tainty on the rules; this situation has been termed “unexpected uncertainty” (Yu and
Dayan 2005). Because the impact of such uncertainty on value-based decision-
making is less well known, I will focus here on uncertain gamble probabilities and
the related economic concept of ambiguity (Ellsberg 1961).
   Imagine a lottery in which outcome probabilities are not explicitly stated—
instead they can take several particular values. This situation is often termed
“ambiguity” and leads to the famous Ellsberg paradox (Ellsberg 1961). Let’s say
106                                                                                    D.R. Bach




Fig. 6.3 Illustration of a gamble involving uncertainty on outcome probabilities (Bach et al.
2011). A A grey “bowling” ball appears on the screen. The agent is instructed that it may have
come from one of two players (orange, blue) with dispersion indicated by the colour gradients
below the grey ball. Orange and blue balls have different probabilities of winning from the
gamble. The uncertainty (Shannon entropy H) associated with the ball position is indicated on top.
B A corresponding gamble with no uncertainty. The grey ball may have come from either of two
blue players, such that the outcome probabilities correspond to “blue” and are known


our initial urn A contains 100 balls, half of which are black, and the other half
white. Another urn B contains 100 balls with unknown proportion of black and
white. Would you rather bet on black in urn A or B? Some people may say A, so
under assumptions of EUT, one can infer that they think the probability of winning
from black in urn A (which has p = 0.5) is larger than of winning from black in urn
B (which has therefore p < 0.5). Further, would you rather bet on white in urn A or
B? Again, the same people may say A, so that the probability of winning white
from urn B is again p < 0.5. The proportion of black and white balls in urn B hence
does not add up to 1, which constitutes the paradox. Following this thought
experiment, empirical investigations have demonstrated that most people avoid
ambiguity, even when this does not maximise utility; for example, if one has to pay
6 Decision-Making Under Uncertainty                                                 107

extra money to bet on urn A (Becker and Brownson 1964; Curley et al. 1986; Keren
and Gerritsen 1999; MacCrimmon and Larson 1979; Pulford and Colman 2008;
Slovic and Tversky 1974; Yates and Zukowski 1976).
    How can we resolve the paradox? Urn A constitutes a single-stage lottery. By
contrast, urn B can be understood as a two-stage lottery. There is a bet on the
distribution of balls in urn B, termed second-order distribution (Bach et al. 2011;
Klibanoff et al. 2005), and a bet on the outcomes of a draw from this distribution.
EUT posits that a rational decision-maker should collapse the two stages of this
lottery (Camerer 1999). In the absence of further information, one should assume a
uniform second-order distribution (that is, all 100 possible compositions in urn B
have probability p = 1/100). For each possible urn composition, one should mul-
tiply the ensuing ﬁrst-order probabilities of a black or white draw, multiply them
with its second-order probability and ﬁnally add up all probabilities for black and
white across all urn composition in order to make a decision. It turns out that in this
case, the expected outcome is the same for both urns.
    The Ellsberg paradox however is only a paradox if we assume this reduction of
the two-stage bet to a single-stage one. If we assume that people treat the lottery as a
full two-stage bet, we can invoke a number of reasons to explain ambiguity aversion.
A very simple reason would be that decision-making agents have a prior belief that
the number of balls in urn B is not uniformly distributed, and unfavourable urn
compositions are more likely. Indeed, restricting the range of possible urn compo-
sition reduces ambiguity aversion (Keren and Gerritsen 1999; Larson 1980).
    However, ambiguous and non-ambiguous gambles differ across other factors as
well. For example, by making a choice between urn A and urn B, people reveal their
knowledge and belief about gambles and probabilities, something that might have
additional (positive or negative) utility. When people are asked to make their choice
publicly in a group, ambiguity aversion is larger than when they make the same
choice, but write it down on a piece of paper that is only later to be read by the
experimenter (Curley et al. 1986). In line with this, instructing individuals that their
choices are going to be evaluated increases ambiguity aversion (Muthukrishnan et al.
2009). Also, when people gamble on getting one of two movies, where the experi-
menter asks which of the two they prefer, they avoid gambles of type B. However, if
the experimenter does not know which movie they prefer, there is no ambiguity
avoidance (Trautmann et al. 2008). In this latter case, the experimenter cannot judge
people’s choices because he does not know what they want to obtain from the
gamble. This is a purely social factor that may explain ambiguity aversion but has no
relation to uncertainty. Interestingly also, ambiguity aversion (Chow and Sarin 2002)
—and also brain responses to ambiguous gambles (Bach et al. 2009)—depend on the
fact that something is hidden from the observer rather than completely unknowable.
    In summary, ambiguity is a good example how the categorical contrast certainty
versus. uncertainty can be imbued with conceptual confounds. At the same time,
this type of gamble allows for an elegant manipulation of uncertainty. We can
simply use the entropy of the second-order probability distribution (i.e. the prob-
abilities that a certain outcome probability will be realised) to quantify rule
uncertainty. In a repeated gamble on aversive outcomes, we presented a “bowling
108                                                                           D.R. Bach

ball game” gamble to participants. A grey ball would appear somewhere on the
screen—it could either come from player type 1 or player type 2. Balls from the two
player types represented gambles with different outcome probabilities—but the
same outcome magnitudes. Now if the ball was close to player type 1, it was more
likely to have come from player 1, and if it appeared right in the middle of the
screen, it was equally likely to have come from either of the players. Hence, the
latter situation involves more uncertainty than the former, and we can realise many
ball positions with different rule uncertainties. Indeed, it turned out that gambles are
avoided to a degree that depends on the amount of rule uncertainty (Bach et al.
2011). This avoidance of uncertain situations with higher uncertainty appeared to
be due to overweighting of the more unfavourable possibility when rule uncertainty
was high (Bach et al. 2011). A neural representation of this uncertainty was found
in the posterior cingulate cortex. In contrast, neural responses to the contrast
ambiguity versus non-ambiguity—possibly not reflecting uncertainty—are consis-
tently reported in a different brain area, namely in the posterior parietal cortex (Bach
et al. 2009, 2011; Huettel et al. 2006).



6.5    Sensory Uncertainty

Value-based decisions are often based on abstract, propositional information—here,
sensory uncertainty is often irrelevant. In many biological situations, however,
information has to be extracted from low-level physical information. This includes
a plethora of neuroeconomic experiments done on non-human animals (Camerer
1995). The influence of sensory uncertainty on value-based decisions is illustrated
by the certainty effect. When faced with a choice between €4 with p = 0.2 and €3
with p = 0.25, an agent might choose the €4 lottery. But when given the choice
between €4 with p = 0.8 and €3 with p = 1, he may flip his preference and go for
the certain €3 option. According to EUT, these are incompatible choices (von
Neumann and Morgenstern 1944), and this discrepancy has been termed the cer-
tainty effect. However, sometimes the reverse is observed: a decreased propensity to
choose the certain option. It has been demonstrated that a certainty effect can be
reversed by manipulating the imprecision on outcome magnitude information
(Shaﬁr et al. 2008). Noisy sensory information will also occur in economic trans-
actions that are made under time pressure (think of a stock market), and in eco-
nomic decisions involving nonmonetary goods.



6.6    Summary and Conclusions

In this chapter, I have discussed how a probabilistic account of the brain can be
integrated with economic accounts of decision-making. It becomes clear that in
natural environments, the brain must extract all information from noisy sensory
6 Decision-Making Under Uncertainty                                                           109

data, and take account of uncertainty on all levels of a neural hierarchy. In this
process, information sources are combined with each other and with prior knowl-
edge. This can also be relevant for situations in which propositional information is
provided as basis for a decision—because even this abstract information may be
combined with prior assumptions. Experimental approaches to neural representa-
tion of uncertainty in economic variables have focused on the concepts of risk and
ambiguity. Sensory and motor uncertainty is less often investigated but may be
crucial to understand value-based behaviour in non-human species. It is likely that
neuroeconomic investigation of decision-making under uncertainty is going to be a
fruitful approach to study the brain, and human decisions.

Acknowledgments I would like to thank Quentin Huys, Marc Guitart Masip, Deborah Talmi and
Matthias Staib, for helpful comments on a ﬁrst draft of this manuscript.




References

Abler B, Herrnberger B, Gron G, Spitzer M (2009) From uncertainty to reward: BOLD
   characteristics differentiate signaling pathways. BMC. Neurosci. 10:154
Aron AR, Shohamy D, Clark J, Myers C, Gluck MA, Poldrack RA (2004) Human midbrain
   sensitivity to cognitive feedback and uncertainty during classiﬁcation learning. J Neurophysiol
   92:1144–1152
Bach DR, Dolan RJ (2012) Knowing how much you don’t know: a neural organization of
   uncertainty estimates. Nat Rev Neurosci 13:572–586
Bach DR, Seymour B, Dolan RJ (2009) Neural activity associated with the passive prediction of
   ambiguity and risk for aversive events. J Neurosci 29:1648–1656
Bach DR, Hulme O, Penny WD, Dolan RJ (2011) The known unknowns: neural representation of
   second-order uncertainty, and ambiguity. J Neurosci 31:4811–4820
Battaglia PW, Schrater PR (2007) Humans trade off viewing time and movement duration to
   improve visuomotor accuracy in a fast reaching task. J Neurosci 27:6984–6994
Becker SW, Brownson FO (1964) What price ambiguity? Or the role of ambiguity in decision
   making. J Polit Econ 72:62–73
Behrens TE, Woolrich MW, Walton ME, Rushworth MF (2007) Learning the value of information
   in an uncertain world. Nat Neurosci 10:1214–1221
Bernoulli D (1738) Specimen theoriae novae de mensura sortis. Commentarii Academiae
   Scientiarum Imperialis Petropolitanae 5:175–192
Brouwer AM, Knill DC (2009) Humans use visual and remembered information about object
   location to plan pointing movements. J Vis 9:24–19
Camerer C (1995) Individual decision making. In: Kagel JH, Roth AE (eds) Handbook of
   experimental economics. Princeton University Press, Princeton, pp 587–704
Camerer C (1999) Ambiguity aversion and non-additive probability: experimental evidence,
   models and applications. In: Luini L (ed) Uncertain decisions: bridging theory and
   experiments. Kluwer, Boston, pp 53–80
Chow CC, Sarin RK (2002) Known, unknown, and unknowable certainties. Theor Decis 52:
   127–138
Curley SP, Yates F, Abrams RA (1986) Psychological sources of ambiguity avoidance. Organ
   Behav Hum Decis Process 38:230–256
d’Acremont M, Lu ZL, Li X, Van der LM, Bechara A (2009) Neural correlates of risk prediction
   error during reinforcement learning in humans. NeuroImage 47:1929–1939
110                                                                                 D.R. Bach

d’Acremont M, Bossaerts P (2008) Neurobiological studies of risk assessment: a comparison of
    expected utility and mean-variance approaches. Cogn Affect Behav Neurosci 8:363–374
Dayan P, Hinton GE (1996) Varieties of Helmholtz machine. Neural Netw 9:1385–1403
Dayan P, Hinton GE, Neal RM, Zemel RS (1995) The Helmholtz machine. Neural Comput 7:
    889–904
Dreher JC, Kohn P, Berman KF (2006) Neural coding of distinct statistical properties of reward
    information in humans. Cereb Cortex 16:561–573
Ellsberg D (1961) Risk, ambiguity, and the savage axioms. Quart J Econ 75:643–669
Faisal AA, Wolpert DM (2009) Near optimal combination of sensory and motor uncertainty in
    time during a naturalistic perception-action task. J Neurophysiol 101:1901–1912
Fitzgerald TH, Seymour B, Bach DR, Dolan RJ (2010) Differentiable neural substrates for learned
    and described value and risk. Curr Biol 20:1823–1829
Friston K (2009) The free-energy principle: a rough guide to the brain? Trends Cogn Sci 13:
    293–301
Friston K (2010) The free-energy principle: a uniﬁed brain theory? Nat Rev Neurosci 11:127–138
Huettel SA, Stowe CJ, Gordon EM, Warner BT, Platt ML (2006) Neural signatures of economic
    preferences for risk and ambiguity. Neuron 49:765–775
Keren G, Gerritsen LEM (1999) On the robustness and possible accounts of ambiguity aversion.
    Acta Psychol 103:149–172
Klibanoff P, Marinacci M, Mukerji S (2005) A smooth model of decision making under ambiguity.
    Econometrica 73:1849–1892
Knill DC, Pouget A (2004) The Bayesian brain: the role of uncertainty in neural coding and
    computation. Trends Neurosci 27:712–719
Kording KP, Wolpert DM (2004) Bayesian integration in sensorimotor learning. Nature
    427:244–247
Kording KP, Wolpert DM (2006) Bayesian decision theory in sensorimotor control. Trends in
    cognitive sciences 10:319–326
Kording KP, Ku SP, Wolpert DM (2004) Bayesian integration in force estimation. J Neurophysiol
    92:3161–3165
Larson JR (1980) Exploring the external validity of a subjectively weighted utility model of
    decision making. Organ Behav Hum Performance 26:293–304
MacCrimmon KR, Larson S (1979) Utility theory: axioms versus ‘paradoxes’. In: Allais M,
    Hagen O (eds) Expected utility hypotheses and the allais paradox. D. Reidel, Dordrecht,
    pp 333–410
Mackintosh NJ (1983) Conditioning and associative learning. Oxford University Press, Oxford
Markowitz H (1952) Portfolio selection. J Finan 7:77–91
Mathys C, Daunizeau J, Friston KJ, Stephan KE (2011) A Bayesian foundation for individual
    learning under uncertainty. Front Hum Neurosci 5:39
Mohr PN, Biele G, Krugel LK, Li SC, Heekeren HR (2010) Neural foundations of risk-return
    trade-off in investment decisions. NeuroImage 49:2556–2563
Muthukrishnan AV, Wathieu L, Xu AJ (2009) Ambiguity aversion and the preference for
    established brands. Manage Sci 55:1933–1941
Ogawa M, van der Meer MA, Esber GR, Cerri DH, Stalnaker TA, Schoenbaum G (2013)
    Risk-responsive orbitofrontal neurons track acquired salience. Neuron 77:251–258
O’Neill M, Schultz W (2010) Coding of reward risk by orbitofrontal neurons is mostly distinct
    from coding of reward value. Neuron 68:789–800
Orban G, Wolpert DM (2011) Representations of uncertainty in sensorimotor control. Curr Opin
    Neurobiol 21:629–635
Parise CV, Knorre K, Ernst MO (2014) Natural auditory scene statistics shapes human spatial
    hearing. Proc Natl Acad Sci USA 111:6104–6108
Pearce JM, Hall G (1980) A model for Pavlovian learning—variations in the effectiveness of
    conditioned but not of unconditioned stimuli. Psychol Rev 87:532–552
Pouget A, Beck JM, Ma WJ, Latham PE (2013) Probabilistic brains: knowns and unknowns. Nat
    Neurosci 16:1170–1178
6 Decision-Making Under Uncertainty                                                          111

Preuschoff K, Bossaerts P, Quartz SR (2006) Neural differentiation of expected reward and risk in
   human subcortical structures. Neuron 51:381–390
Pulford BD, Colman AM (2008) Size doesn’t really matter. ambiguity aversion in Ellsberg urns
   with few balls. Exp Psychol 55:31–37
Rescorla RA, Wagner AR (1972) A theory of Pavlovian conditioning: variations in the
   effectiveness of reinforcement and nonreinforcement. In: Black AH, Prokasy WF
   (eds) Classical conditioning II: current research and theory. Appleton-Century-Crofts, New
   York, pp 64–99
Rolls ET, McCabe C, Redoute J (2008) Expected value, reward outcome, and temporal difference
   error representations in a probabilistic decision task. Cereb Cortex 18:652–663
Schultz W, Dayan P, Montague PR (1997) A neural substrate of prediction and reward. Science
   275:1593–1599
Shaﬁr S, Reich T, Tsur E, Erev I, Lotem A (2008) Perceptual accuracy and conflicting effects of
   certainty on risk-taking behaviour. Nature 453:917–920
Slovic P, Tversky A (1974) Who accepts Savage’s axiom? Behav Sci 19:368–373
Sutton RS, Barto AG (1998) Reinforcement learning: an introduction. MIT Press, Cambridge
Symmonds M, Bossaerts P, Dolan RJ (2010) A behavioral and neural evaluation of prospective
   decision-making under risk. J Neurosci 30:14380–14389
Symmonds M, Wright ND, Bach DR, Dolan RJ (2011) Deconstructing risk: separable encoding of
   variance and skewness in the brain. NeuroImage
Tassinari H, Hudson TE, Landy MS (2006) Combining priors and noisy visual cues in a rapid
   pointing task. J Neurosci 26:10154–10163
Tobler PN, Fiorillo CD, Schultz W (2005) Adaptive coding of reward value by dopamine neurons.
   Science 307:1642–1645
Tobler PN, O’Doherty JP, Dolan RJ, Schultz W (2007) Reward value coding distinct from risk
   attitude-related uncertainty coding in human reward systems. J Neurophysiol 97:1621–1632
Trautmann ST, Vieider FM, Wakker PP (2008) Causes of ambiguity aversion: known versus
   unknown preferences. J Risk Uncertainty 36:225–243
Trommershauser J, Kording K, Landy MS (2011) Sensory cue integration. Oxford University
   Press, Oxford
Vilares I, Kording K (2011) Bayesian models: the structure of the world, uncertainty, behavior,
   and the brain. Ann NY Acad Sci 1224:22–39
von Neumann J, Morgenstern O (1944) Theory of games and economic behavior. Princeton
   University Press, Princeton
Yates JF, Zukowski LG (1976) Characterization of ambiguity in decision-making. Behav Sci
   21:19–25
Yu AJ, Dayan P (2005) Uncertainty, neuromodulation, and attention. Neuron 46:681–692
